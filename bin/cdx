#!/usr/bin/env bash
# Generated by scripts/build-cdx.sh; edit bin/cdx.d/* and rebuild.
set -euo pipefail

# Fancy-ish log strings
if [[ -t 1 ]]; then
  BOLD="\033[1m"
  DIM="\033[2m"
  GREEN="\033[32m"
  YELLOW="\033[33m"
  ORANGE="\033[38;5;208m"
  CYAN="\033[96m"
  BLUE="\033[36m"
  MAGENTA="\033[35m"
  RED="\033[31m"
  RESET="\033[0m"
else
  BOLD=""
  DIM=""
  GREEN=""
  YELLOW=""
  ORANGE=""
  CYAN=""
  BLUE=""
  MAGENTA=""
  RED=""
  RESET=""
fi

LOG_PREFIX_INFO="${LOG_PREFIX_INFO:-»}"
LOG_PREFIX_WARN="${LOG_PREFIX_WARN:-!}"
LOG_PREFIX_ERROR="${LOG_PREFIX_ERROR:-x}"

log_info() {
  (( CODEX_SILENT )) && return
  local msg="${1-}"
  while IFS= read -r line; do
    printf "%b%s%b %s\n" "${BLUE}${BOLD}" "$LOG_PREFIX_INFO" "${RESET}" "$line"
  done <<< "$msg"
}

log_warn() {
  (( CODEX_SILENT )) && return
  local msg="${1-}"
  while IFS= read -r line; do
    printf "%b%s%b %s\n" "${YELLOW}${BOLD}" "$LOG_PREFIX_WARN" "${RESET}" "$line" >&2
  done <<< "$msg"
}

log_error() {
  local msg="${1-}"
  while IFS= read -r line; do
    printf "%b%s%b %s\n" "${RED}${BOLD}" "$LOG_PREFIX_ERROR" "${RESET}" "$line" >&2
  done <<< "$msg"
}

log_debug() {
  (( CODEX_SILENT )) && return 0
  (( CODEX_DEBUG )) && printf "%b[debug]%b %s\n" "${DIM}" "${RESET}" "$1" >&2
  return 0
}

MOTD_TEXT="$(cat <<'EOF'
  ██████╗ ██████╗ ██████╗ ███████╗██╗  ██╗
 ██╔════╝██╔═══██╗██╔══██╗██╔════╝╚██╗██╔╝
 ██║     ██║   ██║██║  ██║█████╗   ╚███╔╝ 
 ██║     ██║   ██║██║  ██║██╔══╝   ██╔██╗ 
 ╚██████╗╚██████╔╝██████╔╝███████╗██╔╝ ██╗
  ╚═════╝ ╚═════╝ ╚═════╝ ╚══════╝╚═╝  ╚═╝
                                           
  ██████╗ ██████╗  ██████╗ ██████╗ ██████╗ ██╗███╗   ██╗ █████╗ ████████╗ ██████╗ ██████╗ 
 ██╔════╝██╔═══██╗██╔═══██╗██╔══██╗██╔══██╗██║████╗  ██║██╔══██╗╚══██╔══╝██╔═══██╗██╔══██╗
 ██║     ██║   ██║██║   ██║██████╔╝██║  ██║██║██╔██╗ ██║███████║   ██║   ██║   ██║██████╔╝
 ██║     ██║   ██║██║   ██║██╔══██╗██║  ██║██║██║╚██╗██║██╔══██║   ██║   ██║   ██║██╔══██╗
 ╚██████╗╚██████╔╝╚██████╔╝██║  ██║██████╔╝██║██║ ╚████║██║  ██║   ██║   ╚██████╔╝██║  ██║
  ╚═════╝ ╚═════╝  ╚═════╝ ╚═╝  ╚═╝╚═════╝ ╚═╝╚═╝  ╚═══╝╚═╝  ╚═╝   ╚═╝    ╚═════╝ ╚═╝  ╚═╝
EOF
)"

print_motd() {
  while IFS= read -r line; do
    printf "%b %s%b\n" "${ORANGE}${BOLD}" "$line" "${RESET}"
  done <<<"$MOTD_TEXT"
}

mask_key() {
  local key="$1"
  if [[ -z "$key" ]]; then
    printf 'none'
    return
  fi
  local len=${#key}
  if (( len <= 8 )); then
    printf '%s' "$key"
  else
    printf '%s…%s' "${key:0:4}" "${key: -4}"
  fi
}

emit_insecure_notice() {
  (( HOST_SECURITY_NOTICE_EMITTED )) && return
  log_warn "Host marked insecure; auth.json will be removed after this run."
  log_warn "Bootstrap (insecure host): auth will not persist on disk."
  HOST_SECURITY_NOTICE_EMITTED=1
}

CODEX_DEBUG=${CODEX_DEBUG:-0}
CODEX_NO_PTY=${CODEX_NO_PTY:-0}
CODEX_NO_SCRIPT=${CODEX_NO_SCRIPT:-0}
CODEX_FORCE_WRAPPER_UPDATE=0
CODEX_EXIT_AFTER_UPDATE=0
CODEX_DO_UNINSTALL=0
CODEX_PROFILE_CANDIDATE=""
CODEX_SKIP_MOTD=${CODEX_SKIP_MOTD:-0}
CODEX_SILENT="${CODEX_SILENT:-__CODEX_SILENT__}"
CODEX_HOST_MODEL="${CODEX_HOST_MODEL:-__CODEX_HOST_MODEL__}"
CODEX_HOST_REASONING_EFFORT="${CODEX_HOST_REASONING_EFFORT:-__CODEX_HOST_REASONING_EFFORT__}"
if [[ "$CODEX_HOST_MODEL" == "__CODEX_HOST_MODEL__" ]]; then
  CODEX_HOST_MODEL=""
fi
if [[ "$CODEX_HOST_REASONING_EFFORT" == "__CODEX_HOST_REASONING_EFFORT__" ]]; then
  CODEX_HOST_REASONING_EFFORT=""
fi

# Per-host baked configuration (populated by the server at download time).
CODEX_SYNC_BASE_URL_DEFAULT="__CODEX_SYNC_BASE_URL__"
CODEX_SYNC_BASE_URL="$CODEX_SYNC_BASE_URL_DEFAULT"
CODEX_SYNC_API_KEY="__CODEX_SYNC_API_KEY__"
CODEX_SYNC_FQDN="__CODEX_SYNC_FQDN__"
CODEX_SYNC_CA_FILE="__CODEX_SYNC_CA_FILE__"
CODEX_HOST_SECURE="__CODEX_HOST_SECURE__"
if [[ "$CODEX_HOST_SECURE" == "__CODEX_HOST_SECURE__" ]]; then
  CODEX_HOST_SECURE="1"
fi
CODEX_FORCE_IPV4="__CODEX_FORCE_IPV4__"
if [[ "$CODEX_FORCE_IPV4" == "__CODEX_FORCE_IPV4__" ]]; then
  CODEX_FORCE_IPV4="0"
fi
CODEX_INSTALLATION_ID="__CODEX_INSTALLATION_ID__"
if [[ "$CODEX_INSTALLATION_ID" == "__CODEX_INSTALLATION_ID__" ]]; then
  CODEX_INSTALLATION_ID=""
fi
CODEX_SYNC_BAKED=1
CODEX_SYNC_ALLOW_INSECURE="${CODEX_SYNC_ALLOW_INSECURE:-0}"
export CODEX_SYNC_ALLOW_INSECURE
SYNC_CONFIG_LOADED=0
SYNC_WARNED_NO_PYTHON=0
CODEX_COMMAND_STARTED=0
SYNC_PUSH_COMPLETED=0
ORIGINAL_LAST_REFRESH=""
AUTH_PUSH_RESULT=""
AUTH_PUSH_REASON=""
AUTH_STATUS=""
AUTH_ACTION=""
AUTH_MESSAGE=""
SYNC_REMOTE_CLIENT_VERSION=""
SYNC_REMOTE_CLIENT_VERSION_SOURCE=""
SYNC_REMOTE_WRAPPER_VERSION=""
SYNC_REMOTE_WRAPPER_SHA256=""
SYNC_REMOTE_WRAPPER_URL=""
RUNNER_STATE=""
RUNNER_LAST_OK=""
RUNNER_LAST_FAIL=""
RUNNER_LAST_CHECK=""
RUNNER_ENABLED=0
AUTH_PULL_STATUS="skip"
AUTH_PULL_URL=""
AUTH_PULL_REASON=""
LOCAL_AUTH_IS_FRESH=0
LOCAL_AUTH_IS_RECENT=0
last_usage_payload=""
CHATGPT_STATUS=""
CHATGPT_PLAN=""
CHATGPT_NEXT=""
CHATGPT_PRIMARY_USED=""
CHATGPT_PRIMARY_LIMIT=""
CHATGPT_PRIMARY_RESET_AFTER=""
CHATGPT_PRIMARY_RESET_AT=""
CHATGPT_SECONDARY_USED=""
CHATGPT_SECONDARY_LIMIT=""
CHATGPT_SECONDARY_RESET_AFTER=""
CHATGPT_SECONDARY_RESET_AT=""
CHATGPT_DAILY_USED=""
QUOTA_BLOCKED=0
QUOTA_BLOCK_REASON=""
QUOTA_WARNING=0
QUOTA_WARNING_REASON=""
QUOTA_HARD_FAIL="${CODEX_QUOTA_HARD_FAIL:-1}"
QUOTA_LIMIT_PERCENT="${CODEX_QUOTA_LIMIT_PERCENT:-100}"
QUOTA_WEEK_PARTITION="${CODEX_QUOTA_WEEK_PARTITION:-0}"
HOST_SECURE="$CODEX_HOST_SECURE"
HOST_VIP=0
HOST_IS_SECURE=1
PURGE_AUTH_AFTER_RUN=0
HOST_SECURITY_NOTICE_EMITTED=0
HOST_API_CALLS=""
HOST_TOKENS_MONTH_TOTAL=""
HOST_TOKENS_MONTH_INPUT=""
HOST_TOKENS_MONTH_OUTPUT=""
HOST_TOKENS_MONTH_CACHED=""
HOST_TOKENS_MONTH_REASONING=""
HOST_TOKENS_MONTH_EVENTS=""
PROMPT_DIR="$HOME/.codex/prompts"
PROMPT_BASELINE_FILE="$HOME/.codex/.prompt-baseline.json"
PROMPT_SYNC_STATUS="skip"
PROMPT_SYNC_REASON=""
PROMPT_PULL_UPDATED=0
PROMPT_PULL_ERRORS=0
PROMPT_PUSHED=0
PROMPT_PUSH_ERRORS=0
PROMPT_PUSH_STATUS=""
PROMPT_REMOTE_COUNT=""
PROMPT_LOCAL_COUNT=""
PROMPT_LOCAL_CHANGED=""
PROMPT_REMOVED=0
AGENTS_PATH="$HOME/.codex/AGENTS.md"
AGENTS_SYNC_STATUS="skip"
AGENTS_SYNC_REASON=""
AGENTS_STATE=""
AGENTS_REMOTE_SHA=""
AGENTS_REMOTE_UPDATED_AT=""
AGENTS_REMOTE_BYTES=""
AGENTS_REMOVED=0
CONFIG_PATH="$HOME/.codex/config.toml"
CONFIG_SYNC_STATUS="skip"
CONFIG_SYNC_REASON=""
CONFIG_STATE=""
CONFIG_REMOTE_SHA=""
CONFIG_REMOTE_UPDATED_AT=""
CONFIG_REMOTE_BYTES=""
CONFIG_REMOVED=0

if [[ "$HOST_SECURE" == "0" || "${HOST_SECURE,,}" == "false" ]]; then
  HOST_IS_SECURE=0
  PURGE_AUTH_AFTER_RUN=1
  emit_insecure_notice
fi
if [[ "$CODEX_SILENT" == "__CODEX_SILENT__" ]]; then
  CODEX_SILENT=0
fi

WRAPPER_VERSION="2025.12.15-03"
MAX_LOCAL_AUTH_AGE_SECONDS=$((24 * 3600))
MAX_LOCAL_AUTH_RECENT_SECONDS=$((7 * 24 * 3600))
RUNNER_STALE_WARN_SECONDS=$((36 * 3600))
RUNNER_STALE_CRIT_SECONDS=$((72 * 3600))

IS_ROOT=0
CAN_SUDO=0
SUDO_BIN="sudo -n"
if (( EUID == 0 )); then
  IS_ROOT=1
elif command -v sudo >/dev/null 2>&1; then
  if sudo -n true >/dev/null 2>&1; then
    CAN_SUDO=1
  fi
fi

CURRENT_USER="$(id -un 2>/dev/null || echo unknown)"
LOCAL_HOSTNAME="$(hostname -f 2>/dev/null || hostname 2>/dev/null || echo unknown)"
HOST_USERS_CACHE=()
HOST_USERS_FETCHED=0

if [[ "${1-}" == "--execute" ]]; then
  shift
  if (( $# == 0 )); then
    printf 'Usage: cdx --execute "<prompt>" [codex args]\n' >&2
    exit 1
  fi
  prompt="$1"
  shift
  tmp_output="$(mktemp -t cdx-exec-XXXXXX)"
  cleanup_tmp() { rm -f "$tmp_output"; }
  trap cleanup_tmp EXIT
  if codex --model gpt-5.1 --sandbox read-only -a untrusted exec --skip-git-repo-check \
    --output-last-message "$tmp_output" "$prompt" "$@" >/dev/null 2>&1; then
    [[ -s "$tmp_output" ]] && cat "$tmp_output"
    cleanup_tmp
    exit 0
  else
    status=$?
    cleanup_tmp
    exit "$status"
  fi
fi

# Early one-shot commands
case "${1-}" in
  --wrapper-version|-W)
    printf 'cdx wrapper %s\n' "$WRAPPER_VERSION"
    exit 0
    ;;
  --uninstall)
    CODEX_DO_UNINSTALL=1
    shift
    ;;
  --update|-U)
    CODEX_FORCE_WRAPPER_UPDATE=1
    CODEX_EXIT_AFTER_UPDATE=1
    shift
    ;;
esac

case "${1-}" in
  --debug|--verbose)
    CODEX_DEBUG=1
    shift
    ;;
esac

if [[ -n "${1-}" && "${1-}" != -* ]]; then
  CODEX_PROFILE_CANDIDATE="$1"
  shift
fi

if (( ! IS_ROOT )) && (( CAN_SUDO == 0 )); then
  log_info "Non-root execution detected; skipping automatic Codex install/update (passwordless sudo required)."
fi
log_debug "starting | user=${CURRENT_USER} | is_root=${IS_ROOT} | can_sudo=${CAN_SUDO} | path=$PATH"

detect_linux_package_manager() {
  local tokens=()
  if [[ -r /etc/os-release ]]; then
    # shellcheck disable=SC1091
    . /etc/os-release
    if [[ -n "${ID:-}" ]]; then
      tokens+=("$ID")
    fi
    if [[ -n "${ID_LIKE:-}" ]]; then
      local like
      for like in $ID_LIKE; do
        tokens+=("$like")
      done
    fi
  fi
  local token
  for token in "${tokens[@]}"; do
    case "$token" in
      debian|ubuntu)
        if command -v apt-get >/dev/null 2>&1; then
          printf '%s' apt-get
          return 0
        fi
        ;;
      rhel|centos|fedora|almalinux|rocky|ol)
        if command -v dnf >/dev/null 2>&1; then
          printf '%s' dnf
          return 0
        fi
        ;;
    esac
  done
  if command -v apt-get >/dev/null 2>&1; then
    printf '%s' apt-get
    return 0
  fi
  if command -v dnf >/dev/null 2>&1; then
    printf '%s' dnf
    return 0
  fi
  return 1
}

with_sudo() {
  if (( EUID == 0 )); then
    "$@"
  elif command -v sudo >/dev/null 2>&1; then
    sudo "$@"
  else
    return 1
  fi
}

remove_path() {
  local path="$1"
  local label="$2"
  [[ -z "$path" || "$path" == "/" ]] && return 0
  if rm -rf "$path" 2>/dev/null; then
    log_info "Removed $label ($path)"
    return 0
  fi
  if with_sudo rm -rf "$path" 2>/dev/null; then
    log_info "Removed $label ($path) with sudo"
    return 0
  fi
  log_warn "Unable to remove $label ($path)"
  return 1
}

maybe_home() {
  local user="$1"
  local home=""
  if command -v getent >/dev/null 2>&1; then
    home="$(getent passwd "$user" | cut -d: -f6 2>/dev/null || true)"
  fi
  [[ -z "$home" ]] && home="/home/$user"
  printf '%s\n' "$home"
}

uninstall_api_deregister() {
  local base="${CODEX_SYNC_BASE_URL%/}"
  local key="$CODEX_SYNC_API_KEY"
  local cafile="$CODEX_SYNC_CA_FILE"
  if [[ -z "$base" || -z "$key" ]]; then
    log_warn "Skipping API deregistration (missing base URL or API key)"
    return
  fi
  local url="${base}/auth?force=1"
  local args=(-fsS -X DELETE -H "X-API-Key: ${key}")
  [[ -n "$cafile" ]] && args+=(--cacert "$cafile")
  if curl "${args[@]}" "$url" >/dev/null 2>&1; then
    log_info "API deregistration succeeded"
  else
    log_warn "API deregistration failed (continuing cleanup)"
  fi
}

record_host_user_with_api() {
  load_sync_config
  local base="${CODEX_SYNC_BASE_URL%/}"
  local key="$CODEX_SYNC_API_KEY"
  local cafile="$CODEX_SYNC_CA_FILE"
  if [[ -z "$base" || -z "$key" ]]; then
    return 1
  fi
  local hostname="$LOCAL_HOSTNAME"
  [[ -z "$hostname" || "$hostname" == "unknown" ]] && hostname="$(hostname 2>/dev/null || echo unknown)"

  local payload
  if ! payload="$(USERNAME="$CURRENT_USER" HOSTNAME="$hostname" python3 - <<'PY' 2>/dev/null
import json, os, sys
user = os.environ.get("USERNAME", "").strip()
host = os.environ.get("HOSTNAME", "").strip()
print(json.dumps({"username": user, "hostname": host}, ensure_ascii=False))
PY
)"; then
    return 1
  fi

  local url="${base}/host/users"
  local args=(-fsS -X POST -H "X-API-Key: ${key}" -H "Content-Type: application/json" --data "$payload")
  [[ -n "$cafile" ]] && args+=(--cacert "$cafile")
  local response=""
  if ! response="$(curl "${args[@]}" "$url" 2>/dev/null)"; then
    return 1
  fi

  local parsed_users=()
  if mapfile -t parsed_users < <(API_RESPONSE="$response" python3 - <<'PY' 2>/dev/null
import json, os
data = os.environ.get("API_RESPONSE", "")
parsed = json.loads(data)
users = parsed.get("data", {}).get("users")
if not isinstance(users, list):
    raise SystemExit(1)
seen = set()
for entry in users:
    username = None
    if isinstance(entry, dict):
        username = entry.get("username")
    elif isinstance(entry, str):
        username = entry
    if not username:
        continue
    username = str(username).strip()
    if not username or username in seen:
        continue
    seen.add(username)
    print(username)
PY
); then
    parsed_users=()
  fi
  HOST_USERS_CACHE=("${parsed_users[@]-}")
  HOST_USERS_FETCHED=1
  return 0
}

cmd_uninstall() {
  log_info "Starting Codex uninstall"
  load_sync_config
  record_host_user_with_api || true
  uninstall_api_deregister

  # Legacy env/config files
  remove_path "/usr/local/etc/codex-sync.env" "sync env (system)"
  remove_path "/etc/codex-sync.env" "sync env (system-legacy)"
  remove_path "$HOME/.codex/sync.env" "sync env (user)"

  # Auth + state per user (from API fallback to current user)
  local users=()
  if (( ${#HOST_USERS_CACHE[@]} == 0 )); then
    users+=("$CURRENT_USER")
  else
    users+=("${HOST_USERS_CACHE[@]}")
  fi
  local ensured_current=0
  local u
  for u in "${users[@]}"; do
    [[ "$u" == "$CURRENT_USER" ]] && ensured_current=1 && break
  done
  (( ensured_current )) || users+=("$CURRENT_USER")

  local seen=()
  local home
  for u in "${users[@]}"; do
    local skip=0
    for existing in "${seen[@]}"; do
      [[ "$existing" == "$u" ]] && skip=1 && break
    done
    (( skip )) && continue
    seen+=("$u")
    home="$(maybe_home "$u")"
    [[ ! -d "$home" ]] && continue
    remove_path "$home/.codex/auth.json" "auth.json for $u"
    remove_path "$home/.codex" ".codex dir for $u"
  done

  # Binaries and install dirs
  remove_path "/usr/local/bin/cdx" "cdx binary"
  remove_path "$HOME/.local/bin/cdx" "cdx binary (user)"
  remove_path "/usr/local/bin/codex" "codex binary"
  remove_path "$HOME/.local/bin/codex" "codex binary (user)"
  remove_path "/opt/codex" "/opt/codex directory"

  # NPM global package (best effort)
  if command -v npm >/dev/null 2>&1; then
    if npm list -g codex-cli --depth=0 >/dev/null 2>&1; then
      if (( EUID == 0 )); then
        npm uninstall -g codex-cli >/dev/null 2>&1 || log_warn "npm uninstall codex-cli failed"
      else
        with_sudo npm uninstall -g codex-cli >/dev/null 2>&1 || npm uninstall -g codex-cli >/dev/null 2>&1 || log_warn "npm uninstall codex-cli failed"
      fi
      log_info "Removed npm codex-cli (if present)"
    fi
  fi

  log_info "Codex uninstall complete"
  exit 0
}


ensure_commands() {
  local missing=()
  local cmd
  for cmd in "$@"; do
    if ! command -v "$cmd" >/dev/null 2>&1; then
      missing+=("$cmd")
    fi
  done

  if (( ${#missing[@]} == 0 )); then
    return 0
  fi

  if [[ "$(uname -s)" != "Linux" ]]; then
    log_error "Missing required commands: ${missing[*]}. Automatic installation is only supported on Linux."
    exit 1
  fi

  local pm=""
  if ! pm="$(detect_linux_package_manager)"; then
    log_error "Missing required commands: ${missing[*]}. Unable to determine package manager for automatic installation."
    exit 1
  fi

  local use_sudo=()
  if (( EUID != 0 )); then
    if command -v sudo >/dev/null 2>&1; then
      use_sudo=(sudo)
    else
      log_error "Missing required commands: ${missing[*]}. Install them manually or rerun Codex as root to allow automatic installation."
      exit 1
    fi
  fi

  case "$pm" in
    apt-get)
      log_info "Installing prerequisites (${missing[*]}) with apt-get"
      if (( ${#use_sudo[@]} > 0 )); then
        "${use_sudo[@]}" apt-get update -qq
        "${use_sudo[@]}" env DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends "${missing[@]}"
      else
        apt-get update -qq
        DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends "${missing[@]}"
      fi
      ;;
    dnf)
      log_info "Installing prerequisites (${missing[*]}) with dnf"
      if (( ${#use_sudo[@]} > 0 )); then
        "${use_sudo[@]}" dnf install -y "${missing[@]}"
      else
        dnf install -y "${missing[@]}"
      fi
      ;;
    *)
      log_error "Unsupported package manager: ${pm}"
      exit 1
      ;;
  esac

  local still_missing=()
  for cmd in "${missing[@]}"; do
    if ! command -v "$cmd" >/dev/null 2>&1; then
      still_missing+=("$cmd")
    fi
  done

  if (( ${#still_missing[@]} > 0 )); then
    log_error "Failed to install required commands: ${still_missing[*]}"
    exit 1
  fi
}

is_codex_installed_via_npm() {
  if ! command -v npm >/dev/null 2>&1; then
    return 1
  fi
  if npm list -g codex-cli --depth=0 >/dev/null 2>&1; then
    return 0
  fi
  return 1
}

update_codex_via_npm() {
  local target="$1"
  if ! command -v npm >/dev/null 2>&1; then
    return 1
  fi
  if [[ -z "$target" ]]; then
    npm install -g codex-cli >/dev/null
  else
    npm install -g "codex-cli@$target" >/dev/null
  fi
}

real_path() {
  if command -v realpath >/dev/null 2>&1; then
    realpath "$1"
  elif command -v python3 >/dev/null 2>&1; then
    python3 - "$1" <<'PY'
import os, sys
print(os.path.realpath(sys.argv[1]))
PY
  else
    # best effort fallback
    local dir
    dir="$(cd "$(dirname "$1")" 2>/dev/null && pwd)"
    printf '%s/%s\n' "${dir:-.}" "$(basename "$1")"
  fi
}

get_file_mtime() {
  if stat --version >/dev/null 2>&1; then
    stat -c %Y "$1"
  else
    stat -f %m "$1"
  fi
}

resolve_real_codex() {
  local self_real
  self_real="$(real_path "$0")"
  local prefer_paths=(
    /usr/local/bin/codex
    /opt/codex/bin/codex
  )
  local preferred=""
  for preferred in "${prefer_paths[@]}"; do
    if [[ -x "$preferred" ]]; then
      local preferred_real
      preferred_real="$(real_path "$preferred")"
      if [[ "$preferred_real" != "$self_real" ]]; then
        printf '%s' "$preferred_real"
        return 0
      fi
    fi
  done
  local found=""
  IFS=: read -r -a path_entries <<< "${PATH:-}"
  for entry in "${path_entries[@]}"; do
    [[ -z "$entry" ]] && entry="."
    local candidate="$entry/codex"
    [[ ! -x "$candidate" ]] && continue
    local candidate_real
    candidate_real="$(real_path "$candidate")"
    if [[ "$candidate_real" == "$self_real" ]]; then
      continue
    fi
    found="$candidate_real"
    break
  done
  if [[ -z "$found" && -x /usr/local/bin/codex ]]; then
    found="$(real_path /usr/local/bin/codex)"
  fi
  printf '%s' "$found"
}

normalize_version() {
  local v="$1"
  v="${v#codex-cli }"
  v="${v#codex }"
  v="${v#rust-}"
  v="${v#v}"
  printf '%s' "$v"
}

detect_glibc_version() {
  local version=""
  if command -v getconf >/dev/null 2>&1; then
    local gc
    gc="$(getconf GNU_LIBC_VERSION 2>/dev/null || true)"
    if [[ "$gc" =~ ([0-9]+\.[0-9]+) ]]; then
      version="${BASH_REMATCH[1]}"
    fi
  fi
  if [[ -z "$version" ]]; then
    if command -v ldd >/dev/null 2>&1; then
      local first
      first="$(ldd --version 2>&1 | head -n1)"
      if [[ "$first" =~ ([0-9]+\.[0-9]+) ]]; then
        version="${BASH_REMATCH[1]}"
      fi
    fi
  fi
  printf '%s' "$version"
}

version_lt() {
  local a="$1"
  local b="$2"
  [[ "$a" == "$b" ]] && return 1
  if [[ "$(printf '%s\n%s\n' "$a" "$b" | sort -V | head -n1)" == "$a" ]]; then
    return 0
  fi
  return 1
}

probe_latest_version_tag() {
  local url="${1:-https://github.com/openai/codex/releases/latest}"
  if ! command -v curl >/dev/null 2>&1; then
    return 1
  fi
  local effective
  if ! effective="$(curl -fsSLI -o /dev/null -w '%{url_effective}' -L "$url" 2>/dev/null)"; then
    return 1
  fi
  if [[ "$effective" =~ /tag/([^/]+)$ ]]; then
    printf '%s' "${BASH_REMATCH[1]}"
    return 0
  fi
  return 1
}

require_python() {
  if ! command -v python3 >/dev/null 2>&1; then
    log_warn "python3 is required for update checks; skipping update detection."
    return 1
  fi
  return 0
}

load_sync_config() {
  if (( SYNC_CONFIG_LOADED )); then
    return 0
  fi
  # Always prefer baked-in sync configuration; ignore local .env overrides.
  CODEX_SYNC_BASE_URL="${CODEX_SYNC_BASE_URL_DEFAULT%/}"
  log_debug "config (baked-only) | base=${CODEX_SYNC_BASE_URL} | api_key=$(mask_key "$CODEX_SYNC_API_KEY") | fqdn=${CODEX_SYNC_FQDN:-none} | ca=${CODEX_SYNC_CA_FILE:-none} | secure=${CODEX_HOST_SECURE}"
  SYNC_CONFIG_LOADED=1
}

if (( CODEX_DO_UNINSTALL )); then
  cmd_uninstall
fi

sync_auth_with_api() {
  local phase="$1"
  load_sync_config
  if [[ -z "$CODEX_SYNC_API_KEY" || -z "$CODEX_SYNC_BASE_URL" ]]; then
    log_error "Sync config missing API key or base URL; download a fresh cdx wrapper from the server."
    AUTH_PULL_STATUS="missing-config"
    AUTH_PULL_URL="$CODEX_SYNC_BASE_URL"
    return 1
  fi
  if ! command -v python3 >/dev/null 2>&1; then
    log_error "python3 is required for Codex auth sync; install python3 and retry."
    exit 1
  fi
  if (( HOST_USERS_FETCHED == 0 )); then
    record_host_user_with_api || true
  fi
  local auth_path="$HOME/.codex/auth.json"
  AUTH_PULL_REASON=""
  # Drop a malformed local auth.json so we can hydrate cleanly.
  if [[ -f "$auth_path" ]] && ! validate_auth_json_file "$auth_path"; then
    rm -f "$auth_path"
  fi
  local phase_label
  phase_label="${phase:-sync}"
  # No chatty per-step auth logging; final summary will capture the outcome.
  local api_output=""
  local api_status=0
  local offline_reason=""
  if api_output="$(CODEX_SYNC_API_KEY="$CODEX_SYNC_API_KEY" python3 - "$CODEX_SYNC_BASE_URL" "$auth_path" "$CODEX_SYNC_CA_FILE" "$LOCAL_VERSION" "$WRAPPER_VERSION" <<'PY'
import hashlib, json, os, pathlib, ssl, sys, urllib.error, urllib.request

base = (sys.argv[1] or "").rstrip("/")
path = pathlib.Path(sys.argv[2]).expanduser()
cafile = sys.argv[3] if len(sys.argv) > 3 else ""
client_version = sys.argv[4] if len(sys.argv) > 4 else "unknown"
wrapper_version = sys.argv[5] if len(sys.argv) > 5 else "unknown"
api_key = os.environ.get("CODEX_SYNC_API_KEY", "")
installation_id = (os.environ.get("CODEX_INSTALLATION_ID", "") or "").strip()

if not base:
    print("Sync API base URL missing", file=sys.stderr)
    sys.exit(1)


def default_auth():
    return {"last_refresh": "2000-01-01T00:00:00Z", "auths": {}}


def load_auth():
    try:
        data = json.loads(path.read_text(encoding="utf-8"))
    except Exception:  # noqa: BLE001
        return default_auth()
    if not isinstance(data, dict) or "last_refresh" not in data:
        return default_auth()
    return data


def canonical_json(obj):
    return json.dumps(obj, ensure_ascii=False, separators=(",", ":"))


def build_context():
    contexts = []
    # Preferred: custom CA if provided
    ctx_primary = ssl.create_default_context()
    if cafile:
        try:
            ctx_primary.load_verify_locations(cafile)
        except Exception:
            ctx_primary = None
    if ctx_primary is not None:
        try:
            ctx_primary.verify_flags &= ~ssl.VERIFY_X509_STRICT
        except AttributeError:
            pass
        contexts.append(ctx_primary)
    # Fallback: system default
    try:
        ctx_default = ssl.create_default_context()
        ctx_default.verify_flags &= ~ssl.VERIFY_X509_STRICT
        contexts.append(ctx_default)
    except Exception:
        pass
    # Last resort: unverified (only if others fail)
    allow_insecure = os.environ.get("CODEX_SYNC_ALLOW_INSECURE", "").lower() in ("1", "true", "yes")
    if allow_insecure:
        try:
            contexts.append(ssl._create_unverified_context())
        except Exception:
            pass
    return contexts or [None]


def parse_error_body(body: str):
    msg = body
    details = {}
    try:
        parsed = json.loads(body)
        if isinstance(parsed, dict):
            msg = parsed.get("message", body)
            details = parsed.get("details", {}) or {}
    except Exception:
        pass
    return msg, details


def normalize_bool(value):
    if isinstance(value, bool):
        return value
    if isinstance(value, (int, float)):
        return bool(value)
    return None


def fail_with_http(exc: urllib.error.HTTPError, action: str):
    body = exc.read().decode("utf-8", "ignore")
    msg, details = parse_error_body(body)
    msg_lower = msg.lower() if isinstance(msg, str) else ""
    detail_code = ""
    if isinstance(details, dict):
        detail_code = str(details.get("code") or "").lower()
    expected_ip = details.get("expected_ip") if isinstance(details, dict) else None
    received_ip = details.get("received_ip") if isinstance(details, dict) else None
    extra = ""
    if expected_ip or received_ip:
        parts = []
        if expected_ip:
            parts.append(f"expected {expected_ip}")
        if received_ip:
            parts.append(f"received {received_ip}")
        extra = " (" + ", ".join(parts) + ")"
    if exc.code == 401:
        if isinstance(msg, str) and "Invalid API key" in msg:
            sys.exit(10)
        if isinstance(msg, str) and "API key missing" in msg:
            sys.exit(21)
        sys.exit(22)
    if exc.code == 403:
        if "host is disabled" in msg_lower:
            sys.exit(11)
        if detail_code == "insecure_api_disabled" or "insecure host api access disabled" in msg_lower:
            print("insecure host API access disabled", file=sys.stderr)
            sys.exit(24)
        if "not allowed from this IP" in msg or expected_ip or received_ip:
            print(f"{action} denied (IP bound){extra}", file=sys.stderr)
            sys.exit(12)
        sys.exit(23)
    if exc.code == 503 and "disabled" in msg.lower():
        print("api disabled", file=sys.stderr)
        sys.exit(40)
    print(f"{action} failed ({exc.code}): {msg}{extra}", file=sys.stderr)
    sys.exit(2)


def post_json(url: str, payload: dict, action: str):
    body = canonical_json(payload).encode("utf-8")
    headers = {"Content-Type": "application/json", "X-API-Key": api_key}
    req = urllib.request.Request(url, data=body, headers=headers, method="POST")
    contexts = build_context()
    last_err = None
    offline_reason = ""
    for ctx in contexts:
        try:
            with urllib.request.urlopen(req, timeout=20, context=ctx) as resp:
                return json.load(resp)
        except urllib.error.HTTPError as exc:
            if 500 <= exc.code < 600:
                offline_reason = f"http-{exc.code}"
                last_err = exc
                continue
            fail_with_http(exc, action)
        except Exception as exc:  # noqa: BLE001
            last_err = exc
            if isinstance(exc, urllib.error.URLError):
                reason_val = getattr(exc, "reason", None)
                offline_reason = str(reason_val or exc)
            continue
    if offline_reason:
        safe_reason = offline_reason.replace("\n", " ").strip()
        print(f"offline:{safe_reason}")
        sys.exit(3)
    print(f"{action} failed: {last_err}", file=sys.stderr)
    sys.exit(3)


current = load_auth()
auth_json = canonical_json(current)
auth_sha = hashlib.sha256(auth_json.encode("utf-8")).hexdigest()

retrieve_payload = {
    "command": "retrieve",
    "last_refresh": current.get("last_refresh") or "2000-01-01T00:00:00Z",
    "digest": auth_sha,
    "client_version": client_version or "unknown",
}
if wrapper_version and wrapper_version != "unknown":
    retrieve_payload["wrapper_version"] = wrapper_version
if installation_id:
    retrieve_payload["installation_id"] = installation_id

retrieve_data = post_json(f"{base}/auth", retrieve_payload, "auth retrieve")
payload_data = retrieve_data.get("data") if isinstance(retrieve_data, dict) else {}
status = (payload_data or {}).get("status")
versions_block = payload_data.get("versions") if isinstance(payload_data, dict) else {}
canonical_digest = payload_data.get("canonical_digest") or payload_data.get("digest")
auth_to_write = None
chatgpt_usage = payload_data.get("chatgpt_usage") if isinstance(payload_data, dict) else {}
host_info = payload_data.get("host") if isinstance(payload_data, dict) else {}
host_secure = normalize_bool(host_info.get("secure")) if isinstance(host_info, dict) else None
host_vip = normalize_bool(host_info.get("vip")) if isinstance(host_info, dict) else None


def record_versions(vblock):
    out = {}
    if isinstance(vblock, dict):
        cv = vblock.get("client_version")
        if isinstance(cv, str) and cv.strip():
            out["client_version"] = cv.strip()
        cvs = vblock.get("client_version_source")
        if isinstance(cvs, str) and cvs.strip():
            out["client_version_source"] = cvs.strip()
        wv = vblock.get("wrapper_version")
        if isinstance(wv, str) and wv.strip():
            out["wrapper_version"] = wv.strip()
        ws = vblock.get("wrapper_sha256")
        if isinstance(ws, str) and ws.strip():
            out["wrapper_sha256"] = ws.strip()
        wu = vblock.get("wrapper_url")
        if isinstance(wu, str) and wu.strip():
            out["wrapper_url"] = wu.strip()
        rs = vblock.get("runner_state")
        if isinstance(rs, str) and rs.strip():
            out["runner_state"] = rs.strip()
        rlo = vblock.get("runner_last_ok")
        if isinstance(rlo, str) and rlo.strip():
            out["runner_last_ok"] = rlo.strip()
        rlf = vblock.get("runner_last_fail")
        if isinstance(rlf, str) and rlf.strip():
            out["runner_last_fail"] = rlf.strip()
        rlc = vblock.get("runner_last_check")
        if isinstance(rlc, str) and rlc.strip():
            out["runner_last_check"] = rlc.strip()
        re = vblock.get("runner_enabled")
        if isinstance(re, bool):
            out["runner_enabled"] = re
        silent = vblock.get("cdx_silent")
        if isinstance(silent, bool):
            out["cdx_silent"] = silent
        inst = vblock.get("installation_id")
        if isinstance(inst, str) and inst.strip():
            out["installation_id"] = inst.strip()
    return out


def window(value):
    return value if isinstance(value, dict) else {}


versions_out = record_versions(versions_block)
if versions_out.get("client_version"):
    SYNC_REMOTE_CLIENT_VERSION = versions_out.get("client_version")
if versions_out.get("wrapper_version"):
    SYNC_REMOTE_WRAPPER_VERSION = versions_out.get("wrapper_version")
if versions_out.get("wrapper_sha256"):
    SYNC_REMOTE_WRAPPER_SHA256 = versions_out.get("wrapper_sha256")
server_installation = versions_out.get("installation_id")
if server_installation and installation_id and server_installation != installation_id:
    print("Installation ID mismatch; wrapper belongs to a different server", file=sys.stderr)
    sys.exit(42)
if versions_out.get("wrapper_url"):
    SYNC_REMOTE_WRAPPER_URL = versions_out.get("wrapper_url")

primary_window = window(chatgpt_usage.get("primary_window"))
secondary_window = window(chatgpt_usage.get("secondary_window"))

if status == "valid":
    auth_to_write = current
elif status == "outdated":
    auth_to_write = payload_data.get("auth") or current
    lr = payload_data.get("canonical_last_refresh") or payload_data.get("last_refresh")
    if isinstance(lr, str):
        auth_to_write["last_refresh"] = lr
elif status in ("missing", "upload_required"):
    pass
else:
    status = "upload_required"

if status in ("missing", "upload_required"):
    store_payload = {
        "command": "store",
        "auth": current,
        "client_version": client_version or "unknown",
    }
    if canonical_digest:
        store_payload["digest"] = canonical_digest
    if wrapper_version and wrapper_version != "unknown":
        store_payload["wrapper_version"] = wrapper_version
    if installation_id:
        store_payload["installation_id"] = installation_id
    update_data = post_json(f"{base}/auth", store_payload, "auth store")
    payload_data = update_data.get("data") if isinstance(update_data, dict) else {}
    versions_out = record_versions(payload_data.get("versions", {})) or versions_out
    host_info = payload_data.get("host") if isinstance(payload_data, dict) else host_info
    host_vip = normalize_bool(host_info.get("vip")) if isinstance(host_info, dict) else host_vip
    host_secure = normalize_bool(host_info.get("secure")) if isinstance(host_info, dict) else host_secure
    server_installation = versions_out.get("installation_id")
    if server_installation and installation_id and server_installation != installation_id:
        print("Installation ID mismatch; wrapper belongs to a different server", file=sys.stderr)
        sys.exit(42)
    auth_to_write = payload_data.get("auth") or current
    lr = payload_data.get("canonical_last_refresh") or payload_data.get("last_refresh")
    if isinstance(lr, str):
        auth_to_write["last_refresh"] = lr

if not isinstance(auth_to_write, dict):
    auth_to_write = current

path.parent.mkdir(parents=True, exist_ok=True)
path.write_text(json.dumps(auth_to_write, indent=2) + "\n", encoding="utf-8")
try:
    os.chmod(path, 0o600)
except PermissionError:
    pass

# Surface versions and auth outcome to caller via stdout as JSON
print(
    json.dumps(
        {
            "versions": versions_out,
            "auth_status": status or "unknown",
            "auth_action": ("store" if status in ("missing", "upload_required") else status or "unknown"),
            "auth_message": (
                "synced (no change)" if status == "valid" else
                "updated from api" if status == "outdated" else
                "uploaded current auth" if status in ("missing", "upload_required") else
                status
            ),
            "host_secure": host_secure,
            "chatgpt_status": chatgpt_usage.get("status"),
            "chatgpt_plan": chatgpt_usage.get("plan_type"),
            "chatgpt_next": chatgpt_usage.get("next_eligible_at"),
            "chatgpt_primary_used": primary_window.get("used_percent"),
            "chatgpt_primary_limit": primary_window.get("limit_seconds"),
            "chatgpt_primary_reset_after": primary_window.get("reset_after_seconds"),
            "chatgpt_primary_reset_at": primary_window.get("reset_at"),
            "chatgpt_secondary_used": secondary_window.get("used_percent"),
            "chatgpt_secondary_limit": secondary_window.get("limit_seconds"),
            "chatgpt_secondary_reset_after": secondary_window.get("reset_after_seconds"),
            "chatgpt_secondary_reset_at": secondary_window.get("reset_at"),
            "chatgpt_daily_used_percent": chatgpt_usage.get("daily_used_percent"),
            "chatgpt_daily_baseline_at": chatgpt_usage.get("daily_baseline_at"),
            "api_calls": payload_data.get("api_calls"),
            "token_usage_month": payload_data.get("token_usage_month"),
            "quota_hard_fail": payload_data.get("quota_hard_fail"),
            "quota_limit_percent": payload_data.get("quota_limit_percent"),
            "quota_week_partition": payload_data.get("quota_week_partition"),
            "cdx_silent": payload_data.get("cdx_silent"),
            "host_vip": host_vip,
        },
        separators=(",", ":"),
    )
)
PY
  )"; then
    log_debug "auth api output: ${api_output}"
    local versions_json
    versions_json="$api_output"
    if [[ -n "$versions_json" ]] && command -v python3 >/dev/null 2>&1; then
      local parsed
      parsed="$(VJSON="$versions_json" python3 - <<'PY'
import json, os, sys
data = os.environ.get("VJSON", "")
try:
    parsed = json.loads(data)
except Exception:
    sys.exit(0)
if not isinstance(parsed, dict):
    sys.exit(0)
versions = parsed.get("versions")
if not isinstance(versions, dict):
    sys.exit(0)
cv = versions.get("client_version")
cvs = versions.get("client_version_source")
wv = versions.get("wrapper_version")
ws = versions.get("wrapper_sha256")
wu = versions.get("wrapper_url")
if isinstance(cv, str) and cv.strip():
    print(f"cv={cv.strip()}")
if isinstance(cvs, str) and cvs.strip():
    print(f"cvs={cvs.strip()}")
if isinstance(wv, str) and wv.strip():
    print(f"wv={wv.strip()}")
if isinstance(ws, str) and ws.strip():
    print(f"ws={ws.strip()}")
if isinstance(wu, str) and wu.strip():
    print(f"wu={wu.strip()}")
rs = versions.get("runner_state")
if isinstance(rs, str) and rs.strip():
    print(f"rs={rs.strip()}")
rlo = versions.get("runner_last_ok")
if isinstance(rlo, str) and rlo.strip():
    print(f"rlo={rlo.strip()}")
rlf = versions.get("runner_last_fail")
if isinstance(rlf, str) and rlf.strip():
    print(f"rlf={rlf.strip()}")
rlc = versions.get("runner_last_check")
if isinstance(rlc, str) and rlc.strip():
    print(f"rlc={rlc.strip()}")
re = versions.get("runner_enabled")
if isinstance(re, bool):
    print("re=1" if re else "re=0")
asv = parsed.get("auth_status")
if isinstance(asv, str) and asv.strip():
    print(f"as={asv.strip()}")
aact = parsed.get("auth_action")
if isinstance(aact, str) and aact.strip():
    print(f"aa={aact.strip()}")
amsg = parsed.get("auth_message")
if isinstance(amsg, str) and amsg.strip():
    print(f"am={amsg.strip()}")
def _emit_int(key, prefix):
    if isinstance(key, (int, float)):
        print(f"{prefix}={int(key)}")
hv = parsed.get("host_vip")
if isinstance(hv, bool):
    print("hv=1" if hv else "hv=0")
qh = parsed.get("quota_hard_fail")
if isinstance(qh, bool):
    print("qh=1" if qh else "qh=0")
elif isinstance(qh, (int, float)):
    print(f"qh={int(qh)}")
ql = parsed.get("quota_limit_percent")
if isinstance(ql, (int, float)):
    print(f"ql={int(ql)}")
qwp = parsed.get("quota_week_partition")
_emit_int(qwp, "qwp")
csil = parsed.get("cdx_silent")
if isinstance(csil, bool):
    print("cs=1" if csil else "cs=0")
hs = parsed.get("host_secure")
if isinstance(hs, bool):
    print("hs=1" if hs else "hs=0")
cgst = parsed.get("chatgpt_status")
if isinstance(cgst, str) and cgst.strip():
    print(f"cgs={cgst.strip()}")
cgpl = parsed.get("chatgpt_plan")
if isinstance(cgpl, str) and cgpl.strip():
    print(f"cgp={cgpl.strip()}")
cgnx = parsed.get("chatgpt_next")
if isinstance(cgnx, str) and cgnx.strip():
    print(f"cgn={cgnx.strip()}")
cd_u = parsed.get("chatgpt_daily_used_percent") or parsed.get("chatgpt_daily_used")
_emit_int(cd_u, "cgdu")
cp_u = parsed.get("chatgpt_primary_used")
_emit_int(cp_u, "cgu")
cp_l = parsed.get("chatgpt_primary_limit")
_emit_int(cp_l, "cgl")
cp_r = parsed.get("chatgpt_primary_reset_after")
_emit_int(cp_r, "cgr")
cp_a = parsed.get("chatgpt_primary_reset_at")
if isinstance(cp_a, str) and cp_a.strip():
    print(f"cga={cp_a.strip()}")
cs_u = parsed.get("chatgpt_secondary_used")
_emit_int(cs_u, "cgsu")
cs_l = parsed.get("chatgpt_secondary_limit")
_emit_int(cs_l, "cgsl")
cs_r = parsed.get("chatgpt_secondary_reset_after")
_emit_int(cs_r, "cgsr")
cs_a = parsed.get("chatgpt_secondary_reset_at")
if isinstance(cs_a, str) and cs_a.strip():
    print(f"cgsa={cs_a.strip()}")
api_calls = parsed.get("api_calls")
_emit_int(api_calls, "hac")
month_usage = parsed.get("token_usage_month")
if isinstance(month_usage, dict):
    def _emit_month(key, prefix):
        val = month_usage.get(key)
        _emit_int(val, prefix)
    _emit_month("total", "hmtotal")
    _emit_month("input", "hminput")
    _emit_month("output", "hmoutput")
    _emit_month("cached", "hmcached")
    _emit_month("reasoning", "hmreason")
    _emit_month("events", "hmevents")
PY
)" || true
      if [[ -n "$parsed" ]]; then
        local line
        while IFS= read -r line; do
          case "$line" in
            cv=*)
              SYNC_REMOTE_CLIENT_VERSION="${line#cv=}"
              ;;
            cvs=*)
              SYNC_REMOTE_CLIENT_VERSION_SOURCE="${line#cvs=}"
              ;;
            wv=*)
              SYNC_REMOTE_WRAPPER_VERSION="${line#wv=}"
              ;;
            ws=*)
              SYNC_REMOTE_WRAPPER_SHA256="${line#ws=}"
              ;;
            wu=*)
              SYNC_REMOTE_WRAPPER_URL="${line#wu=}"
              ;;
            rs=*)
              RUNNER_STATE="${line#rs=}"
              ;;
            rlo=*)
              RUNNER_LAST_OK="${line#rlo=}"
              ;;
            rlf=*)
              RUNNER_LAST_FAIL="${line#rlf=}"
              ;;
            rlc=*)
              RUNNER_LAST_CHECK="${line#rlc=}"
              ;;
            re=*)
              RUNNER_ENABLED="${line#re=}"
              ;;
            as=*)
              AUTH_STATUS="${line#as=}"
              ;;
            aa=*)
              AUTH_ACTION="${line#aa=}"
              ;;
            am=*)
              AUTH_MESSAGE="${line#am=}"
              ;;
            qh=*)
              QUOTA_HARD_FAIL="${line#qh=}"
              ;;
            hv=*)
              HOST_VIP="${line#hv=}"
              ;;
            ql=*)
              QUOTA_LIMIT_PERCENT="${line#ql=}"
              ;;
            qwp=*)
              QUOTA_WEEK_PARTITION="${line#qwp=}"
              ;;
            cs=*)
              CODEX_SILENT="${line#cs=}"
              ;;
            hs=*)
              HOST_SECURE="${line#hs=}"
              ;;
            cgs=*)
              CHATGPT_STATUS="${line#cgs=}"
              ;;
            cgp=*)
              CHATGPT_PLAN="${line#cgp=}"
              ;;
            cgn=*)
              CHATGPT_NEXT="${line#cgn=}"
              ;;
            cgu=*)
              CHATGPT_PRIMARY_USED="${line#cgu=}"
              ;;
            cgl=*)
              CHATGPT_PRIMARY_LIMIT="${line#cgl=}"
              ;;
            cgr=*)
              CHATGPT_PRIMARY_RESET_AFTER="${line#cgr=}"
              ;;
            cga=*)
              CHATGPT_PRIMARY_RESET_AT="${line#cga=}"
              ;;
            cgsu=*)
              CHATGPT_SECONDARY_USED="${line#cgsu=}"
              ;;
            cgsl=*)
              CHATGPT_SECONDARY_LIMIT="${line#cgsl=}"
              ;;
            cgsr=*)
              CHATGPT_SECONDARY_RESET_AFTER="${line#cgsr=}"
              ;;
            cgsa=*)
              CHATGPT_SECONDARY_RESET_AT="${line#cgsa=}"
              ;;
            cgdu=*)
              CHATGPT_DAILY_USED="${line#cgdu=}"
              ;;
            hac=*)
              HOST_API_CALLS="${line#hac=}"
              ;;
            hmtotal=*)
              HOST_TOKENS_MONTH_TOTAL="${line#hmtotal=}"
              ;;
            hminput=*)
              HOST_TOKENS_MONTH_INPUT="${line#hminput=}"
              ;;
            hmoutput=*)
              HOST_TOKENS_MONTH_OUTPUT="${line#hmoutput=}"
              ;;
            hmcached=*)
              HOST_TOKENS_MONTH_CACHED="${line#hmcached=}"
              ;;
            hmreason=*)
              HOST_TOKENS_MONTH_REASONING="${line#hmreason=}"
              ;;
            hmevents=*)
              HOST_TOKENS_MONTH_EVENTS="${line#hmevents=}"
              ;;
          esac
        done <<<"$parsed"

        if [[ "$HOST_SECURE" == "0" || "${HOST_SECURE,,}" == "false" ]]; then
          HOST_IS_SECURE=0
          PURGE_AUTH_AFTER_RUN=1
          emit_insecure_notice
        else
          HOST_IS_SECURE=1
          PURGE_AUTH_AFTER_RUN=0
        fi
      fi
    fi
    AUTH_PULL_STATUS="ok"
    AUTH_PULL_URL="$CODEX_SYNC_BASE_URL"
    return 0
  else
    api_status=$?
    if [[ "$api_output" == offline:* ]]; then
      offline_reason="${api_output#offline:}"
    fi
  fi
  case "$api_status" in
    10)
      log_warn "Auth sync denied: invalid API key; removing local auth.json"
      AUTH_PULL_STATUS="invalid"
      rm -f "$auth_path" 2>/dev/null || true
      return 1
      ;;
    11)
      log_warn "Auth sync denied: host disabled; removing local auth.json"
      rm -f "$auth_path" 2>/dev/null || true
      return 1
      ;;
    12)
      log_warn "Auth sync blocked for this IP (key bound elsewhere); re-register to rotate the key. Keeping local auth.json."
      return 1
      ;;
    21|22)
      log_warn "Auth sync failed: API key missing/invalid"
      return 1
      ;;
    2|3)
      local reason_suffix=""
      if [[ -n "$offline_reason" ]]; then
        AUTH_PULL_REASON="$offline_reason"
        reason_suffix="; reason=${offline_reason}"
        log_debug "auth sync offline reason: ${offline_reason}"
      fi
      if [[ -n "$phase" ]]; then
        log_warn "Auth API sync (${phase}) unreachable (base=${CODEX_SYNC_BASE_URL}, key=$(mask_key "$CODEX_SYNC_API_KEY")${reason_suffix})"
      else
        log_warn "Auth API sync unreachable (base=${CODEX_SYNC_BASE_URL}, key=$(mask_key "$CODEX_SYNC_API_KEY")${reason_suffix})"
      fi
      AUTH_PULL_STATUS="offline"
      AUTH_PULL_URL="$CODEX_SYNC_BASE_URL"
      return 1
      ;;
    40)
      log_warn "Auth sync blocked: API disabled by administrator"
      AUTH_PULL_STATUS="disabled"
      AUTH_PULL_URL="$CODEX_SYNC_BASE_URL"
      return 1
      ;;
    24)
      log_warn "Auth sync blocked: insecure host window is closed; enable it in the admin dashboard and retry."
      AUTH_PULL_STATUS="insecure"
      AUTH_PULL_URL="$CODEX_SYNC_BASE_URL"
      return 1
      ;;
    *)
      if [[ -n "$phase" ]]; then
        log_warn "Auth API sync (${phase}) failed (base=${CODEX_SYNC_BASE_URL}, key=$(mask_key "$CODEX_SYNC_API_KEY"))"
      else
        log_warn "Auth API sync failed (base=${CODEX_SYNC_BASE_URL}, key=$(mask_key "$CODEX_SYNC_API_KEY"))"
      fi
      AUTH_PULL_STATUS="fail"
      AUTH_PULL_URL="$CODEX_SYNC_BASE_URL"
      return 1
      ;;
  esac
  return 1
}

get_auth_last_refresh() {
  local path="$1"
  if [[ ! -f "$path" ]]; then
    return 0
  fi
  if ! command -v python3 >/dev/null 2>&1; then
    return 0
  fi
 python3 - "$path" <<'PY'
import json, sys, pathlib
path = pathlib.Path(sys.argv[1])
try:
    data = json.loads(path.read_text(encoding="utf-8"))
except Exception:  # noqa: BLE001
    sys.exit(0)
if isinstance(data, dict):
    lr = data.get("last_refresh")
    if isinstance(lr, str):
        print(lr, end="")
PY
}

is_last_refresh_recent() {
  local last_refresh="$1"
  local max_age_seconds="${2:-$MAX_LOCAL_AUTH_AGE_SECONDS}"
  if [[ -z "$last_refresh" ]]; then
    return 1
  fi
  if ! command -v python3 >/dev/null 2>&1; then
    return 1
  fi
  python3 - "$last_refresh" "$max_age_seconds" <<'PY'
import sys, datetime
from datetime import timezone

value = sys.argv[1]
max_age_seconds = int(sys.argv[2])
max_future_skew = 300
try:
    dt = datetime.datetime.fromisoformat(value.replace("Z", "+00:00"))
    if dt.tzinfo is None:
        dt = dt.replace(tzinfo=timezone.utc)
    now = datetime.datetime.now(timezone.utc)
    delta = now - dt
except Exception:  # noqa: BLE001
    sys.exit(1)

if delta.total_seconds() < -max_future_skew:
    sys.exit(1)
if delta.total_seconds() <= max_age_seconds:
    sys.exit(0)
sys.exit(1)
PY
}

validate_auth_json_file() {
  local path="$1"
  if [[ ! -f "$path" ]]; then
    return 1
  fi
  if ! command -v python3 >/dev/null 2>&1; then
    return 1
  fi
  python3 - "$path" <<'PY'
import json, sys, pathlib

path = pathlib.Path(sys.argv[1])
try:
    data = json.loads(path.read_text(encoding="utf-8"))
except Exception:  # noqa: BLE001
    sys.exit(1)

if not isinstance(data, dict):
    sys.exit(1)

last_refresh = data.get("last_refresh")
auths = data.get("auths")

if not isinstance(last_refresh, str) or not last_refresh.strip():
    sys.exit(1)

if not isinstance(auths, dict) or not auths:
    sys.exit(1)

for target, entry in auths.items():
    if not isinstance(target, str) or not target.strip():
        sys.exit(1)
    if not isinstance(entry, dict):
        sys.exit(1)
    token = entry.get("token")
    if not isinstance(token, str) or not token.strip():
        sys.exit(1)

sys.exit(0)
PY
}

push_auth_if_changed() {
  local phase="${1:-push}"
  local auth_path="$HOME/.codex/auth.json"
  local refreshed
  refreshed="$(get_auth_last_refresh "$auth_path")"
  # No local auth present
  if [[ -z "$ORIGINAL_LAST_REFRESH" && -z "$refreshed" ]]; then
    AUTH_PUSH_RESULT="skipped"
    AUTH_PUSH_REASON="no local auth.json"
    return 0
  fi
  if [[ "$refreshed" == "$ORIGINAL_LAST_REFRESH" ]]; then
    AUTH_PUSH_RESULT="not-needed"
    AUTH_PUSH_REASON="auth.json unchanged"
    return 0
  fi
  if sync_auth_with_api "$phase"; then
    SYNC_PUSH_COMPLETED=1
    AUTH_PUSH_RESULT="uploaded"
    AUTH_PUSH_REASON="auth.json changed"
    return 0
  fi
  AUTH_PUSH_RESULT="failed"
  AUTH_PUSH_REASON="api sync error"
  return 1
}


prompt_sync_python() {
  local mode="$1"
  local base="$2"
  local api_key="$3"
  local prompt_dir="$4"
  local cafile="$5"
  local baseline_file="$6"
  CODEX_SYNC_API_KEY="$api_key" python3 - "$mode" "$base" "$prompt_dir" "$cafile" "$baseline_file" <<'PY'
import hashlib, json, os, pathlib, ssl, sys, urllib.error, urllib.request

mode = sys.argv[1] if len(sys.argv) > 1 else ""
base = (sys.argv[2] or "").rstrip("/")
prompt_dir = pathlib.Path(sys.argv[3]).expanduser()
cafile = sys.argv[4] if len(sys.argv) > 4 else ""
baseline_file = pathlib.Path(sys.argv[5]).expanduser() if len(sys.argv) > 5 else prompt_dir.parent / ".prompt-baseline.json"
api_key = os.environ.get("CODEX_SYNC_API_KEY", "")


def contexts():
    ctxs = []
    primary = ssl.create_default_context()
    if cafile:
        try:
            primary.load_verify_locations(cafile)
        except Exception:
            primary = None
    if primary is not None:
        try:
            primary.verify_flags &= ~ssl.VERIFY_X509_STRICT
        except AttributeError:
            pass
        ctxs.append(primary)
    try:
        fallback = ssl.create_default_context()
        fallback.verify_flags &= ~ssl.VERIFY_X509_STRICT
        ctxs.append(fallback)
    except Exception:
        pass
    allow_insecure = os.environ.get("CODEX_SYNC_ALLOW_INSECURE", "").lower() in ("1", "true", "yes")
    if allow_insecure:
        try:
            ctxs.append(ssl._create_unverified_context())
        except Exception:
            pass
    return ctxs or [None]


def request_json(method: str, url: str, payload=None):
    data = None
    headers = {"X-API-Key": api_key}
    if payload is not None:
        data = json.dumps(payload, ensure_ascii=False, separators=(",", ":")).encode("utf-8")
        headers["Content-Type"] = "application/json"
    req = urllib.request.Request(url, data=data, headers=headers, method=method)
    last_err = None
    for ctx in contexts():
        try:
            with urllib.request.urlopen(req, timeout=20, context=ctx) as resp:
                return json.load(resp)
        except urllib.error.HTTPError as exc:  # noqa: PERF203
            body = exc.read().decode("utf-8", "ignore")
            reason = f"http-{exc.code}"
            if body:
                reason = f"{reason}:{body.strip()[:80]}"
            raise RuntimeError(reason) from exc
        except Exception as exc:  # noqa: BLE001
            last_err = exc
            continue
    raise RuntimeError(f"request failed: {last_err}")


def parse_front_matter(text: str):
    description = None
    argument_hint = None
    lines = text.splitlines()
    if not lines or lines[0].strip() != "---":
        return description, argument_hint
    end_idx = None
    for idx in range(1, len(lines)):
        if lines[idx].strip() == "---":
            end_idx = idx
            break
    if end_idx is None:
        return description, argument_hint
    for idx in range(1, end_idx):
        line = lines[idx].strip()
        if not line or ":" not in line:
            continue
        key, value = line.split(":", 1)
        key = key.strip().lower()
        value = value.strip()
        if key == "description":
            description = value
        elif key == "argument-hint":
            argument_hint = value
    return description, argument_hint


def load_local(include_content: bool = False):
    prompt_dir.mkdir(parents=True, exist_ok=True)
    prompts = {}
    for path in prompt_dir.iterdir():
        if not path.is_file():
            continue
        try:
            content = path.read_text(encoding="utf-8")
        except Exception:  # noqa: BLE001
            continue
        sha = hashlib.sha256(content.encode("utf-8")).hexdigest()
        entry = {"filename": path.name, "sha": sha}
        if include_content:
            entry["content"] = content
        prompts[path.name] = entry
    return prompts


def save_baseline(prompts: dict):
    try:
        baseline_file.parent.mkdir(parents=True, exist_ok=True)
        baseline_file.write_text(json.dumps(prompts, indent=2) + "\n", encoding="utf-8")
    except Exception:  # noqa: BLE001
        pass


if not base:
    print("error reason=missing-base")
    sys.exit(1)
if not api_key:
    print("error reason=missing-api-key")
    sys.exit(1)

prompt_dir.mkdir(parents=True, exist_ok=True)

if mode == "pull":
    try:
        list_resp = request_json("GET", f"{base}/slash-commands")
    except Exception as exc:  # noqa: BLE001
        print(f"error reason={str(exc).replace(' ', '_')}")
        sys.exit(1)

    commands = []
    if isinstance(list_resp, dict):
        data = list_resp.get("data") or {}
        commands = data.get("commands") or []
    downloaded = 0
    errors = 0
    removed = 0
    local = load_local()

    for cmd in commands:
        if not isinstance(cmd, dict):
            continue
        fname = cmd.get("filename")
        rsha = cmd.get("sha256")
        deleted = bool(cmd.get("deleted_at"))
        if not fname:
            continue
        if deleted:
            try:
                (prompt_dir / fname).unlink(missing_ok=True)
                removed += 1
            except Exception:
                pass
            continue
        if not rsha:
            continue
        local_sha = (local.get(fname) or {}).get("sha")
        if local_sha and local_sha == rsha:
            continue
        payload = {"filename": fname}
        if local_sha:
            payload["sha256"] = local_sha
        try:
            resp = request_json("POST", f"{base}/slash-commands/retrieve", payload)
        except Exception as exc:  # noqa: BLE001
            errors += 1
            continue
        data = resp.get("data") if isinstance(resp, dict) else {}
        status = (data or {}).get("status")
        prompt = (data or {}).get("prompt")
        if status == "unchanged":
            continue
        if not isinstance(prompt, str):
            errors += 1
            continue
        try:
            (prompt_dir / fname).write_text(prompt, encoding="utf-8")
            downloaded += 1
        except Exception:  # noqa: BLE001
            errors += 1

    updated_local = load_local()
    baseline = {name: entry["sha"] for name, entry in updated_local.items()}
    remote_names = {cmd["filename"] for cmd in commands if isinstance(cmd, dict) and cmd.get("filename") and not cmd.get("deleted_at")}
    filtered_baseline = {name: sha for name, sha in baseline.items() if name in remote_names}
    save_baseline(filtered_baseline)
    print(
        "ok "
        f"updated={downloaded} "
        f"errors={errors} "
        f"remote={len(commands)} "
        f"local={len(updated_local)} "
        f"removed={removed}"
    )
    sys.exit(0)

if mode == "push":
    if not baseline_file.exists():
        print("skip reason=no-baseline errors=0")
        sys.exit(0)
    try:
        baseline_data = json.loads(baseline_file.read_text(encoding="utf-8"))
    except Exception:  # noqa: BLE001
        baseline_data = {}
    if not isinstance(baseline_data, dict):
        baseline_data = {}

    current = load_local(include_content=True)
    changes = []
    for name, entry in current.items():
        if baseline_data.get(name) != entry.get("sha"):
            changes.append(entry)

    if not changes:
        print("ok pushed=0 errors=0")
        sys.exit(0)

    errors = 0
    pushed = 0
    for entry in changes:
        fname = entry.get("filename")
        content = entry.get("content")
        sha = entry.get("sha")
        if not fname or not content or not sha:
            continue
        desc, arg_hint = parse_front_matter(content)
        payload = {
            "filename": fname,
            "prompt": content,
            "sha256": sha,
        }
        if desc:
            payload["description"] = desc
        if arg_hint:
            payload["argument_hint"] = arg_hint
        try:
            resp = request_json("POST", f"{base}/slash-commands/store", payload)
        except Exception:  # noqa: BLE001
            errors += 1
            continue
        data = resp.get("data") if isinstance(resp, dict) else {}
        status = (data or {}).get("status")
        if status in ("created", "updated", "unchanged"):
            pushed += 1
        else:
            errors += 1

    if errors == 0:
        latest_baseline = {name: entry["sha"] for name, entry in current.items()}
        save_baseline(latest_baseline)

    print(
        "ok "
        f"pushed={pushed} "
        f"errors={errors} "
        f"changes={len(changes)} "
        f"local={len(current)}"
    )
    sys.exit(0)

print("skip reason=unknown-mode errors=0")
PY
}

agents_sync_python() {
  local base="$1"
  local api_key="$2"
  local target_file="$3"
  local cafile="$4"
  local current_sha="$5"
  CODEX_SYNC_API_KEY="$api_key" python3 - "$base" "$target_file" "$cafile" "$current_sha" <<'PY'
import hashlib, json, os, pathlib, ssl, sys, urllib.error, urllib.request

base = (sys.argv[1] or "").rstrip("/")
target = pathlib.Path(sys.argv[2]).expanduser()
cafile = sys.argv[3] if len(sys.argv) > 3 else ""
current_sha = (sys.argv[4] or "").strip() if len(sys.argv) > 4 else ""
api_key = os.environ.get("CODEX_SYNC_API_KEY", "")


def contexts():
    ctxs = []
    primary = ssl.create_default_context()
    if cafile:
        try:
            primary.load_verify_locations(cafile)
        except Exception:
            primary = None
    if primary is not None:
        try:
            primary.verify_flags &= ~ssl.VERIFY_X509_STRICT
        except AttributeError:
            pass
        ctxs.append(primary)
    try:
        fallback = ssl.create_default_context()
        fallback.verify_flags &= ~ssl.VERIFY_X509_STRICT
        ctxs.append(fallback)
    except Exception:
        pass
    allow_insecure = os.environ.get("CODEX_SYNC_ALLOW_INSECURE", "").lower() in ("1", "true", "yes")
    if allow_insecure:
        try:
            ctxs.append(ssl._create_unverified_context())
        except Exception:
            pass
    return ctxs or [None]


def request_json(method: str, url: str, payload=None):
    data = None
    headers = {"X-API-Key": api_key}
    if payload is not None:
        data = json.dumps(payload, ensure_ascii=False, separators=(",", ":")).encode("utf-8")
        headers["Content-Type"] = "application/json"
    req = urllib.request.Request(url, data=data, headers=headers, method=method)
    last_err = None
    for ctx in contexts():
        try:
            with urllib.request.urlopen(req, timeout=20, context=ctx) as resp:
                return json.load(resp)
        except urllib.error.HTTPError as exc:  # noqa: PERF203
            body = exc.read().decode("utf-8", "ignore")
            reason = f"http-{exc.code}"
            if body:
                reason = f"{reason}:{body.strip()[:80]}"
            raise RuntimeError(reason) from exc
        except Exception as exc:  # noqa: BLE001
            last_err = exc
            continue
    raise RuntimeError(f"request failed: {last_err}")


if not base:
    print("error reason=missing-base")
    sys.exit(1)
if not api_key:
    print("error reason=missing-api-key")
    sys.exit(1)

payload = {}
if current_sha and len(current_sha) == 64:
    payload["sha256"] = current_sha

try:
    resp = request_json("POST", f"{base}/agents/retrieve", payload)
except Exception as exc:  # noqa: BLE001
    print(f"error reason={str(exc).replace(' ', '_')}")
    sys.exit(1)

data = resp.get("data") if isinstance(resp, dict) else {}
status = (data or {}).get("status")
sha = (data or {}).get("sha256") or ""
content = (data or {}).get("content")
updated_at = (data or {}).get("updated_at") or ""
size_bytes = data.get("size_bytes") if isinstance(data, dict) else None

if status == "missing":
    removed = 0
    try:
        if target.exists():
            target.unlink()
            removed = 1
    except Exception:
        pass
    print(f"ok status=missing removed={removed}")
    sys.exit(0)

if status == "unchanged":
    print(f"ok status=unchanged sha256={sha}")
    sys.exit(0)

if status == "updated":
    if not isinstance(content, str):
        print("error reason=missing-content")
        sys.exit(1)
    try:
        target.parent.mkdir(parents=True, exist_ok=True)
        target.write_text(content, encoding="utf-8")
    except Exception as exc:  # noqa: BLE001
        print(f"error reason=write-failed:{str(exc).replace(' ', '_')}")
        sys.exit(1)
    length = len(content.encode("utf-8"))
    size_label = size_bytes if isinstance(size_bytes, int) else length
    safe_updated = str(updated_at).replace(" ", "_")
    print(f"ok status=updated sha256={sha} bytes={size_label} updated_at={safe_updated}")
    sys.exit(0)

print(f"error reason=unknown-status:{status}")
sys.exit(1)
PY
}

sync_slash_commands_pull() {
  load_sync_config
  if [[ -z "$CODEX_SYNC_API_KEY" || -z "$CODEX_SYNC_BASE_URL" ]]; then
    PROMPT_SYNC_STATUS="missing-config"
    return 1
  fi
  if ! command -v python3 >/dev/null 2>&1; then
    PROMPT_SYNC_STATUS="no-python"
    log_warn "python3 is required for slash command sync; skipping."
    return 1
  fi
  local summary status_code
  set +e
  summary="$(prompt_sync_python pull "$CODEX_SYNC_BASE_URL" "$CODEX_SYNC_API_KEY" "$PROMPT_DIR" "$CODEX_SYNC_CA_FILE" "$PROMPT_BASELINE_FILE")"
  status_code=$?
  set -e
  PROMPT_SYNC_STATUS="error"
  if (( status_code != 0 )); then
    local reason=""
    if [[ "$summary" == error\ reason=* ]]; then
      reason="${summary#error reason=}"
    fi
    if [[ "$reason" == http-5* ]] || [[ "$reason" == request_failed* ]]; then
      PROMPT_SYNC_STATUS="offline"
      PROMPT_SYNC_REASON="$reason"
      [[ -n "$summary" ]] && log_warn "Slash command sync offline: $summary" || log_warn "Slash command sync offline."
      PROMPT_PULL_ERRORS=0
    else
      [[ -n "$summary" ]] && log_warn "Slash command sync failed: $summary" || log_warn "Slash command sync failed."
      PROMPT_PULL_ERRORS=1
    fi
    return 1
  fi
  local part
  PROMPT_SYNC_REASON=""
  PROMPT_SYNC_STATUS="${summary%% *}"
  for part in $summary; do
    case "$part" in
      updated=*) PROMPT_PULL_UPDATED="${part#updated=}" ;;
      errors=*) PROMPT_PULL_ERRORS="${part#errors=}" ;;
      remote=*) PROMPT_REMOTE_COUNT="${part#remote=}" ;;
      local=*) PROMPT_LOCAL_COUNT="${part#local=}" ;;
      removed=*) PROMPT_REMOVED="${part#removed=}" ;;
    esac
  done
  return 0
}

sync_agents_pull() {
  load_sync_config
  if [[ -z "$CODEX_SYNC_API_KEY" || -z "$CODEX_SYNC_BASE_URL" ]]; then
    AGENTS_SYNC_STATUS="missing-config"
    return 1
  fi
  if ! command -v python3 >/dev/null 2>&1; then
    AGENTS_SYNC_STATUS="no-python"
    if (( SYNC_WARNED_NO_PYTHON == 0 )); then
      log_warn "python3 is required for AGENTS.md sync; skipping."
      SYNC_WARNED_NO_PYTHON=1
    fi
    return 1
  fi
  local current_sha=""
  if [[ -f "$AGENTS_PATH" ]]; then
    current_sha="$(python3 - "$AGENTS_PATH" <<'PY'
import hashlib, pathlib, sys
path = pathlib.Path(sys.argv[1])
try:
    print(hashlib.sha256(path.read_bytes()).hexdigest())
except Exception:
    pass
PY
)"
  fi
  local summary status_code
  set +e
  summary="$(agents_sync_python "$CODEX_SYNC_BASE_URL" "$CODEX_SYNC_API_KEY" "$AGENTS_PATH" "$CODEX_SYNC_CA_FILE" "$current_sha")"
  status_code=$?
  set -e
  AGENTS_SYNC_STATUS="error"
  AGENTS_STATE=""
  AGENTS_REMOTE_SHA=""
  AGENTS_REMOTE_UPDATED_AT=""
  AGENTS_REMOTE_BYTES=""
  AGENTS_REMOVED=0
  if (( status_code != 0 )); then
    local reason=""
    if [[ "$summary" == error\ reason=* ]]; then
      reason="${summary#error reason=}"
    fi
    if [[ "$reason" == http-5* ]] || [[ "$reason" == request_failed* ]]; then
      AGENTS_SYNC_STATUS="offline"
      AGENTS_SYNC_REASON="$reason"
    else
      AGENTS_SYNC_STATUS="error"
      AGENTS_SYNC_REASON="$reason"
    fi
    return 1
  fi
  AGENTS_SYNC_STATUS="${summary%% *}"
  AGENTS_SYNC_REASON=""
  local part
  for part in $summary; do
    case "$part" in
      status=*) AGENTS_STATE="${part#status=}" ;;
      sha256=*) AGENTS_REMOTE_SHA="${part#sha256=}" ;;
      updated_at=*) AGENTS_REMOTE_UPDATED_AT="${part#updated_at=}" ;;
      bytes=*) AGENTS_REMOTE_BYTES="${part#bytes=}" ;;
      removed=*) AGENTS_REMOVED="${part#removed=}" ;;
    esac
  done
  return 0
}

config_sync_python() {
  local base="$1"
  local api_key="$2"
  local target_file="$3"
  local cafile="$4"
  local current_sha="$5"
  CODEX_SYNC_API_KEY="$api_key" python3 - "$base" "$target_file" "$cafile" "$current_sha" <<'PY'
import hashlib, json, os, pathlib, ssl, sys, urllib.error, urllib.request

base = (sys.argv[1] or "").rstrip("/")
target = pathlib.Path(sys.argv[2]).expanduser()
cafile = sys.argv[3] if len(sys.argv) > 3 else ""
current_sha = (sys.argv[4] or "").strip() if len(sys.argv) > 4 else ""
api_key = os.environ.get("CODEX_SYNC_API_KEY", "")


def contexts():
    ctxs = []
    primary = ssl.create_default_context()
    if cafile:
        try:
            primary.load_verify_locations(cafile)
        except Exception:
            primary = None
    if primary is not None:
        try:
            primary.verify_flags &= ~ssl.VERIFY_X509_STRICT
        except AttributeError:
            pass
        ctxs.append(primary)
    try:
        fallback = ssl.create_default_context()
        fallback.verify_flags &= ~ssl.VERIFY_X509_STRICT
        ctxs.append(fallback)
    except Exception:
        pass
    allow_insecure = os.environ.get("CODEX_SYNC_ALLOW_INSECURE", "").lower() in ("1", "true", "yes")
    if allow_insecure:
        try:
            ctxs.append(ssl._create_unverified_context())
        except Exception:
            pass
    return ctxs or [None]


def request_json(method: str, url: str, payload=None):
    data = None
    headers = {"X-API-Key": api_key}
    if payload is not None:
        data = json.dumps(payload, ensure_ascii=False, separators=(",", ":")).encode("utf-8")
        headers["Content-Type"] = "application/json"
    req = urllib.request.Request(url, data=data, headers=headers, method=method)
    last_err = None
    for ctx in contexts():
        try:
            with urllib.request.urlopen(req, timeout=20, context=ctx) as resp:
                return json.load(resp)
        except urllib.error.HTTPError as exc:  # noqa: PERF203
            body = exc.read().decode("utf-8", "ignore")
            reason = f"http-{exc.code}"
            if body:
                reason = f"{reason}:{body.strip()[:80]}"
            raise RuntimeError(reason) from exc
        except Exception as exc:  # noqa: BLE001
            last_err = exc
            continue
    raise RuntimeError(f"request failed: {last_err}")


if not base:
    print("error reason=missing-base")
    sys.exit(1)
if not api_key:
    print("error reason=missing-api-key")
    sys.exit(1)

payload = {}
if current_sha and len(current_sha) == 64:
    payload["sha256"] = current_sha

try:
    resp = request_json("POST", f"{base}/config/retrieve", payload)
except Exception as exc:  # noqa: BLE001
    print(f"error reason={str(exc).replace(' ', '_')}")
    sys.exit(1)

data = resp.get("data") if isinstance(resp, dict) else {}
status = (data or {}).get("status")
sha = (data or {}).get("sha256") or ""
content = (data or {}).get("content")
updated_at = (data or {}).get("updated_at") or ""
size_bytes = data.get("size_bytes") if isinstance(data, dict) else None

if status == "missing":
    removed = 0
    try:
        if target.exists():
            target.unlink()
            removed = 1
    except Exception:
        pass
    print(f"ok status=missing removed={removed}")
    sys.exit(0)

if status == "unchanged":
    print(f"ok status=unchanged sha256={sha}")
    sys.exit(0)

if status == "updated":
    if not isinstance(content, str):
        print("error reason=missing-content")
        sys.exit(1)
    try:
        target.parent.mkdir(parents=True, exist_ok=True)
        target.write_text(content, encoding="utf-8")
    except Exception as exc:  # noqa: BLE001
        print(f"error reason=write-failed:{str(exc).replace(' ', '_')}")
        sys.exit(1)
    length = len(content.encode("utf-8"))
    size_label = size_bytes if isinstance(size_bytes, int) else length
    safe_updated = str(updated_at).replace(" ", "_")
    print(f"ok status=updated sha256={sha} bytes={size_label} updated_at={safe_updated}")
    sys.exit(0)

print(f"error reason=unknown-status:{status}")
sys.exit(1)
PY
}

sync_config_pull() {
  load_sync_config
  if [[ -z "$CODEX_SYNC_API_KEY" || -z "$CODEX_SYNC_BASE_URL" ]]; then
    CONFIG_SYNC_STATUS="missing-config"
    return 1
  fi
  if ! command -v python3 >/dev/null 2>&1; then
    CONFIG_SYNC_STATUS="no-python"
    if (( SYNC_WARNED_NO_PYTHON == 0 )); then
      log_warn "python3 is required for config.toml sync; skipping."
      SYNC_WARNED_NO_PYTHON=1
    fi
    return 1
  fi
  local current_sha=""
  if [[ -f "$CONFIG_PATH" ]]; then
    current_sha="$(python3 - "$CONFIG_PATH" <<'PY'
import hashlib, pathlib, sys
path = pathlib.Path(sys.argv[1])
try:
    print(hashlib.sha256(path.read_bytes()).hexdigest())
except Exception:
    pass
PY
)"
  fi
  local summary status_code
  set +e
  summary="$(config_sync_python "$CODEX_SYNC_BASE_URL" "$CODEX_SYNC_API_KEY" "$CONFIG_PATH" "$CODEX_SYNC_CA_FILE" "$current_sha")"
  status_code=$?
  set -e
  CONFIG_SYNC_STATUS="error"
  CONFIG_STATE=""
  CONFIG_REMOTE_SHA=""
  CONFIG_REMOTE_UPDATED_AT=""
  CONFIG_REMOTE_BYTES=""
  CONFIG_REMOVED=0
  if (( status_code != 0 )); then
    local reason=""
    if [[ "$summary" == error\ reason=* ]]; then
      reason="${summary#error reason=}"
    fi
    if [[ "$reason" == http-5* ]] || [[ "$reason" == request_failed* ]]; then
      CONFIG_SYNC_STATUS="offline"
      CONFIG_SYNC_REASON="$reason"
    else
      CONFIG_SYNC_STATUS="error"
      CONFIG_SYNC_REASON="$reason"
    fi
    return 1
  fi
  CONFIG_SYNC_STATUS="${summary%% *}"
  CONFIG_SYNC_REASON=""
  local part
  for part in $summary; do
    case "$part" in
      status=*) CONFIG_STATE="${part#status=}" ;;
      sha256=*) CONFIG_REMOTE_SHA="${part#sha256=}" ;;
      updated_at=*) CONFIG_REMOTE_UPDATED_AT="${part#updated_at=}" ;;
      bytes=*) CONFIG_REMOTE_BYTES="${part#bytes=}" ;;
      removed=*) CONFIG_REMOVED="${part#removed=}" ;;
    esac
  done
  return 0
}

otel_env_from_config_python() {
  python3 - "$CONFIG_PATH" <<'PY'
import os, re, sys

path = sys.argv[1]
try:
    raw = open(path, "r", encoding="utf-8", errors="ignore").read()
except Exception:
    sys.exit(0)

def find_block(name: str) -> str:
    m = re.search(r'(?m)^\\[' + re.escape(name) + r'\\]\\s*$', raw)
    if not m:
        return ""
    start = m.end()
    m2 = re.search(r'(?m)^\\[', raw[start:])
    end = start + (m2.start() if m2 else len(raw[start:]))
    return raw[start:end]

block = find_block("otel")
if not block.strip():
    sys.exit(0)

def parse_value(v: str):
    v = v.strip()
    if v.startswith('"') and v.endswith('"'):
        return v[1:-1]
    if v.lower() in ("true", "false"):
        return v.lower()
    return v

def parse_inline_table(v: str):
    # Very small TOML-ish parser for { k = "v", ... } used by our builder.
    v = v.strip()
    if not (v.startswith("{") and v.endswith("}")):
        return {}
    inner = v[1:-1].strip()
    if not inner:
        return {}
    parts = []
    buf = ""
    in_str = False
    esc = False
    for ch in inner:
        if esc:
            buf += ch
            esc = False
            continue
        if ch == "\\":
            buf += ch
            esc = True
            continue
        if ch == '"':
            in_str = not in_str
            buf += ch
            continue
        if ch == "," and not in_str:
            parts.append(buf)
            buf = ""
        else:
            buf += ch
    if buf.strip():
        parts.append(buf)
    out = {}
    for part in parts:
        if "=" not in part:
            continue
        k, val = part.split("=", 1)
        k = k.strip()
        out[k] = parse_value(val)
    return out

otel = {}
for line in block.splitlines():
    line = line.strip()
    if not line or line.startswith("#") or "=" not in line:
        continue
    k, v = line.split("=", 1)
    k = k.strip()
    otel[k] = v.strip()

exporter = parse_value(otel.get("exporter", "")).strip()
environment = parse_value(otel.get("environment", "")).strip()
log_prompts = parse_value(otel.get("log_user_prompt", "")).strip()

if exporter in ("", "none"):
    sys.exit(0)

endpoint = parse_value(otel.get("endpoint", "")).strip()
protocol = parse_value(otel.get("protocol", "")).strip()
headers = parse_inline_table(otel.get("headers", "{}"))

def emit(k: str, v: str):
    if v is None:
        return
    v = str(v).strip()
    if v == "":
        return
    print(f"{k}={v}")

# Emit env vars as k=v lines; shell will export them.
emit("OTEL_SERVICE_NAME", "cdx")
if environment:
    emit("OTEL_RESOURCE_ATTRIBUTES", f"deployment.environment={environment}")

if exporter == "otlp-http":
    emit("OTEL_TRACES_EXPORTER", "otlp")
    emit("OTEL_EXPORTER_OTLP_PROTOCOL", protocol or "http/protobuf")
    if endpoint:
        emit("OTEL_EXPORTER_OTLP_ENDPOINT", endpoint)
elif exporter == "otlp-grpc":
    emit("OTEL_TRACES_EXPORTER", "otlp")
    emit("OTEL_EXPORTER_OTLP_PROTOCOL", "grpc")
    if endpoint:
        emit("OTEL_EXPORTER_OTLP_ENDPOINT", endpoint)

if headers:
    # OTEL expects comma-separated key=value
    header_str = ",".join([f"{k}={v}" for k, v in headers.items() if str(k).strip() and str(v).strip()])
    emit("OTEL_EXPORTER_OTLP_HEADERS", header_str)

# Optional: prompt logging toggle. We expose as CODEX wrapper env, not OpenTelemetry standard.
if log_prompts in ("true", "false"):
    emit("CODEX_OTEL_LOG_USER_PROMPT", log_prompts)
PY
}

push_slash_commands_if_changed() {
  load_sync_config
  if [[ -z "$CODEX_SYNC_API_KEY" || -z "$CODEX_SYNC_BASE_URL" ]]; then
    PROMPT_PUSH_STATUS="missing-config"
    return 0
  fi
  if [[ ! -f "$PROMPT_BASELINE_FILE" ]]; then
    PROMPT_PUSH_STATUS="no-baseline"
    return 0
  fi
  if ! command -v python3 >/dev/null 2>&1; then
    PROMPT_PUSH_STATUS="no-python"
    return 0
  fi
  local summary status_code
  set +e
  summary="$(prompt_sync_python push "$CODEX_SYNC_BASE_URL" "$CODEX_SYNC_API_KEY" "$PROMPT_DIR" "$CODEX_SYNC_CA_FILE" "$PROMPT_BASELINE_FILE")"
  status_code=$?
  set -e
  PROMPT_PUSH_STATUS="error"
  if (( status_code != 0 )); then
    [[ -n "$summary" ]] && log_warn "Slash command push failed: $summary" || log_warn "Slash command push failed."
    PROMPT_PUSH_ERRORS=1
    return 1
  fi
  local part
  PROMPT_PUSH_STATUS="${summary%% *}"
  for part in $summary; do
    case "$part" in
      pushed=*) PROMPT_PUSHED="${part#pushed=}" ;;
      errors=*) PROMPT_PUSH_ERRORS="${part#errors=}" ;;
      changes=*) PROMPT_LOCAL_CHANGED="${part#changes=}" ;;
      local=*) PROMPT_LOCAL_COUNT="${part#local=}" ;;
    esac
  done
  return 0
}

extract_token_usage_payload() {
  local log_path="$1"
  if [[ ! -f "$log_path" ]]; then
    return 0
  fi
  if ! command -v python3 >/dev/null 2>&1; then
    return 0
  fi
  python3 - "$log_path" <<'PY'
import json, pathlib, re, sys

path = pathlib.Path(sys.argv[1])
try:
    content = path.read_text(encoding="utf-8", errors="ignore")
except Exception:  # noqa: BLE001
    sys.exit(0)

ansi_csi = re.compile(r"\x1B\[[0-9;?]*[ -/]*[@-~]")
ansi_osc = re.compile(r"\x1B\][^\a\x1b]*[\a\x1b\\]")
control = re.compile(r"[\x00-\x08\x0b\x0c\x0e-\x1f\x7f]")


def strip_noise(text: str) -> str:
    text = ansi_osc.sub("", text)
    text = ansi_csi.sub("", text)
    text = control.sub("", text)
    return text


cleaned = strip_noise(content)
lines = [ln.strip() for ln in cleaned.splitlines() if "token usage" in ln.lower()]
if not lines:
    sys.exit(0)

pattern = re.compile(
    r"Token usage:\s*total=(?P<total>[\d,]+)\s+input=(?P<input>[\d,]+)(?:\s*\(\+\s*(?P<cached>[\d,]+)\s*cached\))?\s+output=(?P<output>[\d,]+)(?:\s*\(reasoning\s*(?P<reasoning>[\d,]+)\))?",
    re.IGNORECASE,
)
kv_pattern = re.compile(r"\b(total|input|output|cached|reasoning)\s*[:=]\s*([\d,][\d,]*)", re.IGNORECASE)


def clean_int(val):
    if val is None:
        return None
    try:
        return int(val.replace(",", ""))
    except Exception:
        return None


entries = []
for raw in lines:
    entry = {}
    safe_line = raw.strip()
    if len(safe_line) > 240:
        safe_line = safe_line[:240] + "…"

    match = pattern.search(raw)
    if match:
        entry["total"] = clean_int(match.group("total"))
        entry["input"] = clean_int(match.group("input"))
        entry["output"] = clean_int(match.group("output"))
        cached_val = clean_int(match.group("cached"))
        if cached_val is not None:
            entry["cached"] = cached_val
        reasoning_val = clean_int(match.group("reasoning"))
        if reasoning_val is not None:
            entry["reasoning"] = reasoning_val
    else:
        for key, value in kv_pattern.findall(raw):
            cleaned_val = clean_int(value)
            if cleaned_val is not None:
                entry[key.lower()] = cleaned_val
        cached_match = re.search(r"\(\+\s*([\d,]+)\s*cached", raw, re.IGNORECASE)
        if cached_match:
            cached_val = clean_int(cached_match.group(1))
            if cached_val is not None:
                entry["cached"] = cached_val

    if safe_line:
        entry["line"] = safe_line

    if entry:
        entries.append(entry)

if not entries:
    sys.exit(0)

print(json.dumps({"usages": entries}, separators=(",", ":")))
PY
}

post_token_usage_payload() {
  local payload_json="$1"
  if [[ -z "$payload_json" ]]; then
    return 0
  fi
  if [[ -z "$CODEX_SYNC_API_KEY" || -z "$CODEX_SYNC_BASE_URL" ]]; then
    log_warn "Usage push skipped: API key or base URL missing"
    return 1
  fi
  if ! command -v python3 >/dev/null 2>&1; then
    log_warn "Usage push skipped: python3 missing"
    return 1
  fi

  local summary=""
  local status=0
  summary="$(CODEX_SYNC_API_KEY="$CODEX_SYNC_API_KEY" python3 - "$CODEX_SYNC_BASE_URL" "$payload_json" "$CODEX_SYNC_CA_FILE" <<'PY'
import json, os, ssl, sys, urllib.error, urllib.request

base = (sys.argv[1] or "").rstrip("/")
payload_raw = sys.argv[2]
cafile = sys.argv[3] if len(sys.argv) > 3 else ""
api_key = os.environ.get("CODEX_SYNC_API_KEY", "")

try:
    payload = json.loads(payload_raw)
except Exception:  # noqa: BLE001
    sys.exit(1)

body = json.dumps(payload, separators=(",", ":")).encode("utf-8")
headers = {"Content-Type": "application/json", "X-API-Key": api_key}
url = f"{base}/usage"
req = urllib.request.Request(url, data=body, headers=headers, method="POST")


def build_contexts():
    contexts = []
    try:
        ctx = ssl.create_default_context()
        if cafile:
            ctx.load_verify_locations(cafile)
        try:
            ctx.verify_flags &= ~ssl.VERIFY_X509_STRICT
        except Exception:
            pass
        contexts.append(ctx)
    except Exception:
        pass
    allow_insecure = os.environ.get("CODEX_SYNC_ALLOW_INSECURE", "").lower() in ("1", "true", "yes")
    if allow_insecure:
        try:
            contexts.append(ssl._create_unverified_context())
        except Exception:
            pass
    return contexts or [None]


def format_summary(data: dict) -> str:
    def summarize(entry: dict) -> str:
        parts = []
        for key in ("total", "input", "output", "cached", "reasoning"):
            if isinstance(entry.get(key), int):
                parts.append(f"{key}={entry[key]}")
        if not parts and entry.get("line"):
            return entry["line"]
        return " ".join(parts)

    usages = data.get("usages")
    if isinstance(usages, list) and usages:
        latest = usages[-1] if isinstance(usages[-1], dict) else {}
        summary = summarize(latest if isinstance(latest, dict) else {})
        if len(usages) > 1:
            return f"{len(usages)} rows" + (f" | {summary}" if summary else "")
        return summary

    parts = []
    for key in ("total", "input", "output", "cached", "reasoning"):
        if key in data and data[key] is not None:
            parts.append(f"{key}={data[key]}")
    if not parts and data.get("line"):
        return data["line"]
    return " ".join(parts)


last_err = None
last_code = 1
for ctx in build_contexts():
    try:
        with urllib.request.urlopen(req, timeout=10, context=ctx) as resp:  # noqa: S310
            resp.read(512)
            print(format_summary(payload))
            sys.exit(0)
    except urllib.error.HTTPError as exc:
        body = ""
        try:
            body = exc.read().decode("utf-8", "replace")
        except Exception:
            body = ""
        if exc.code == 503 and "disabled" in body.lower():
            print("api disabled")
            sys.exit(40)
        body_snip = (body or "").replace("\n", " ").strip()
        if len(body_snip) > 160:
            body_snip = body_snip[:160] + "…"
        last_err = f"HTTP {exc.code}" + (f": {body_snip}" if body_snip else "")
        last_code = exc.code or 1
        continue
    except Exception as exc:  # noqa: BLE001
        last_err = str(exc)
        continue

if last_err:
    print(last_err)
sys.exit(last_code)
PY
  )" || status=$?
  if (( status == 0 )); then
    log_info "Usage push | ok | ${summary}"
    return 0
  fi

  if (( status == 40 )); then
    log_warn "Usage push skipped: API disabled by administrator"
    return 0
  fi

  local primary_err="$summary"

  # Fallback: retry without the freeform line if present (avoid bad payloads/escape debris)
  if [[ "$payload_json" == *'"line"'* ]]; then
    local fallback_payload=""
    fallback_payload="$(python3 - "$payload_json" <<'PY'
import json, sys
try:
    data = json.loads(sys.argv[1])
except Exception:  # noqa: BLE001
    sys.exit(1)
if "line" in data:
    data.pop("line", None)
usages = data.get("usages")
if isinstance(usages, list):
    cleaned = []
    for entry in usages:
        if isinstance(entry, dict):
            entry.pop("line", None)
            if entry:
                cleaned.append(entry)
    data["usages"] = cleaned
print(json.dumps(data, separators=(",", ":")))
PY
    )" || fallback_payload=""
    if [[ -n "$fallback_payload" && "$fallback_payload" != "$payload_json" ]]; then
      summary=""
      status=0
      summary="$(CODEX_SYNC_API_KEY="$CODEX_SYNC_API_KEY" python3 - "$CODEX_SYNC_BASE_URL" "$fallback_payload" "$CODEX_SYNC_CA_FILE" <<'PY'
import json, os, ssl, sys, urllib.error, urllib.request

base = (sys.argv[1] or "").rstrip("/")
payload_raw = sys.argv[2]
cafile = sys.argv[3] if len(sys.argv) > 3 else ""
api_key = os.environ.get("CODEX_SYNC_API_KEY", "")

payload = json.loads(payload_raw)
body = json.dumps(payload, separators=(",", ":")).encode("utf-8")
headers = {"Content-Type": "application/json", "X-API-Key": api_key}
url = f"{base}/usage"
req = urllib.request.Request(url, data=body, headers=headers, method="POST")

ctx = ssl.create_default_context()
if cafile:
    try:
        ctx.load_verify_locations(cafile)
    except Exception:
        pass
try:
    with urllib.request.urlopen(req, timeout=10, context=ctx) as resp:  # noqa: S310
        resp.read(512)
        print("fallback")
        sys.exit(0)
except urllib.error.HTTPError as exc:  # noqa: PERF203
    body = ""
    try:
        body = exc.read().decode("utf-8", "replace")
    except Exception:
        body = ""
    if exc.code == 503 and "disabled" in body.lower():
        print("api disabled")
        sys.exit(40)
    print(str(exc))
    sys.exit(1)
except Exception as exc:  # noqa: BLE001
    print(str(exc))
    sys.exit(1)
PY
      )" || status=$?
      if (( status == 0 )); then
        log_info "Usage push | ok (fallback) | ${summary}"
        return 0
      elif (( status == 40 )); then
        log_warn "Usage push skipped: API disabled by administrator"
        return 0
      fi
      [[ -z "$primary_err" ]] && primary_err="$summary"
    fi
  fi

  if [[ -z "$primary_err" ]]; then
    primary_err="unknown error"
  fi
  log_warn "Usage push | failed | ${primary_err}"
  return 1
}

parse_usage_summary() {
  local payload_json="$1"
  local summary=""
  summary="$(python3 - "$payload_json" <<'PY'
import json, sys
try:
    data = json.loads(sys.argv[1])
except Exception:  # noqa: BLE001
    sys.exit(0)

usages = data.get("usages")
entry = {}
if isinstance(usages, list) and usages:
    last = usages[-1]
    if isinstance(last, dict):
        entry = last
else:
    entry = data if isinstance(data, dict) else {}

parts = []
total = entry.get("total")
inp = entry.get("input")
out = entry.get("output")
cached = entry.get("cached")
reasoning = entry.get("reasoning")
if isinstance(total, int):
    parts.append(f"sent={total}")
if isinstance(inp, int):
    parts.append(f"input={inp}")
if isinstance(out, int):
    parts.append(f"output={out}")
if isinstance(cached, int):
    parts.append(f"cached={cached}")
if isinstance(reasoning, int):
    parts.append(f"reasoning={reasoning}")
if isinstance(usages, list) and len(usages) > 1:
    parts.append(f"rows={len(usages)}")
if parts:
    print(", ".join(parts))
PY
  )" || summary=""
  printf "%s" "$summary"
}

send_token_usage_if_present() {
  local log_path="$1"
  local payload
  payload="$(extract_token_usage_payload "$log_path")" || return 0
  if [[ -z "$payload" ]]; then
    return 0
  fi

  last_usage_payload="$payload"
  post_token_usage_payload "$payload" || true
}


fetch_release_payload() {
  local api_url="$1"
  local wanted_asset="$2"
  python3 - "$api_url" "$wanted_asset" <<'PY'
import json, sys, time, urllib.request
url = sys.argv[1]
wanted = sys.argv[2]
headers = {
    "Accept": "application/vnd.github+json",
    "User-Agent": "codex-wrapper-update-check"
}
try:
    req = urllib.request.Request(url, headers=headers)
    with urllib.request.urlopen(req, timeout=15) as resp:
        data = json.load(resp)
except Exception as exc:  # noqa: BLE001
    print(f"error: {exc}", file=sys.stderr)
    sys.exit(1)
name = data.get("name") or data.get("tag_name") or ""
assets = data.get("assets") or []
asset = None
if wanted:
    for candidate in assets:
        if candidate.get("name") == wanted:
            asset = candidate
            break
if asset is None:
    for candidate in assets:
        if candidate.get("name") == "codex":
            asset = candidate
            break
if asset is None:
    print("error: could not find a matching release asset", file=sys.stderr)
    sys.exit(2)
payload = {
    "timestamp": int(time.time()),
    "version": name,
    "tag": data.get("tag_name") or "",
    "asset_name": asset.get("name", ""),
    "download_url": asset.get("browser_download_url", "")
}
json.dump(payload, sys.stdout, separators=(",", ":"))
PY
}

read_cached_payload() {
  local cache_file="$1"
  python3 - "$cache_file" <<'PY'
import json, sys
with open(sys.argv[1], 'r', encoding='utf-8') as fh:
    data = json.load(fh)
print(data.get('version', ''))
print(data.get('download_url', ''))
print(data.get('asset_name', ''))
print(data.get('timestamp', 0))
print(data.get('tag', ''))
PY
}

perform_update() (
  set -euo pipefail
  local target_path="$1"
  local url="$2"
  local asset_name="$3"
  local new_version="$4"
  local tmpdir
  tmpdir="$(mktemp -d)"
  trap 'rm -rf "$tmpdir"' EXIT
  log_info "Downloading Codex ${new_version}"
  local asset_file="$tmpdir/asset"
  if ! curl -fsSL "$url" -o "$asset_file"; then
    log_error "Download failed from $url"
    exit 1
  fi
  local extracted="$asset_file"
  case "$asset_name" in
    *.tar.gz)
      tar -xzf "$asset_file" -C "$tmpdir"
      # pick the first executable named codex*
      extracted="$(find "$tmpdir" -type f -name 'codex*' ! -name 'asset' | head -n1)"
      ;;
    *.zip)
      if ! command -v unzip >/dev/null 2>&1; then
        log_error "unzip is required to handle $asset_name"
        exit 1
      fi
      unzip -q "$asset_file" -d "$tmpdir"
      extracted="$(find "$tmpdir" -type f -name 'codex*' | head -n1)"
      ;;
  esac
  if [[ -z "$extracted" || ! -f "$extracted" ]]; then
    log_error "Unable to locate Codex binary inside downloaded asset"
    exit 1
  fi
  chmod +x "$extracted"
  local target_dir
  target_dir="$(dirname "$target_path")"
  if [[ ! -d "$target_dir" ]]; then
    log_error "Target directory $target_dir does not exist"
    exit 1
  fi
  if [[ -w "$target_dir" ]]; then
    log_info "Installing Codex into $target_path"
    install -m 755 "$extracted" "$target_path"
  else
    if (( CAN_SUDO )); then
      log_info "Installing Codex into $target_path with sudo -n"
      $SUDO_BIN install -m 755 "$extracted" "$target_path"
    else
      log_warn "Insufficient permissions to install Codex into $target_path (no sudo)."
      exit 1
    fi
  fi
  log_info "Codex updated to ${new_version}"
)


API_RELEASES_URL="https://api.github.com/repos/openai/codex/releases"

SCRIPT_REAL="$(real_path "$0")"
CODEX_REAL_BIN="$(resolve_real_codex)"
if [[ -z "$CODEX_REAL_BIN" ]]; then
  log_error "Unable to find the real Codex binary on PATH"
  exit 1
fi

platform_os="$(uname -s 2>/dev/null || echo unknown)"
platform_arch="$(uname -m 2>/dev/null || echo unknown)"

can_manage_codex=0
if (( IS_ROOT )); then
  can_manage_codex=1
elif (( CAN_SUDO )); then
  can_manage_codex=1
fi

if (( can_manage_codex )) && [[ "$(uname -s)" == "Linux" ]]; then
  ensure_commands curl unzip
fi

LOCAL_VERSION_RAW="$("$CODEX_REAL_BIN" -V 2>/dev/null || true)"
LOCAL_VERSION="$(normalize_version "$LOCAL_VERSION_RAW")"
LOCAL_VERSION_UNKNOWN=0
if [[ -z "$LOCAL_VERSION" ]]; then
  LOCAL_VERSION_UNKNOWN=1
  log_warn "Could not determine local Codex version; attempting to refresh Codex before launch."
fi

# Early auth + versions sync (single POST), captures target versions and hydrates auth if needed.
sync_auth_with_api "pull" || true
sync_slash_commands_pull || true
sync_agents_pull || true
sync_config_pull || true
ORIGINAL_LAST_REFRESH="$(get_auth_last_refresh "$HOME/.codex/auth.json")"
LOCAL_AUTH_IS_FRESH=0
if is_last_refresh_recent "$ORIGINAL_LAST_REFRESH" "$MAX_LOCAL_AUTH_AGE_SECONDS"; then
  LOCAL_AUTH_IS_FRESH=1
fi
LOCAL_AUTH_IS_RECENT=0
if is_last_refresh_recent "$ORIGINAL_LAST_REFRESH" "${MAX_LOCAL_AUTH_RECENT_SECONDS:-$MAX_LOCAL_AUTH_AGE_SECONDS}"; then
  LOCAL_AUTH_IS_RECENT=1
fi
HAS_LOCAL_AUTH=0
[[ -f "$HOME/.codex/auth.json" ]] && HAS_LOCAL_AUTH=1

if (( ! CODEX_SKIP_MOTD )) && (( ! CODEX_SILENT )); then
  print_motd
fi

os_name="$(uname -s)"
arch_name="$(uname -m)"
asset_name=""
skip_update_check=0
if (( ! can_manage_codex )); then
  skip_update_check=1
fi
case "$os_name" in
  Linux)
	    case "$arch_name" in
	      x86_64|amd64)
	        asset_name="codex-x86_64-unknown-linux-gnu.tar.gz"
	        glibc_version="$(detect_glibc_version)"
	        if [[ -z "$glibc_version" ]]; then
	          asset_name="codex-x86_64-unknown-linux-musl.tar.gz"
	          if [[ "${CODEX_WRAPPER_RESTARTED:-0}" != "1" ]]; then
	            log_info "Unable to detect glibc version; using musl Codex build for compatibility."
	          fi
	        elif version_lt "$glibc_version" "2.39"; then
	          asset_name="codex-x86_64-unknown-linux-musl.tar.gz"
	          if [[ "${CODEX_WRAPPER_RESTARTED:-0}" != "1" ]]; then
	            log_info "glibc ${glibc_version} detected; using musl Codex build for compatibility."
	          fi
	        fi
	        ;;
      aarch64|arm64)
        asset_name="codex-aarch64-unknown-linux-gnu.tar.gz"
        ;;
      *)
        log_warn "Unsupported Linux architecture (${arch_name}); skipping update check."
        skip_update_check=1
        ;;
    esac
    ;;
  *)
    log_warn "Non-Linux operating system (${os_name}) detected; skipping update check."
    skip_update_check=1
    ;;
esac

remote_version=""
remote_url=""
remote_asset=""
remote_tag=""
remote_source=""
remote_timestamp=0
prefer_npm_update=0
enforce_exact_codex_version=0

if [[ "${SYNC_REMOTE_CLIENT_VERSION_SOURCE:-}" == "locked" ]]; then
  enforce_exact_codex_version=1
fi

if (( ! skip_update_check )); then
  if [[ "$AUTH_PULL_STATUS" == "ok" && -n "$SYNC_REMOTE_CLIENT_VERSION" ]]; then
    remote_version="$(normalize_version "$SYNC_REMOTE_CLIENT_VERSION")"
    remote_tag="$remote_version"
    remote_timestamp="$(date +%s)"
    remote_source="api"
  elif [[ "$AUTH_PULL_STATUS" == "ok" ]]; then
    # API succeeded but no version provided; assume local is target to avoid noisy warnings.
    remote_version="$LOCAL_VERSION"
    remote_tag="$LOCAL_VERSION"
    remote_source="api"
  fi
fi

need_update=0
norm_remote=""
if (( ! skip_update_check )) && [[ -n "$remote_version" ]]; then
  norm_remote="$(normalize_version "$remote_version")"
  if (( LOCAL_VERSION_UNKNOWN )); then
    need_update=1
  else
    norm_local="$(normalize_version "$LOCAL_VERSION")"
    if [[ "$norm_remote" != "$norm_local" ]]; then
      if (( enforce_exact_codex_version )); then
        need_update=1
      elif [[ "$(printf '%s\n%s\n' "$norm_local" "$norm_remote" | sort -V | tail -n1)" == "$norm_remote" ]]; then
        need_update=1
      fi
    fi
  fi
fi

if (( need_update )) && is_codex_installed_via_npm; then
  prefer_npm_update=1
fi

# If an update is needed but we don't yet have a download URL (e.g., version came from the API), fetch release metadata now.
if (( need_update )) && [[ -z "$remote_url" ]] && require_python; then
  tmp_payload="$(mktemp)"
  fetch_success=0
  candidate_tags=()
  add_tag() { local t="$1"; [[ -z "$t" ]] && return; for existing in "${candidate_tags[@]-}"; do [[ "$existing" == "$t" ]] && return; done; candidate_tags+=("$t"); }
  add_tag "$remote_tag"
  add_tag "$remote_version"
  add_tag "v${remote_version}"
  add_tag "rust-${remote_version}"
  add_tag "rust-v${remote_version}"

  for tag_variant in "${candidate_tags[@]}"; do
    if payload_json="$(fetch_release_payload "${API_RELEASES_URL}/tags/${tag_variant}" "$asset_name" 2>/dev/null)"; then
      printf '%s\n' "$payload_json" > "$tmp_payload"
      if mapfile -t fresh_fields < <(read_cached_payload "$tmp_payload"); then
        remote_version="${fresh_fields[0]}"
        remote_url="${fresh_fields[1]}"
        remote_asset="${fresh_fields[2]}"
        remote_timestamp="${fresh_fields[3]}"
        remote_tag="${fresh_fields[4]}"
        fetch_success=1
        break
      fi
    fi
  done
  rm -f "$tmp_payload"
  if (( fetch_success == 0 )); then
    log_warn "Could not fetch release metadata for Codex ${remote_tag}"
  fi
fi

codex_update_attempted=0
codex_updated=0
codex_update_failed=0
codex_status_label=""
codex_status_note=""
codex_target_label=""
codex_installed_label="${LOCAL_VERSION:-unknown}"

if (( skip_update_check )); then
  codex_target_label="${remote_version:-${LOCAL_VERSION:-unknown}}"
  codex_status_label="Check skipped"
  codex_status_note="not permitted to manage Codex (need root)"
elif (( need_update )) && [[ -n "$remote_url" ]]; then
  display_local="${LOCAL_VERSION:-unknown}"
  codex_target_label="$norm_remote"
  codex_update_attempted=1
  if (( prefer_npm_update )) && update_codex_via_npm "$norm_remote"; then
    hash -r
    CODEX_REAL_BIN="$(resolve_real_codex)"
    LOCAL_VERSION_RAW="$("$CODEX_REAL_BIN" -V 2>/dev/null || true)"
    LOCAL_VERSION="$(normalize_version "$LOCAL_VERSION_RAW")"
    LOCAL_VERSION_UNKNOWN=0
    codex_updated=1
    codex_status_label="Updated"
    codex_status_note="npm codex-cli @${norm_remote}"
  elif perform_update "$CODEX_REAL_BIN" "$remote_url" "${remote_asset:-$asset_name}" "$norm_remote"; then
    hash -r
    CODEX_REAL_BIN="$(resolve_real_codex)"
    LOCAL_VERSION_RAW="$("$CODEX_REAL_BIN" -V 2>/dev/null || true)"
    LOCAL_VERSION="$(normalize_version "$LOCAL_VERSION_RAW")"
    LOCAL_VERSION_UNKNOWN=0
    codex_updated=1
    codex_status_label="Updated"
    codex_status_note="from API ${remote_tag:-latest}"
  else
    codex_update_failed=1
    codex_status_label="Update failed"
    codex_status_note="to ${norm_remote}"
    log_warn "Codex update failed (wanted ${norm_remote}, local ${display_local})"
  fi
else
  if [[ -n "$remote_version" ]]; then
    final_label="${remote_tag:-${remote_version}}"
    codex_target_label="$final_label"
    local_norm="$(normalize_version "$LOCAL_VERSION")"
    remote_norm="$(normalize_version "$final_label")"
    if [[ -n "$local_norm" && -n "$remote_norm" && "$local_norm" != "$remote_norm" ]]; then
      codex_status_label="Update available"
    else
      codex_status_label="Current"
    fi
  else
    codex_status_label="API unavailable"
    codex_target_label="n/a"
    codex_update_failed=1
    log_warn "Codex update check unavailable"
  fi
fi

if [[ -z "$codex_status_label" ]]; then
  codex_status_label="Current"
fi
codex_installed_label="${LOCAL_VERSION:-unknown}"

WRAPPER_VERSION_INITIAL="$WRAPPER_VERSION"
wrapper_update_attempted=0
wrapper_updated=0
wrapper_update_failed=0
wrapper_status_label="Current"
wrapper_status_note=""
wrapper_target_label="$WRAPPER_VERSION"

# Wrapper self-update (single latest version only)
wrapper_state="current (${WRAPPER_VERSION})"
target_wrapper=""
target_wrapper_sha=""
target_wrapper_url=""
wrapper_target_label="$WRAPPER_VERSION"

if [[ "$AUTH_PULL_STATUS" == "ok" || "$CODEX_FORCE_WRAPPER_UPDATE" == "1" ]]; then
  target_wrapper="${SYNC_REMOTE_WRAPPER_VERSION:-${WRAPPER_VERSION}}"
  target_wrapper_sha="${SYNC_REMOTE_WRAPPER_SHA256:-}"
  target_wrapper_url="${SYNC_REMOTE_WRAPPER_URL:-}"
  wrapper_target_label="${target_wrapper:-$WRAPPER_VERSION}"

  if [[ -z "$target_wrapper_url" ]] && [[ -n "$CODEX_SYNC_BASE_URL" ]]; then
    target_wrapper_url="${CODEX_SYNC_BASE_URL%/}/wrapper/download"
  fi
  if [[ -n "$target_wrapper_url" && "$target_wrapper_url" != http* ]]; then
    target_wrapper_url="${CODEX_SYNC_BASE_URL%/}${target_wrapper_url}"
  fi

  need_wrapper_update=0
  if [[ -n "$target_wrapper" && "$target_wrapper" != "$WRAPPER_VERSION" ]]; then
    need_wrapper_update=1
  fi
  if (( need_wrapper_update == 0 )) && [[ -n "$target_wrapper_sha" ]]; then
    if current_wrapper_sha="$(sha256sum "$SCRIPT_REAL" 2>/dev/null | awk '{print $1}')" && [[ -n "$current_wrapper_sha" ]]; then
      if [[ "$current_wrapper_sha" != "$target_wrapper_sha" ]]; then
        need_wrapper_update=1
      fi
    fi
  fi
  if (( CODEX_FORCE_WRAPPER_UPDATE )); then
    need_wrapper_update=1
    wrapper_status_note="forced update requested"
  fi

  if (( need_wrapper_update )) && [[ -n "$target_wrapper_url" ]]; then
    wrapper_update_attempted=1
    if [[ -z "$CODEX_SYNC_API_KEY" ]]; then
      log_warn "Wrapper update skipped: API key missing"
      wrapper_update_failed=1
      wrapper_status_label="Update skipped"
      wrapper_status_note="API key missing"
    else
      tmpdir="$(mktemp -d)"
      tmpwrapper="$tmpdir/cdx"
      curl_args=(-fsSL -H "X-API-Key: $CODEX_SYNC_API_KEY")
      if [[ "$CODEX_FORCE_IPV4" == "1" ]]; then
        curl_args+=("-4")
      fi
      if [[ -n "$CODEX_SYNC_CA_FILE" ]]; then
        curl_args+=("--cacert" "$CODEX_SYNC_CA_FILE")
      fi
      if curl "${curl_args[@]}" "$target_wrapper_url" -o "$tmpwrapper"; then
        dl_sha="$(sha256sum "$tmpwrapper" | awk '{print $1}')"
        if [[ -n "$target_wrapper_sha" && "$dl_sha" != "$target_wrapper_sha" ]]; then
          log_warn "Wrapper update skipped: hash mismatch (expected ${target_wrapper_sha}, got ${dl_sha})"
          wrapper_update_failed=1
          wrapper_status_label="Update skipped"
          wrapper_status_note="hash mismatch"
        else
          chmod +x "$tmpwrapper"
          if [[ -w "$(dirname "$SCRIPT_REAL")" ]]; then
            install -m 755 "$tmpwrapper" "$SCRIPT_REAL"
            WRAPPER_VERSION="$target_wrapper"
            wrapper_state="updated (${WRAPPER_VERSION})"
            wrapper_updated=1
            wrapper_status_label="Updated"
            if [[ "$WRAPPER_VERSION_INITIAL" != "$WRAPPER_VERSION" ]]; then
              wrapper_status_note="${wrapper_status_note:-from ${WRAPPER_VERSION_INITIAL}}"
            fi
          elif (( CAN_SUDO )); then
            if $SUDO_BIN install -m 755 "$tmpwrapper" "$SCRIPT_REAL"; then
              WRAPPER_VERSION="$target_wrapper"
              wrapper_state="updated (${WRAPPER_VERSION})"
              wrapper_updated=1
              wrapper_status_label="Updated"
              if [[ "$WRAPPER_VERSION_INITIAL" != "$WRAPPER_VERSION" ]]; then
                wrapper_status_note="${wrapper_status_note:-from ${WRAPPER_VERSION_INITIAL}}"
              fi
            else
              log_warn "Wrapper update failed: sudo install denied"
              wrapper_update_failed=1
              wrapper_status_label="Update failed"
              wrapper_status_note="sudo install denied"
            fi
          else
            log_warn "Wrapper update skipped: insufficient permissions to write $(dirname "$SCRIPT_REAL")"
            wrapper_update_failed=1
            wrapper_status_label="Update skipped"
            wrapper_status_note="no permission"
          fi
        fi
      else
        log_warn "Wrapper update failed: download error"
        wrapper_update_failed=1
        wrapper_status_label="Update failed"
        wrapper_status_note="download error"
      fi
      rm -rf "$tmpdir"
    fi
  elif (( need_wrapper_update )) && [[ -z "$target_wrapper_url" ]]; then
    log_warn "Wrapper update skipped: API did not provide download URL"
    wrapper_update_failed=1
    wrapper_status_label="Update skipped"
    wrapper_status_note="missing download URL"
  fi
fi

if (( CODEX_EXIT_AFTER_UPDATE )); then
  if (( wrapper_updated )); then
    log_info "Wrapper update completed (version ${WRAPPER_VERSION})."
    exit 0
  fi
  if (( wrapper_update_failed )); then
    log_error "Wrapper update failed (${wrapper_status_note:-unknown})."
    exit 1
  fi
  log_warn "Wrapper update not attempted (status ${wrapper_status_label})."
  exit 1
fi

human_join() {
  local items=("$@")
  local count=${#items[@]}
  if (( count == 0 )); then
    printf ''
  elif (( count == 1 )); then
    printf '%s' "${items[0]}"
  elif (( count == 2 )); then
    printf '%s and %s' "${items[0]}" "${items[1]}"
  else
    local last="${items[count-1]}"
    items=("${items[@]:0:count-1}")
    printf '%s, and %s' "$(printf '%s, ' "${items[@]}" | sed 's/, $//')" "$last"
  fi
}

join_with_semicolon() {
  local out=""
  local part
  for part in "$@"; do
    [[ -z "$part" ]] && continue
    if [[ -n "$out" ]]; then
      out+="; "
    fi
    out+="$part"
  done
  printf "%s" "$out"
}

colorize() {
  local text="$1" tone="$2"
  case "$tone" in
    green) printf "%b%s%b" "${GREEN}${BOLD}" "$text" "${RESET}" ;;
    yellow) printf "%b%s%b" "${YELLOW}${BOLD}" "$text" "${RESET}" ;;
    orange) printf "%b%s%b" "${ORANGE}${BOLD}" "$text" "${RESET}" ;;
    red) printf "%b%s%b" "${RED}${BOLD}" "$text" "${RESET}" ;;
    *) printf "%s" "$text" ;;
  esac
}

ROW_LABEL_WIDTH=12
ROW_VALUE_WIDTH=32
QUOTA_BAR_WIDTH=24

format_status_row() {
  local label="$1" installed="$2" target="$3" status="$4"
  local v1="$installed" v2="$target"
  [[ "$v1" == *" installed" ]] && v1="${v1% installed}"
  [[ "$v2" == *" available" ]] && v2="${v2% available}"
  [[ "$v2" == "n/a" || "$v2" == "unknown" ]] && v2=""
  local ver="$v1"
  if [[ -n "$v2" && "$v2" != "$v1" ]]; then
    ver="${v1} → ${v2}"
  fi
  local msg="$ver"
  [[ -n "$status" ]] && msg="${msg} · ${status}"
  format_simple_row "$label" "$msg"
}

format_simple_row() {
  local label="$1" text="$2"
  if [[ -t 1 && "$text" != *$'\033['* ]]; then
    local cols="${COLUMNS:-}"
    if [[ ! "$cols" =~ ^[0-9]+$ ]] && command -v tput >/dev/null 2>&1; then
      cols="$(tput cols 2>/dev/null || true)"
    fi
    if [[ "$cols" =~ ^[0-9]+$ ]]; then
      local max=$(( cols - ROW_LABEL_WIDTH - 5 ))
      if (( max >= 20 )) && (( ${#text} > max )); then
        local first=1 chunk
        while IFS= read -r chunk; do
          if (( first )); then
            printf "%-${ROW_LABEL_WIDTH}s | %s" "$label" "$chunk"
            first=0
          else
            printf "\n%-${ROW_LABEL_WIDTH}s | %s" "" "$chunk"
          fi
        done <<< "$(fold -s -w "$max" <<< "$text")"
        return
      fi
    fi
  fi
  printf "%-${ROW_LABEL_WIDTH}s | %s" "$label" "$text"
}

format_quota_row() {
  local label="$1" text="$2" note="$3"
  if [[ -n "$note" ]]; then
    printf "%-${ROW_LABEL_WIDTH}s | %s\n%${ROW_LABEL_WIDTH}s | %s" "$label" "$text" "" "$note"
  else
    printf "%-${ROW_LABEL_WIDTH}s | %s" "$label" "$text"
  fi
}

join_with_sep() {
  local sep="$1"; shift
  local out="" part
  for part in "$@"; do
    [[ -z "$part" ]] && continue
    if [[ -n "$out" ]]; then
      out+="$sep"
    fi
    out+="$part"
  done
  printf "%s" "$out"
}

status_icon() {
  case "$1" in
    green) printf "✅" ;;
    yellow) printf "⚠" ;;
    red) printf "⛔" ;;
    *) printf "•" ;;
  esac
}

format_core_entry() {
  local name="$1" tone="$2" detail="${3-}" note="${4-}"
  local icon
  icon="$(status_icon "$tone")"
  local text="$name $icon"
  if [[ -n "$detail" ]]; then
    if [[ "$tone" == "green" ]]; then
      text+=" $detail"
    else
      text+=" $(colorize "$detail" "$tone")"
    fi
  elif [[ -n "$note" ]]; then
    text+=" $note"
  fi
  printf "%s" "$text"
}

toml_table_enabled() {
  local path="$1" table="$2"
  [[ -f "$path" ]] || return 2
  local header="[$table]"
  awk -v header="$header" '
    function trim(s) { sub(/^[[:space:]]+/, "", s); sub(/[[:space:]]+$/, "", s); return s }
    BEGIN { in_table=0; found=0; disabled=0 }
    {
      line = trim($0)
      if (line == header) { in_table=1; found=1; next }
      if (in_table && line ~ /^\[/) { in_table=0 }
      if (in_table && line ~ /^enabled[[:space:]]*=[[:space:]]*false([[:space:]]*(#.*)?)?$/) { disabled=1 }
    }
    END {
      if (!found) exit 2
      if (disabled) exit 1
      exit 0
    }
  ' "$path"
}

extract_version_token() {
  local display="$1"
  if [[ "$display" =~ ([0-9]+[0-9A-Za-z\.\-\+_]*) ]]; then
    printf "%s" "${BASH_REMATCH[1]}"
  fi
}

format_version_entry() {
  local name="$1" tone="$2" installed="$3" target="$4" status="$5"
  local icon
  icon="$(status_icon "$tone")"
  local ver_inst
  ver_inst="$(extract_version_token "$installed")"
  local ver_target
  ver_target="$(extract_version_token "$target")"
  local text="$name"
  if [[ -n "$ver_inst" ]]; then
    text+=" ${ver_inst}"
  fi
  if [[ -n "$ver_target" && "$ver_target" != "$ver_inst" ]]; then
    text+="→${ver_target}"
  fi
  if [[ "$tone" == "green" && ( -z "$ver_target" || "$ver_target" == "$ver_inst" ) ]]; then
    text+=" ✅"
  else
    text+=" ${icon}"
    if [[ -n "$status" ]]; then
      text+=" $(colorize "$status" "$tone")"
    fi
  fi
  printf "%s" "$text"
}

seconds_since_iso() {
  local iso="$1"
  [[ -z "$iso" ]] && return 1
  if ! command -v python3 >/dev/null 2>&1; then
    return 1
  fi
  python3 - "$iso" <<'PY'
import datetime, sys
raw = sys.argv[1]
try:
    dt = datetime.datetime.fromisoformat(raw.replace("Z", "+00:00"))
except Exception:  # noqa: BLE001
    sys.exit(1)
now = datetime.datetime.now(datetime.timezone.utc)
delta = now - dt
print(int(delta.total_seconds()))
PY
}

format_duration_short() {
  local seconds="$1"
  [[ "$seconds" =~ ^[0-9]+$ ]] || { printf ""; return; }
  local s=$seconds
  local days=$(( s / 86400 ))
  s=$(( s % 86400 ))
  local hours=$(( s / 3600 ))
  s=$(( s % 3600 ))
  local mins=$(( s / 60 ))
  local parts=()
  (( days > 0 )) && parts+=("${days}d")
  (( hours > 0 )) && parts+=("${hours}h")
  (( mins > 0 )) && parts+=("${mins}m")
  if (( ${#parts[@]} == 0 )); then
    parts=("<1m")
  fi
  printf "%s" "${parts[*]}"
}

format_relative_iso() {
  local iso="$1"
  local seconds=""
  seconds="$(seconds_since_iso "$iso" 2>/dev/null || true)"
  if [[ -z "$seconds" ]]; then
    return 1
  fi
  if (( seconds < 0 )); then
    seconds=$(( -seconds ))
  fi
  local label
  label="$(format_duration_short "$seconds")"
  if [[ -z "$label" ]]; then
    return 1
  fi
  printf "%s ago" "$label"
}

build_quota_bar() {
  local pct="$1" width="$2"
  (( width < 1 )) && width=24
  (( pct < 0 )) && pct=0
  (( pct > 100 )) && pct=100
  local filled=$(( (pct * width + 50) / 100 ))
  (( filled > width )) && filled=$width
  local fill_color="${GREEN}${BOLD}"
  if (( pct >= 95 )); then
    fill_color="${RED}${BOLD}"
  elif (( pct >= 80 )); then
    fill_color="${ORANGE}${BOLD}"
  fi
  local fill_char="${CDX_QUOTA_FILL_CHAR:-█}"
  local empty_char="${CDX_QUOTA_EMPTY_CHAR:-░}"
  local bar=""
  if (( filled > 0 )); then
    local filled_part
    filled_part="$(printf '%*s' "$filled" "")"
    filled_part="${filled_part// /$fill_char}"
    bar+="${fill_color}${filled_part}"
  fi
  local empty_count=$(( width - filled ))
  if (( empty_count > 0 )); then
    local empty_part
    empty_part="$(printf '%*s' "$empty_count" "")"
    empty_part="${empty_part// /$empty_char}"
    bar+="${RESET}${DIM}${empty_part}"
  fi
  bar+="${RESET}"
  printf -v bar "%b" "$bar"
  printf "%s" "$bar"
}

render_quota_line() {
  local used="$1" reset_after="$2" reset_at="$3"
  local width=${QUOTA_BAR_WIDTH:-24}
  local tone="yellow"
  local text="n/a"
  local note=""

  if [[ "$used" =~ ^[0-9]+$ ]]; then
    local pct=$used
    (( pct < 0 )) && pct=0
    (( pct > 100 )) && pct=100
    (( width < 1 )) && width=24
    local bar
    bar="$(build_quota_bar "$pct" "$width")"
    if [[ "$reset_after" =~ ^[0-9]+$ ]]; then
      local dur
      dur=$(format_duration_short "$reset_after")
      [[ -n "$dur" ]] && note="resets in ${dur}"
    elif [[ -n "$reset_at" ]]; then
      note="resets @ ${reset_at}"
    fi

    if (( pct >= 95 )); then
      tone="red"
    elif (( pct >= 80 )); then
      tone="orange"
    else
      tone="green"
    fi

    text=$(printf "%3d%% [%s]" "$pct" "$bar")
  fi

  printf "%s\t%s\t%s" "$tone" "$text" "$note"
}

project_quota_usage() {
  local used_pct="$1" limit_seconds="$2" reset_after="$3"
  [[ "$used_pct" =~ ^[0-9]+$ ]] || return
  [[ "$limit_seconds" =~ ^[0-9]+$ ]] || return
  (( limit_seconds > 0 )) || return
  local remaining=0
  if [[ "$reset_after" =~ ^[0-9]+$ ]]; then
    remaining="$reset_after"
  fi
  (( remaining < 0 )) && remaining=0
  local elapsed=$(( limit_seconds - remaining ))
  (( elapsed < 1 )) && return
  (( elapsed > limit_seconds )) && elapsed=limit_seconds
  local projected=$(( (used_pct * limit_seconds + elapsed / 2) / elapsed ))
  (( projected > 999 )) && projected=999
  (( projected > 100 )) && projected=100
  printf "%d" "$projected"
}

format_auth_label() {
  local status="$1" action="$2" msg="$3"
  if (( ! HOST_IS_SECURE )) && [[ "$status" =~ ^(outdated|missing|upload_required)$ ]]; then
    local parts=("status refreshed (insecure host)")
    case "$action" in
      store|retrieve|outdated) parts+=("fetched latest auth") ;;
    esac
    [[ -n "$msg" ]] && parts+=("$msg")
    printf "%s" "$(join_with_semicolon "${parts[@]}")"
    return
  fi
  local parts=()
  case "$status" in
    valid) parts+=("status valid (matches server)") ;;
    outdated) parts+=("status outdated (server newer)") ;;
    missing) parts+=("status missing (upload needed)") ;;
    upload_required) parts+=("status upload required (client newer)") ;;
    *)
      [[ -n "$status" ]] && parts+=("status ${status}")
      ;;
  esac
  case "$action" in
    valid) parts+=("no update needed") ;;
    store) parts+=("stored latest auth on server") ;;
    retrieve) parts+=("pulled latest auth from server") ;;
    *)
      [[ -n "$action" ]] && parts+=("action ${action}")
      ;;
  esac
  [[ -n "$msg" ]] && parts+=("$msg")
  printf "%s" "$(join_with_semicolon "${parts[@]}")"
}

codex_target_label="${codex_target_label:-${remote_tag:-${remote_version:-${LOCAL_VERSION:-unknown}}}}"
wrapper_target_label="${wrapper_target_label:-${WRAPPER_VERSION}}"
wrapper_installed_label="${WRAPPER_VERSION:-unknown}"
codex_installed_label="${codex_installed_label:-${LOCAL_VERSION:-unknown}}"

codex_status_display="$codex_status_label"
if [[ -n "$codex_status_note" ]]; then
  codex_status_display="${codex_status_display} (${codex_status_note})"
fi
wrapper_status_display="$wrapper_status_label"
if [[ -n "$wrapper_status_note" ]]; then
  wrapper_status_display="${wrapper_status_display} (${wrapper_status_note})"
fi

codex_installed_display="$codex_installed_label"
if [[ -n "$codex_installed_display" ]]; then
  codex_installed_display+=" installed"
fi
codex_target_display="$codex_target_label"
if [[ -n "$codex_target_display" && "$codex_target_display" != "n/a" && "$codex_target_display" != "unknown" ]]; then
  codex_target_display+=" available"
fi
wrapper_installed_display="$wrapper_installed_label"
if [[ -n "$wrapper_installed_display" ]]; then
  wrapper_installed_display+=" installed"
fi
wrapper_target_display="$wrapper_target_label"
if [[ -n "$wrapper_target_display" && "$wrapper_target_display" != "n/a" && "$wrapper_target_display" != "unknown" ]]; then
  wrapper_target_display+=" available"
fi

api_label="Unavailable"
api_tone="red"
case "$AUTH_PULL_STATUS" in
  ok)
    api_label="Up and working"
    api_tone="green"
    ;;
  offline)
    api_label="Unavailable (offline"
    if [[ -n "$AUTH_PULL_REASON" ]]; then
      api_label+="; ${AUTH_PULL_REASON}"
    fi
    api_label+=")"
    api_tone="yellow"
    ;;
  disabled)
    api_label="API disabled"
    api_tone="red"
    ;;
  invalid)
    api_label="Invalid API key"
    api_tone="red"
    ;;
  missing-config)
    api_label="Missing API config"
    api_tone="red"
    ;;
  insecure)
    api_label="Insecure host blocked"
    api_tone="red"
    ;;
esac

auth_label="n/a"
if [[ -n "$AUTH_STATUS" ]]; then
  auth_label="$(format_auth_label "$AUTH_STATUS" "$AUTH_ACTION" "$AUTH_MESSAGE")"
elif [[ "$AUTH_PULL_STATUS" == "offline" ]]; then
  cached_lr="${ORIGINAL_LAST_REFRESH:-unknown}"
  offline_hint=""
  [[ -n "$AUTH_PULL_REASON" ]] && offline_hint="; ${AUTH_PULL_REASON}"
  if (( HAS_LOCAL_AUTH )) && (( LOCAL_AUTH_IS_FRESH )); then
    auth_label="using cached auth (api offline${offline_hint}; last_refresh ${cached_lr})"
  elif (( HAS_LOCAL_AUTH )) && (( HOST_IS_SECURE )) && (( LOCAL_AUTH_IS_RECENT )); then
    auth_label="using cached auth (secure host; api offline${offline_hint}; last_refresh ${cached_lr})"
  elif (( HAS_LOCAL_AUTH )); then
    auth_label="cached auth stale (api offline${offline_hint}; last_refresh ${cached_lr})"
  else
    auth_label="auth unavailable (api offline${offline_hint})"
  fi
elif [[ "$AUTH_PULL_STATUS" == "insecure" ]]; then
  auth_label="insecure host window closed"
elif [[ "$AUTH_PULL_STATUS" != "ok" ]]; then
  auth_label="auth sync failed"
fi

auth_tone="yellow"
case "$AUTH_STATUS" in
  valid|"")
    [[ "$AUTH_PULL_STATUS" == "ok" ]] && auth_tone="green"
    ;;
  outdated|missing|upload_required)
    if (( HOST_IS_SECURE )); then
      auth_tone="yellow"
    else
      auth_tone="green"
    fi
    ;;
  *)
    auth_tone="yellow"
    ;;
esac
if [[ "$AUTH_PULL_STATUS" == "offline" ]]; then
  if (( HAS_LOCAL_AUTH )) && (( LOCAL_AUTH_IS_FRESH || (HOST_IS_SECURE && LOCAL_AUTH_IS_RECENT) )); then
    auth_tone="yellow"
  else
    auth_tone="red"
  fi
elif [[ "$AUTH_PULL_STATUS" != "ok" ]]; then
  auth_tone="red"
fi

runner_label=""
runner_tone="yellow"
runner_enabled_flag=0
[[ "$RUNNER_ENABLED" == "1" ]] && runner_enabled_flag=1
if (( runner_enabled_flag )) || [[ -n "$RUNNER_STATE$RUNNER_LAST_OK$RUNNER_LAST_FAIL" ]]; then
  state="${RUNNER_STATE,,}"
  last_ok_rel="$(format_relative_iso "$RUNNER_LAST_OK" 2>/dev/null || true)"
  last_fail_rel="$(format_relative_iso "$RUNNER_LAST_FAIL" 2>/dev/null || true)"
  if (( runner_enabled_flag )); then
    if [[ "$state" == "fail" ]]; then
      runner_tone="red"
      runner_label="runner failing"
      if [[ -n "$last_fail_rel" ]]; then
        runner_label+=" (${last_fail_rel})"
      fi
      if [[ -n "$last_ok_rel" ]]; then
        runner_label+="; last ok ${last_ok_rel}"
      fi
    else
      runner_tone="green"
      if [[ -n "$last_ok_rel" ]]; then
        age_seconds="$(seconds_since_iso "$RUNNER_LAST_OK" 2>/dev/null || true)"
        if [[ "$age_seconds" =~ ^-?[0-9]+$ ]]; then
          (( age_seconds < 0 )) && age_seconds=$(( -age_seconds ))
          if (( age_seconds <= 90 )); then
            runner_label="runner verified recently"
          else
            runner_label="runner verified ${last_ok_rel}"
          fi
          if (( age_seconds >= RUNNER_STALE_CRIT_SECONDS )); then
            runner_tone="red"
            runner_label+=" (stale)"
          elif (( age_seconds >= RUNNER_STALE_WARN_SECONDS )); then
            runner_tone="yellow"
            runner_label+=" (stale)"
          fi
        else
          runner_label="runner verified ${last_ok_rel}"
        fi
      else
        runner_tone="yellow"
        runner_label="runner enabled; no successful verification yet"
        if [[ -n "$last_fail_rel" ]]; then
          runner_label+=" (last fail ${last_fail_rel})"
        fi
      fi
    fi
  else
    runner_label="runner disabled"
  fi
fi

prompt_label="sync skipped"
prompt_tone="yellow"
if [[ "$PROMPT_SYNC_STATUS" == "ok" ]]; then
  prompt_label="synced"
  counts=()
  if [[ "$PROMPT_LOCAL_COUNT" =~ ^[0-9]+$ ]]; then
    counts+=("local ${PROMPT_LOCAL_COUNT}")
  fi
  if [[ "$PROMPT_REMOTE_COUNT" =~ ^[0-9]+$ ]]; then
    counts+=("remote ${PROMPT_REMOTE_COUNT}")
  fi
  if (( ${#counts[@]} )); then
    prompt_label+=" ($(join_with_semicolon "${counts[@]}"))"
  fi
  if [[ "$PROMPT_PULL_UPDATED" =~ ^[0-9]+$ ]] && (( PROMPT_PULL_UPDATED > 0 )); then
    prompt_label+=" (${PROMPT_PULL_UPDATED} updated)"
  fi
  if [[ "$PROMPT_REMOVED" =~ ^[0-9]+$ ]] && (( PROMPT_REMOVED > 0 )); then
    prompt_label+=" (${PROMPT_REMOVED} removed)"
  fi
  if [[ "$PROMPT_PULL_ERRORS" =~ ^[0-9]+$ ]] && (( PROMPT_PULL_ERRORS > 0 )); then
    prompt_label+=" (${PROMPT_PULL_ERRORS} fetch errors)"
    prompt_tone="yellow"
  else
    prompt_tone="green"
  fi
elif [[ "$PROMPT_SYNC_STATUS" == "missing-config" ]]; then
  prompt_label="sync config missing"
  prompt_tone="red"
elif [[ "$PROMPT_SYNC_STATUS" == "no-python" ]]; then
  prompt_label="sync requires python3"
  prompt_tone="yellow"
elif [[ "$PROMPT_SYNC_STATUS" == "offline" ]]; then
  prompt_label="sync unavailable"
  if [[ -n "$PROMPT_SYNC_REASON" ]]; then
    prompt_label+=" (${PROMPT_SYNC_REASON})"
  fi
  prompt_tone="yellow"
elif [[ "$PROMPT_SYNC_STATUS" == "error" ]]; then
  prompt_label="sync failed"
  prompt_tone="red"
fi

agents_label="AGENTS sync skipped"
agents_tone="yellow"
if [[ "$AGENTS_SYNC_STATUS" == "ok" ]]; then
  case "$AGENTS_STATE" in
    updated)
      agents_label="AGENTS updated"
      agents_tone="green"
      ;;
    unchanged)
      agents_label="AGENTS current"
      agents_tone="green"
      ;;
    missing)
      agents_label="AGENTS cleared"
      agents_tone="yellow"
      ;;
    *)
      agents_label="AGENTS synced"
      agents_tone="green"
      ;;
  esac
elif [[ "$AGENTS_SYNC_STATUS" == "missing-config" ]]; then
  agents_label="AGENTS sync config missing"
  agents_tone="red"
elif [[ "$AGENTS_SYNC_STATUS" == "no-python" ]]; then
  agents_label="AGENTS sync requires python3"
  agents_tone="yellow"
elif [[ "$AGENTS_SYNC_STATUS" == "offline" ]]; then
  agents_label="AGENTS sync unavailable"
  if [[ -n "$AGENTS_SYNC_REASON" ]]; then
    agents_label+=" (${AGENTS_SYNC_REASON})"
  fi
  agents_tone="yellow"
elif [[ "$AGENTS_SYNC_STATUS" == "error" ]]; then
  agents_label="AGENTS sync failed"
  agents_tone="red"
fi

config_label="config sync skipped"
config_tone="yellow"
if [[ "$CONFIG_SYNC_STATUS" == "ok" ]]; then
  case "$CONFIG_STATE" in
    updated)
      config_label="config updated"
      config_tone="green"
      ;;
    unchanged)
      config_label="config current"
      config_tone="green"
      ;;
    missing)
      config_label="config cleared"
      config_tone="yellow"
      ;;
    *)
      config_label="config synced"
      config_tone="green"
      ;;
  esac
elif [[ "$CONFIG_SYNC_STATUS" == "missing-config" ]]; then
  config_label="config sync config missing"
  config_tone="red"
elif [[ "$CONFIG_SYNC_STATUS" == "no-python" ]]; then
  config_label="config sync requires python3"
  config_tone="yellow"
elif [[ "$CONFIG_SYNC_STATUS" == "offline" ]]; then
  config_label="config sync unavailable"
  if [[ -n "$CONFIG_SYNC_REASON" ]]; then
    config_label+=" (${CONFIG_SYNC_REASON})"
  fi
  config_tone="yellow"
elif [[ "$CONFIG_SYNC_STATUS" == "error" ]]; then
  config_label="config sync failed"
  config_tone="red"
fi

case "$PROMPT_PUSH_STATUS" in
  ok)
    if [[ "$PROMPT_PUSHED" =~ ^[0-9]+$ ]] && (( PROMPT_PUSHED > 0 )); then
      prompt_label+="; pushed ${PROMPT_PUSHED}"
    fi
    if [[ "$PROMPT_PUSH_ERRORS" =~ ^[0-9]+$ ]] && (( PROMPT_PUSH_ERRORS > 0 )); then
      prompt_label+="; push errors ${PROMPT_PUSH_ERRORS}"
      prompt_tone="yellow"
    fi
    ;;
  no-baseline)
    prompt_label+="; push skipped (no baseline)"
    ;;
  no-python)
    prompt_label+="; push skipped (python missing)"
    ;;
  missing-config)
    prompt_label+="; push skipped (config missing)"
    prompt_tone="red"
    ;;
  error)
    prompt_label+="; push failed"
    prompt_tone="red"
    ;;
esac

command_actions=()
if (( codex_update_attempted )); then command_actions+=("codex"); fi
if (( wrapper_update_attempted )); then command_actions+=("wrapper"); fi
should_flag_auth=1
if (( ! HOST_IS_SECURE )) && [[ "$AUTH_PULL_STATUS" == "ok" ]] && [[ "$AUTH_STATUS" =~ ^(outdated|missing|upload_required)$ ]]; then
  should_flag_auth=0
fi
if (( should_flag_auth )) && [[ "$AUTH_STATUS" =~ ^(outdated|missing|upload_required)$ || "$AUTH_ACTION" == "store" ]]; then command_actions+=("auth"); fi
command_label="launching codex"
if (( ${#command_actions[@]} )); then
  command_label="updating $(human_join "${command_actions[@]}")"
fi

result_parts=()
if (( codex_updated )); then
  result_parts+=("codex updated")
elif (( codex_update_failed )); then
  result_parts+=("codex update failed")
else
  result_parts+=("codex ${codex_status_label,,}")
fi
if (( wrapper_updated )); then
  result_parts+=("wrapper updated")
elif (( wrapper_update_failed )); then
  result_parts+=("wrapper update failed")
else
  result_parts+=("wrapper ${wrapper_status_label,,}")
fi
if [[ -n "$AUTH_STATUS" ]]; then
  if (( ! HOST_IS_SECURE )) && [[ "$AUTH_STATUS" =~ ^(outdated|missing|upload_required)$ ]]; then
    auth_result="auth refreshed (insecure host)"
    if [[ -n "$AUTH_MESSAGE" ]]; then
      auth_result+=", ${AUTH_MESSAGE}"
    fi
  else
    auth_result="auth ${AUTH_STATUS}"
    if [[ -n "$AUTH_ACTION" ]]; then
      auth_result+=", ${AUTH_ACTION}"
    fi
  fi
  result_parts+=("$auth_result")
elif [[ "$AUTH_PULL_STATUS" == "offline" ]]; then
  offline_note="api offline"
  [[ -n "$AUTH_PULL_REASON" ]] && offline_note+="; ${AUTH_PULL_REASON}"
  if (( HAS_LOCAL_AUTH )) && (( LOCAL_AUTH_IS_FRESH )); then
    result_parts+=("auth cached (${offline_note})")
  elif (( HAS_LOCAL_AUTH )) && (( HOST_IS_SECURE )) && (( LOCAL_AUTH_IS_RECENT )); then
    result_parts+=("auth cached (secure host; ${offline_note})")
  elif (( HAS_LOCAL_AUTH )); then
    result_parts+=("auth stale (${offline_note})")
  else
    result_parts+=("auth unavailable (${offline_note})")
  fi
elif [[ "$AUTH_PULL_STATUS" != "ok" ]]; then
  result_parts+=("auth unavailable")
fi
if [[ "$PROMPT_SYNC_STATUS" == "ok" ]]; then
  prompt_result="prompts synced"
  if [[ "$PROMPT_LOCAL_COUNT" =~ ^[0-9]+$ ]]; then
    prompt_result+=" (local ${PROMPT_LOCAL_COUNT}"
    if [[ "$PROMPT_REMOTE_COUNT" =~ ^[0-9]+$ ]]; then
      prompt_result+=", remote ${PROMPT_REMOTE_COUNT}"
    fi
    prompt_result+=")"
  fi
  if [[ "$PROMPT_PULL_UPDATED" =~ ^[0-9]+$ ]] && (( PROMPT_PULL_UPDATED > 0 )); then
    prompt_result+=" (${PROMPT_PULL_UPDATED} updated)"
  fi
  if [[ "$PROMPT_PUSHED" =~ ^[0-9]+$ ]] && (( PROMPT_PUSHED > 0 )); then
    prompt_result+="; pushed ${PROMPT_PUSHED}"
  fi
  if [[ "$PROMPT_REMOVED" =~ ^[0-9]+$ ]] && (( PROMPT_REMOVED > 0 )); then
    prompt_result+="; removed ${PROMPT_REMOVED}"
  fi
  if [[ "$PROMPT_PUSH_ERRORS" =~ ^[0-9]+$ ]] && (( PROMPT_PUSH_ERRORS > 0 )); then
    prompt_result+="; push errors ${PROMPT_PUSH_ERRORS}"
  fi
  result_parts+=("$prompt_result")
elif [[ "$PROMPT_SYNC_STATUS" == "missing-config" ]]; then
  result_parts+=("prompts config missing")
elif [[ "$PROMPT_SYNC_STATUS" == "no-python" ]]; then
  result_parts+=("prompts python missing")
elif [[ "$PROMPT_SYNC_STATUS" == "offline" ]]; then
  if [[ -n "$PROMPT_SYNC_REASON" ]]; then
    result_parts+=("prompts offline (${PROMPT_SYNC_REASON})")
  else
    result_parts+=("prompts offline")
  fi
elif [[ "$PROMPT_SYNC_STATUS" == "error" ]]; then
  result_parts+=("prompts sync failed")
fi
if [[ "$PROMPT_PUSH_STATUS" == "error" ]]; then
  result_parts+=("prompts push failed")
fi
if [[ "$AGENTS_SYNC_STATUS" == "ok" ]]; then
  case "$AGENTS_STATE" in
    updated)
      result_parts+=("AGENTS.md updated")
      ;;
    unchanged)
      result_parts+=("AGENTS.md current")
      ;;
    missing)
      result_parts+=("AGENTS.md cleared")
      ;;
    *)
      result_parts+=("AGENTS.md synced")
      ;;
  esac
elif [[ "$AGENTS_SYNC_STATUS" == "missing-config" ]]; then
  result_parts+=("AGENTS.md config missing")
elif [[ "$AGENTS_SYNC_STATUS" == "no-python" ]]; then
  result_parts+=("AGENTS.md python missing")
elif [[ "$AGENTS_SYNC_STATUS" == "offline" ]]; then
  if [[ -n "$AGENTS_SYNC_REASON" ]]; then
    result_parts+=("AGENTS.md offline (${AGENTS_SYNC_REASON})")
  else
    result_parts+=("AGENTS.md offline")
  fi
elif [[ "$AGENTS_SYNC_STATUS" == "error" ]]; then
  result_parts+=("AGENTS.md sync failed")
fi
if [[ "$CONFIG_SYNC_STATUS" == "ok" ]]; then
  case "$CONFIG_STATE" in
    updated)
      result_parts+=("config.toml updated")
      ;;
    unchanged)
      result_parts+=("config.toml current")
      ;;
    missing)
      result_parts+=("config.toml cleared")
      ;;
    *)
      result_parts+=("config.toml synced")
      ;;
  esac
elif [[ "$CONFIG_SYNC_STATUS" == "missing-config" ]]; then
  result_parts+=("config.toml config missing")
elif [[ "$CONFIG_SYNC_STATUS" == "no-python" ]]; then
  result_parts+=("config.toml python missing")
elif [[ "$CONFIG_SYNC_STATUS" == "offline" ]]; then
  if [[ -n "$CONFIG_SYNC_REASON" ]]; then
    result_parts+=("config.toml offline (${CONFIG_SYNC_REASON})")
  else
    result_parts+=("config.toml offline")
  fi
elif [[ "$CONFIG_SYNC_STATUS" == "error" ]]; then
  result_parts+=("config.toml sync failed")
fi
if (( QUOTA_BLOCKED )); then
  result_parts+=("${QUOTA_BLOCK_REASON:-quota reached}")
fi
result_label="$(human_join "${result_parts[@]}")"

  usage_summary=""
  if [[ -n "$last_usage_payload" ]]; then
    usage_summary="$(parse_usage_summary "$last_usage_payload")"
  fi

  codex_tone="green"
  case "${codex_status_label,,}" in
    update\ available|check\ skipped|update\ skipped)
      codex_tone="yellow"
      ;;
  update\ failed|api\ unavailable)
    codex_tone="red"
    ;;
esac
(( codex_update_failed )) && codex_tone="red"

wrapper_tone="green"
case "${wrapper_status_label,,}" in
  update\ available|update\ skipped|check\ skipped)
    wrapper_tone="yellow"
    ;;
  update\ failed)
    wrapper_tone="red"
    ;;
esac
(( wrapper_update_failed )) && wrapper_tone="red"

result_tone="green"
if (( codex_update_failed )) || (( wrapper_update_failed )) || { [[ "$AUTH_PULL_STATUS" != "ok" ]] && [[ "$AUTH_PULL_STATUS" != "offline" ]]; }; then
  result_tone="red"
elif [[ "$AUTH_PULL_STATUS" == "offline" ]]; then
  if (( HAS_LOCAL_AUTH )) && (( LOCAL_AUTH_IS_FRESH || (HOST_IS_SECURE && LOCAL_AUTH_IS_RECENT) )); then
    result_tone="yellow"
  else
    result_tone="red"
  fi
elif [[ "$AUTH_STATUS" =~ ^(outdated|missing|upload_required)$ ]]; then
  result_tone="yellow"
elif [[ "${codex_status_label,,}" == "update available" ]] || [[ "${wrapper_status_label,,}" == "update available" ]]; then
  result_tone="yellow"
elif [[ "$PROMPT_SYNC_STATUS" == "error" || "$PROMPT_PUSH_STATUS" == "error" ]]; then
  result_tone="red"
elif [[ "$PROMPT_SYNC_STATUS" != "ok" && "$PROMPT_SYNC_STATUS" != "skip" ]]; then
  result_tone="yellow"
elif [[ "$PROMPT_PUSH_ERRORS" =~ ^[0-9]+$ ]] && (( PROMPT_PUSH_ERRORS > 0 )); then
  result_tone="yellow"
elif [[ "$AGENTS_SYNC_STATUS" == "error" ]]; then
  result_tone="red"
elif [[ "$AGENTS_SYNC_STATUS" != "ok" && "$AGENTS_SYNC_STATUS" != "skip" ]]; then
  result_tone="yellow"
elif [[ "$CONFIG_SYNC_STATUS" == "error" ]]; then
  result_tone="red"
elif [[ "$CONFIG_SYNC_STATUS" != "ok" && "$CONFIG_SYNC_STATUS" != "skip" ]]; then
  result_tone="yellow"
elif (( QUOTA_WARNING )); then
  result_tone="yellow"
elif (( QUOTA_BLOCKED )); then
  result_tone="red"
fi

command_tone=""
if (( ${#command_actions[@]} )); then
  command_tone="yellow"
fi
if (( QUOTA_WARNING )); then
  command_tone="yellow"
fi
if (( QUOTA_BLOCKED )); then
  command_tone="red"
fi

if [[ "$result_tone" == "green" && "$command_tone" != "red" && "$auth_tone" == "green" && "$codex_tone" == "green" && "$wrapper_tone" == "green" ]]; then
  result_label="Codex go Brrrr!"
fi

  quota_limit="$QUOTA_LIMIT_PERCENT"
  if [[ ! "$quota_limit" =~ ^[0-9]+$ ]]; then
    quota_limit=100
  fi
  if (( quota_limit < 50 )); then
    quota_limit=50
  elif (( quota_limit > 100 )); then
    quota_limit=100
  fi
  QUOTA_LIMIT_PERCENT="$quota_limit"
  if (( QUOTA_HARD_FAIL )); then
    quota_summary="Deny launches at ≥${quota_limit}% usage."
  else
    quota_summary="Warn at ≥${quota_limit}% usage; continue running."
  fi

  partition_days="$QUOTA_WEEK_PARTITION"
  if [[ ! "$partition_days" =~ ^[0-9]+$ ]]; then
    partition_days=0
  fi
  if (( partition_days != 5 && partition_days != 7 )); then
    partition_days=0
  fi
  QUOTA_WEEK_PARTITION="$partition_days"

  command_line=""
  if [[ -n "$command_label" ]]; then
    command_line="Command: $(colorize "$command_label" "$command_tone")"
  fi

  core_bits=()
  api_detail=""
  [[ "$api_tone" != "green" ]] && api_detail="$api_label"
  core_bits+=("$(format_core_entry "API" "$api_tone" "$api_detail")")

  auth_detail=""
  if [[ "$auth_tone" != "green" ]]; then
    auth_detail="$auth_label"
  fi
  core_bits+=("$(format_core_entry "Auth" "$auth_tone" "$auth_detail")")

  prompt_detail=""
  if [[ "$prompt_tone" == "green" ]]; then
    if [[ "$prompt_label" =~ local[[:space:]]+([0-9]+).*remote[[:space:]]+([0-9]+) ]]; then
      prompt_detail="(${BASH_REMATCH[1]}/${BASH_REMATCH[2]})"
    fi
  else
    prompt_detail="$prompt_label"
  fi
  core_bits+=("$(format_core_entry "Prompts" "$prompt_tone" "$prompt_detail")")

  if [[ -n "$runner_label" ]]; then
    core_bits+=("$(format_core_entry "Runner" "$runner_tone")")
  fi

  # MCP status (managed codex-orchestrator server in config.toml).
  if [[ -f "$CONFIG_PATH" ]]; then
    mcp_tone="yellow"
    if toml_table_enabled "$CONFIG_PATH" "mcp_servers.cdx"; then
      mcp_tone="green"
    else
      case $? in
        1) mcp_tone="yellow" ;; # explicitly disabled
        2)
          if toml_table_enabled "$CONFIG_PATH" "mcp_servers.codex-orchestrator"; then
            mcp_tone="green"
          else
            mcp_tone="yellow"
          fi
          ;;
      esac
    fi
    core_bits+=("$(format_core_entry "MCP" "$mcp_tone")")
  fi

  policy_entry="Policy: $( (( QUOTA_HARD_FAIL )) && printf "Deny" || printf "Warn" )"
  core_line_bits=("${core_bits[@]}" "$policy_entry")
  core_line="Core: $(join_with_sep ' | ' "${core_line_bits[@]}")"

  versions_bits=()
  versions_bits+=("$(format_version_entry "codex" "$codex_tone" "$codex_installed_display" "$codex_target_display" "$codex_status_display")")
  versions_bits+=("$(format_version_entry "wrapper" "$wrapper_tone" "$wrapper_installed_display" "$wrapper_target_display" "$wrapper_status_display")")
  if [[ -n "$agents_label" ]]; then
    if [[ "$agents_tone" == "green" ]]; then
      versions_bits+=("AGENTS ✅")
    else
      versions_bits+=("$(format_core_entry "AGENTS" "$agents_tone" "$agents_label")")
    fi
  fi
  if [[ -n "$config_label" ]]; then
    if [[ "$config_tone" == "green" ]]; then
      versions_bits+=("config.toml ✅")
    else
      versions_bits+=("$(format_core_entry "config" "$config_tone" "$config_label")")
    fi
  fi
  versions_line=""
  if (( ${#versions_bits[@]} )); then
    versions_line="Versions: $(join_with_sep ' | ' "${versions_bits[@]}")"
  fi

  usage_bits=()
  if [[ -n "$HOST_API_CALLS" ]]; then
    usage_bits+=("calls ${HOST_API_CALLS}")
  fi
  token_bits=()
  [[ -n "$HOST_TOKENS_MONTH_TOTAL" ]] && token_bits+=("total ${HOST_TOKENS_MONTH_TOTAL}")
  token_line="$(join_with_sep ' / ' "${token_bits[@]}")"
  if [[ -n "$token_line" ]]; then
    usage_bits+=("tokens ${token_line}")
  fi
  if [[ -n "$usage_summary" ]]; then
    usage_bits+=("$usage_summary")
  fi
  usage_line=""
  if (( ${#usage_bits[@]} )); then
    usage_line="Usage: $(join_with_sep ' | ' "${usage_bits[@]}")"
  fi

  result_line="Result: $(colorize "$result_label" "$result_tone")"
  if [[ "${HOST_VIP:-0}" == "1" ]]; then
    result_line+=" 👑"
  fi
  primary_reset_hint=""
  primary_quota_segment=""
  qline=$(render_quota_line "$CHATGPT_PRIMARY_USED" "$CHATGPT_PRIMARY_RESET_AFTER" "$CHATGPT_PRIMARY_RESET_AT")
  if [[ -n "$qline" ]]; then
    qtone="${qline%%$'\t'*}"
    rest="${qline#*$'\t'}"
    qtext="${rest%%$'\t'*}"
    qnote="${rest#*$'\t'}"
    primary_reset_hint="$qnote"
    qnote_disp="$qnote"
    if [[ -n "$qnote_disp" ]]; then
      printf -v qnote_disp "%b" "${DIM}${qnote_disp}${RESET}"
    fi
    # qtext looks like "  7% [bars]"
    primary_quota_segment="$(colorize "$qtext" "$qtone")"
    if [[ -n "$qnote_disp" ]]; then
      primary_quota_segment+=" ${qnote_disp}"
    fi
  fi

  secondary_reset_hint=""
  secondary_quota_segment=""
  qline=$(render_quota_line "$CHATGPT_SECONDARY_USED" "$CHATGPT_SECONDARY_RESET_AFTER" "$CHATGPT_SECONDARY_RESET_AT")
  if [[ -n "$qline" ]]; then
    qtone2="${qline%%$'\t'*}"
    rest2="${qline#*$'\t'}"
    qtext2="${rest2%%$'\t'*}"
    qnote2="${rest2#*$'\t'}"
    projection_note=""
    projection_alert=0
    projection_pct="$(project_quota_usage "$CHATGPT_SECONDARY_USED" "$CHATGPT_SECONDARY_LIMIT" "$CHATGPT_SECONDARY_RESET_AFTER")"
    if [[ -n "$projection_pct" ]]; then
      if (( projection_pct >= 100 )); then
        projection_note="proj 100% at reset"
        projection_alert=1
      else
        projection_note="proj ~${projection_pct}% at reset"
      fi
    fi
    qnote_full="$(join_with_semicolon "$qnote2" "$projection_note")"
    secondary_reset_hint="$qnote_full"
    qnote2_disp="$qnote_full"
    if [[ -n "$qnote2_disp" ]]; then
      if (( projection_alert )); then
        printf -v qnote2_disp "%b" "${RED}${BOLD}${qnote2_disp}${RESET}"
      else
        printf -v qnote2_disp "%b" "${DIM}${qnote2_disp}${RESET}"
      fi
    fi
    secondary_quota_segment="$(colorize "$qtext2" "$qtone2")"
    if [[ -n "$qnote2_disp" ]]; then
      secondary_quota_segment+=" ${qnote2_disp}"
    fi
  fi

  daily_quota_segment=""
  daily_reset_hint=""
  daily_allowance_used_pct=""
  if (( QUOTA_WEEK_PARTITION == 5 || QUOTA_WEEK_PARTITION == 7 )); then
    if [[ "$CHATGPT_SECONDARY_USED" =~ ^[0-9]+$ ]]; then
      partition_days="$QUOTA_WEEK_PARTITION"
      allowance_per_day=$(( (100 + partition_days / 2) / partition_days ))
      (( allowance_per_day < 1 )) && allowance_per_day=1
      daily_used="${CHATGPT_DAILY_USED:-}"
      if [[ "$daily_used" =~ ^[0-9]+$ ]]; then
        bar_pct=$(( (daily_used * 100 + allowance_per_day / 2) / allowance_per_day ))
        (( bar_pct < 0 )) && bar_pct=0
        (( bar_pct > 999 )) && bar_pct=999
        daily_allowance_used_pct=$bar_pct
        bar_display=$bar_pct
        (( bar_display > 100 )) && bar_display=100
        bar="$(build_quota_bar "$bar_display" "$QUOTA_BAR_WIDTH")"
        qtone3="green"
        if (( bar_pct >= 95 )); then
          qtone3="red"
        elif (( bar_pct >= 80 )); then
          qtone3="orange"
        fi
        printf -v qtext3 "%3d%% [%s]" "$bar_pct" "$bar"
        note_parts=()
        note_parts+=("today used ${daily_used}% of week")
        note_parts+=("allowance ${allowance_per_day}%/day | ${partition_days} day partition")
        daily_reset_hint="$(join_with_semicolon "${note_parts[@]}")"
        note3_disp="$daily_reset_hint"
        if [[ -n "$note3_disp" ]]; then
          printf -v note3_disp "%b" "${DIM}${note3_disp}${RESET}"
        fi
        daily_quota_segment="$(colorize "$qtext3" "$qtone3")"
        if [[ -n "$note3_disp" ]]; then
          daily_quota_segment+=" ${note3_disp}"
        fi
      fi
    fi
  fi

  if (( QUOTA_WEEK_PARTITION == 5 || QUOTA_WEEK_PARTITION == 7 )) && [[ -z "$daily_quota_segment" ]]; then
    allowance_per_day=$(( (100 + QUOTA_WEEK_PARTITION / 2) / QUOTA_WEEK_PARTITION ))
    bar="$(build_quota_bar 0 "$QUOTA_BAR_WIDTH")"
    qtext3=$(printf "%3d%% [%s]" 0 "$bar")
    note3_disp=$(printf "%b" "${DIM}allowance ${allowance_per_day}%/day | ${QUOTA_WEEK_PARTITION} day partition${RESET}")
    daily_quota_segment="$(colorize "$qtext3" "green") ${note3_disp}"
    daily_allowance_used_pct=0
  fi

  quota_warn_threshold=$(( quota_limit - 10 ))
  if (( quota_warn_threshold < 0 )); then
    quota_warn_threshold=0
  fi
  quota_reasons=()
  quota_warnings=()
  if [[ "${CHATGPT_STATUS,,}" == "limit_reached" ]]; then
    quota_reasons+=("ChatGPT status limit_reached")
  fi
  if [[ "$CHATGPT_PRIMARY_USED" =~ ^[0-9]+$ ]]; then
    if (( CHATGPT_PRIMARY_USED >= quota_limit )); then
      reason="5h quota reached (${CHATGPT_PRIMARY_USED}% used"
      [[ -n "$primary_reset_hint" ]] && reason+="; ${primary_reset_hint}"
      reason+=")"
      quota_reasons+=("$reason")
    elif (( CHATGPT_PRIMARY_USED >= quota_warn_threshold )); then
      reason="5h quota high (${CHATGPT_PRIMARY_USED}% used"
      [[ -n "$primary_reset_hint" ]] && reason+="; ${primary_reset_hint}"
      reason+=")"
      quota_warnings+=("$reason")
    fi
  fi
  if [[ "$CHATGPT_SECONDARY_USED" =~ ^[0-9]+$ ]]; then
    if (( CHATGPT_SECONDARY_USED >= quota_limit )); then
      reason="week quota reached (${CHATGPT_SECONDARY_USED}% used"
      [[ -n "$secondary_reset_hint" ]] && reason+="; ${secondary_reset_hint}"
      reason+=")"
      quota_reasons+=("$reason")
    elif (( CHATGPT_SECONDARY_USED >= quota_warn_threshold )); then
      reason="week quota high (${CHATGPT_SECONDARY_USED}% used"
      [[ -n "$secondary_reset_hint" ]] && reason+="; ${secondary_reset_hint}"
      reason+=")"
      quota_warnings+=("$reason")
    fi
  fi
  if [[ "$daily_allowance_used_pct" =~ ^[0-9]+$ ]]; then
    if (( daily_allowance_used_pct >= quota_limit )); then
      reason="daily allowance reached (${daily_allowance_used_pct}% of allowance"
      [[ -n "$daily_reset_hint" ]] && reason+="; ${daily_reset_hint}"
      reason+=")"
      quota_reasons+=("$reason")
    elif (( daily_allowance_used_pct >= quota_warn_threshold )); then
      reason="daily allowance high (${daily_allowance_used_pct}% of allowance"
      [[ -n "$daily_reset_hint" ]] && reason+="; ${daily_reset_hint}"
      reason+=")"
      quota_warnings+=("$reason")
    fi
  fi
  if (( ${#quota_reasons[@]} )); then
    QUOTA_BLOCKED=1
    QUOTA_BLOCK_REASON="$(human_join "${quota_reasons[@]}")"
  fi
  if (( ${#quota_warnings[@]} )); then
    QUOTA_WARNING=1
    QUOTA_WARNING_REASON="$(human_join "${quota_warnings[@]}")"
  fi

	  if (( ! wrapper_updated )); then
	    format_label_prefix() {
	      local label="$1"
	      local width="${SUMMARY_LABEL_WIDTH:-12}"
	      printf "%-${width}s: " "$label"
	    }
	
	    log_info "$(format_label_prefix "Core")${core_line#Core: }"
	    if [[ -n "$versions_line" ]]; then
	      log_info "$(format_label_prefix "Versions")${versions_line#Versions: }"
	    fi
	    if [[ -n "$usage_line" ]]; then
	      log_info "$(format_label_prefix "Usage")${usage_line#Usage: }"
	    fi
	    quota_label_base="Quota"
	    if [[ -n "$primary_quota_segment" ]]; then
	      quota_line="${primary_quota_segment}"
	      if (( QUOTA_WARNING )) || (( QUOTA_BLOCKED )); then
	        quota_line+=" ⚠"
	      fi
	      log_info "$(format_label_prefix "${quota_label_base} 5h")${quota_line}"
	    fi
	    if [[ -n "$daily_quota_segment" ]]; then
	      quota_line3="${daily_quota_segment}"
	      if (( QUOTA_WARNING )) || (( QUOTA_BLOCKED )); then
	        quota_line3+=" ⚠"
	      fi
	      log_info "$(format_label_prefix "${quota_label_base} day")${quota_line3}"
	    fi
	    if [[ -n "$secondary_quota_segment" ]]; then
	      quota_line2="${secondary_quota_segment}"
	      if (( QUOTA_WARNING )) || (( QUOTA_BLOCKED )); then
	        quota_line2+=" ⚠"
	      fi
	      log_info "$(format_label_prefix "${quota_label_base} wk")${quota_line2}"
	    fi
	    log_info "$(format_label_prefix "Result")${result_line#Result: }"
	  fi

if (( wrapper_updated )) && (( ! CODEX_EXIT_AFTER_UPDATE )); then
  if [[ "${CODEX_WRAPPER_RESTARTED:-0}" == "1" ]]; then
    log_error "Wrapper update loop detected; aborting."
    exit 1
  fi
  log_warn "Wrapper updated; restarting cdx to load the new wrapper."
  CODEX_SKIP_MOTD=1 CODEX_WRAPPER_RESTARTED=1 exec "$SCRIPT_REAL" "$@"
fi

AUTH_LAUNCH_ALLOWED=0
AUTH_LAUNCH_REASON=""
case "$AUTH_PULL_STATUS" in
  ok)
    AUTH_LAUNCH_ALLOWED=1
    ;;
  offline)
    offline_launch_hint=""
    [[ -n "$AUTH_PULL_REASON" ]] && offline_launch_hint=" (${AUTH_PULL_REASON})"
    if (( HAS_LOCAL_AUTH )) && (( LOCAL_AUTH_IS_FRESH )); then
      AUTH_LAUNCH_ALLOWED=1
      AUTH_LAUNCH_REASON="API offline${offline_launch_hint}; using cached auth.json"
    elif (( HAS_LOCAL_AUTH )) && (( HOST_IS_SECURE )); then
      AUTH_LAUNCH_ALLOWED=1
      AUTH_LAUNCH_REASON="API offline${offline_launch_hint}; secure host using cached auth.json"
    elif (( HAS_LOCAL_AUTH )); then
      AUTH_LAUNCH_REASON="API offline${offline_launch_hint}; cached auth.json older than allowed window"
    else
      AUTH_LAUNCH_REASON="API offline${offline_launch_hint} and no cached auth.json"
    fi
    ;;
  invalid)
    AUTH_LAUNCH_REASON="Invalid API key; download a fresh wrapper or rotate the key."
    ;;
  missing-config)
    AUTH_LAUNCH_REASON="Auth configuration missing (base URL or API key)."
    ;;
  disabled)
    AUTH_LAUNCH_REASON="Auth API disabled by administrator."
    ;;
  insecure)
    AUTH_LAUNCH_REASON="Insecure host API disabled; enable the host window in the admin dashboard."
    ;;
  fail)
    AUTH_LAUNCH_REASON="Auth sync failed; check API connectivity."
    ;;
  *)
    AUTH_LAUNCH_REASON="Auth unavailable; fix sync before retrying."
    ;;
esac

if (( AUTH_LAUNCH_ALLOWED == 1 )) && (( QUOTA_BLOCKED )); then
  if (( QUOTA_HARD_FAIL )); then
    AUTH_LAUNCH_ALLOWED=0
    AUTH_LAUNCH_REASON="${QUOTA_BLOCK_REASON:-ChatGPT quota reached}"
  else
    log_warn "ChatGPT quota reached: ${QUOTA_BLOCK_REASON:-see details above}. Continuing (warn mode)."
  fi
fi

if (( QUOTA_WARNING )) && (( AUTH_LAUNCH_ALLOWED == 1 )); then
  log_warn "ChatGPT quota near limit: ${QUOTA_WARNING_REASON:-see usage above}."
fi

if (( AUTH_LAUNCH_ALLOWED == 0 )); then
  log_error "${AUTH_LAUNCH_REASON:-Auth unavailable; refusing to start Codex. Re-run after fixing API key or provisioning auth.}"
  exit 1
elif [[ "$AUTH_PULL_STATUS" == "offline" ]]; then
  log_warn "${AUTH_LAUNCH_REASON} (last_refresh ${ORIGINAL_LAST_REFRESH:-unknown})."
fi

cleanup() {
  local exit_status=$?
  trap - EXIT
  push_slash_commands_if_changed || true
  if (( CODEX_COMMAND_STARTED )) && (( SYNC_PUSH_COMPLETED == 0 )); then
    push_auth_if_changed "push" || true
  fi
  # Emit final auth push status if determined
  if [[ -n "$AUTH_PUSH_RESULT" ]]; then
    log_info "Auth push | ${AUTH_PUSH_RESULT} | ${AUTH_PUSH_REASON:-n/a}"
  fi
  if (( PURGE_AUTH_AFTER_RUN )) && (( CODEX_COMMAND_STARTED )) && [[ -f "$HOME/.codex/auth.json" ]]; then
    remove_path "$HOME/.codex/auth.json" "auth.json (insecure host)"
  fi
  exit "$exit_status"
}
trap cleanup EXIT

if (( AUTH_LAUNCH_ALLOWED == 0 )); then
  exit 1
fi

apply_otel_env_from_config() {
  if [[ ! -f "$CONFIG_PATH" ]]; then
    return 0
  fi
  if ! command -v python3 >/dev/null 2>&1; then
    return 0
  fi
  local line key val
  while IFS= read -r line; do
    [[ -z "$line" ]] && continue
    key="${line%%=*}"
    val="${line#*=}"
    case "$key" in
      OTEL_*|CODEX_OTEL_LOG_USER_PROMPT)
        export "$key=$val"
        ;;
    esac
  done < <(otel_env_from_config_python 2>/dev/null || true)
}

apply_otel_env_from_config

run_codex_command() {
  local tmp_output status
  tmp_output="$(mktemp)"
  set +e
  if [[ -t 1 && "$CODEX_NO_PTY" != "1" ]]; then
    local cmd_line=("$CODEX_REAL_BIN" "$@")
    if [[ "$CODEX_NO_SCRIPT" != "1" ]] && command -v script >/dev/null 2>&1; then
      # Use script to keep a PTY and capture output to a typescript file while streaming to the real TTY.
      local cmd_str
      cmd_str="$(printf '%q ' "${cmd_line[@]}")"
      script -qef "$tmp_output" -c "$cmd_str"
      status=$?
    elif command -v python3 >/dev/null 2>&1; then
      # Fallback PTY using Python's pty module when script is unavailable.
      status=0
      python3 - "$tmp_output" "${cmd_line[@]}" <<'PY'
import os, sys, pty
log_path = sys.argv[1]
cmd = sys.argv[2:]
with open(log_path, "wb") as log:
    pid, fd = pty.fork()
    if pid == 0:
        os.execvp(cmd[0], cmd)
    try:
        while True:
            try:
                data = os.read(fd, 1024)
            except OSError:
                break
            if not data:
                break
            os.write(sys.stdout.fileno(), data)
            log.write(data)
            log.flush()
    except KeyboardInterrupt:
        pass
    _, status = os.waitpid(pid, 0)
    sys.exit(os.WEXITSTATUS(status))
PY
      status=$?
    else
      # Last-resort: run directly to preserve TTY; no tee (token usage may be skipped).
      "${cmd_line[@]}"
      status=$?
    fi
    if [[ ${status:-1} -ne 0 ]]; then
      # Fallback: run without PTY to avoid terminal quirks (e.g., notebooks).
      "${cmd_line[@]}" 2>&1 | tee "$tmp_output"
      status=${PIPESTATUS[0]}
    fi
  else
    "$CODEX_REAL_BIN" "$@" 2>&1 | tee "$tmp_output"
    status=${PIPESTATUS[0]}
  fi
  set -e
  if [[ -f "$tmp_output" ]]; then
    send_token_usage_if_present "$tmp_output"
    rm -f "$tmp_output"
  fi
  return "$status"
}

	if [[ -n "${CODEX_PROFILE_CANDIDATE:-}" ]]; then
	  candidate="$CODEX_PROFILE_CANDIDATE"
	  CODEX_PROFILE_CANDIDATE=""
	  if [[ "$candidate" =~ ^[A-Za-z0-9_-]+$ && -f "$CONFIG_PATH" ]] && grep -qE "^[[:space:]]*\\[profiles\\.${candidate}\\][[:space:]]*$" "$CONFIG_PATH"; then
	    set -- --profile "$candidate" "$@"
	  else
	    set -- "$candidate" "$@"
	  fi
	fi

	if [[ -n "$CODEX_HOST_MODEL" ]]; then
	  set -- --model "$CODEX_HOST_MODEL" "$@"
	fi

if [[ -n "$CODEX_HOST_REASONING_EFFORT" ]]; then
  set -- --reasoning-effort "$CODEX_HOST_REASONING_EFFORT" "$@"
fi

CODEX_COMMAND_STARTED=1
if run_codex_command "$@"; then
  cmd_status=0
else
  cmd_status=$?
fi
push_auth_if_changed "push" || true
exit "$cmd_status"

