#!/usr/bin/env bash
set -euo pipefail

# Fancy-ish log strings
if [[ -t 1 ]]; then
  BOLD="\033[1m"
  DIM="\033[2m"
  GREEN="\033[32m"
  YELLOW="\033[33m"
  ORANGE="\033[38;5;208m"
  BLUE="\033[36m"
  RED="\033[31m"
  RESET="\033[0m"
else
  BOLD=""
  DIM=""
  GREEN=""
  YELLOW=""
  ORANGE=""
  BLUE=""
  RED=""
  RESET=""
fi

log_info() { printf "%b» %s%b\n" "${BLUE}${BOLD}" "$1" "${RESET}"; }
log_warn() { printf "%b! %s%b\n" "${YELLOW}${BOLD}" "$1" "${RESET}" >&2; }
log_error() { printf "%bx %s%b\n" "${RED}${BOLD}" "$1" "${RESET}" >&2; }
log_debug() {
  (( CODEX_DEBUG )) && printf "%b[debug]%b %s\n" "${DIM}" "${RESET}" "$1" >&2
  return 0
}

MOTD_TEXT="$(cat <<'EOF'
  ██████╗ ██████╗ ██████╗ ███████╗██╗  ██╗
 ██╔════╝██╔═══██╗██╔══██╗██╔════╝╚██╗██╔╝
 ██║     ██║   ██║██║  ██║█████╗   ╚███╔╝ 
 ██║     ██║   ██║██║  ██║██╔══╝   ██╔██╗ 
 ╚██████╗╚██████╔╝██████╔╝███████╗██╔╝ ██╗
  ╚═════╝ ╚═════╝ ╚═════╝ ╚══════╝╚═╝  ╚═╝
                                           
  ██████╗ ██████╗  ██████╗ ██████╗ ██████╗ ██╗███╗   ██╗ █████╗ ████████╗ ██████╗ ██████╗ 
 ██╔════╝██╔═══██╗██╔═══██╗██╔══██╗██╔══██╗██║████╗  ██║██╔══██╗╚══██╔══╝██╔═══██╗██╔══██╗
 ██║     ██║   ██║██║   ██║██████╔╝██║  ██║██║██╔██╗ ██║███████║   ██║   ██║   ██║██████╔╝
 ██║     ██║   ██║██║   ██║██╔══██╗██║  ██║██║██║╚██╗██║██╔══██║   ██║   ██║   ██║██╔══██╗
 ╚██████╗╚██████╔╝╚██████╔╝██║  ██║██████╔╝██║██║ ╚████║██║  ██║   ██║   ╚██████╔╝██║  ██║
  ╚═════╝ ╚═════╝  ╚═════╝ ╚═╝  ╚═╝╚═════╝ ╚═╝╚═╝  ╚═══╝╚═╝  ╚═╝   ╚═╝    ╚═════╝ ╚═╝  ╚═╝
EOF
)"

print_motd() {
  while IFS= read -r line; do
    printf "%b %s%b\n" "${ORANGE}${BOLD}" "$line" "${RESET}"
  done <<<"$MOTD_TEXT"
}

mask_key() {
  local key="$1"
  if [[ -z "$key" ]]; then
    printf 'none'
    return
  fi
  local len=${#key}
  if (( len <= 8 )); then
    printf '%s' "$key"
  else
    printf '%s…%s' "${key:0:4}" "${key: -4}"
  fi
}

CODEX_DEBUG=${CODEX_DEBUG:-0}
CODEX_NO_PTY=${CODEX_NO_PTY:-0}
CODEX_NO_SCRIPT=${CODEX_NO_SCRIPT:-0}
CODEX_FORCE_WRAPPER_UPDATE=0
CODEX_EXIT_AFTER_UPDATE=0

# Per-host baked configuration (populated by the server at download time).
CODEX_SYNC_BAKED=${CODEX_SYNC_BAKED:-1}
CODEX_SYNC_BASE_URL_DEFAULT="__CODEX_SYNC_BASE_URL__"
CODEX_SYNC_BASE_URL="${CODEX_SYNC_BASE_URL:-$CODEX_SYNC_BASE_URL_DEFAULT}"
CODEX_SYNC_API_KEY="${CODEX_SYNC_API_KEY:-__CODEX_SYNC_API_KEY__}"
CODEX_SYNC_FQDN="${CODEX_SYNC_FQDN:-__CODEX_SYNC_FQDN__}"
CODEX_SYNC_CA_FILE="${CODEX_SYNC_CA_FILE:-__CODEX_SYNC_CA_FILE__}"
CODEX_SYNC_CONFIG_PATHS=()
SYNC_CONFIG_LOADED=0
SYNC_WARNED_NO_PYTHON=0
CODEX_COMMAND_STARTED=0
SYNC_PUSH_COMPLETED=0
ORIGINAL_LAST_REFRESH=""
AUTH_PUSH_RESULT=""
AUTH_PUSH_REASON=""
AUTH_STATUS=""
AUTH_ACTION=""
AUTH_MESSAGE=""
SYNC_REMOTE_CLIENT_VERSION=""
SYNC_REMOTE_WRAPPER_VERSION=""
SYNC_REMOTE_WRAPPER_SHA256=""
SYNC_REMOTE_WRAPPER_URL=""
AUTH_PULL_STATUS="skip"
AUTH_PULL_URL=""
LOCAL_AUTH_IS_FRESH=0
last_usage_payload=""
CHATGPT_STATUS=""
CHATGPT_PLAN=""
CHATGPT_NEXT=""
CHATGPT_PRIMARY_USED=""
CHATGPT_PRIMARY_LIMIT=""
CHATGPT_PRIMARY_RESET_AFTER=""
CHATGPT_PRIMARY_RESET_AT=""
CHATGPT_SECONDARY_USED=""
CHATGPT_SECONDARY_LIMIT=""
CHATGPT_SECONDARY_RESET_AFTER=""
CHATGPT_SECONDARY_RESET_AT=""
HOST_API_CALLS=""
HOST_TOKENS_MONTH_TOTAL=""
HOST_TOKENS_MONTH_INPUT=""
HOST_TOKENS_MONTH_OUTPUT=""
HOST_TOKENS_MONTH_CACHED=""
HOST_TOKENS_MONTH_REASONING=""
HOST_TOKENS_MONTH_EVENTS=""
PROMPT_DIR="$HOME/.codex/prompts"
PROMPT_BASELINE_FILE="$HOME/.codex/.prompt-baseline.json"
PROMPT_SYNC_STATUS="skip"
PROMPT_PULL_UPDATED=0
PROMPT_PULL_ERRORS=0
PROMPT_PUSHED=0
PROMPT_PUSH_ERRORS=0
PROMPT_PUSH_STATUS=""

WRAPPER_VERSION="2025.11.26-12"
MAX_LOCAL_AUTH_AGE_SECONDS=$((24 * 3600))

IS_ROOT=0
CAN_SUDO=0
SUDO_BIN="sudo -n"
if (( EUID == 0 )); then
  IS_ROOT=1
elif command -v sudo >/dev/null 2>&1; then
  if sudo -n true >/dev/null 2>&1; then
    CAN_SUDO=1
  fi
fi

CURRENT_USER="$(id -un 2>/dev/null || echo unknown)"

# Early one-shot commands
case "${1-}" in
  --wrapper-version|-W)
    printf 'cdx wrapper %s\n' "$WRAPPER_VERSION"
    exit 0
    ;;
  --uninstall)
    cmd_uninstall
    ;;
  --update|-U)
    CODEX_FORCE_WRAPPER_UPDATE=1
    CODEX_EXIT_AFTER_UPDATE=1
    shift
    ;;
esac

case "${1-}" in
  --debug|--verbose)
    CODEX_DEBUG=1
    shift
    ;;
esac

if (( ! IS_ROOT )); then
  # Only auto-install when we can sudo and we're the expected user (chris)
  if (( CAN_SUDO == 0 )) || [[ "$CURRENT_USER" != "chris" ]]; then
    log_info "Non-root execution detected; skipping automatic Codex install/update."
  fi
fi
log_debug "starting | user=${CURRENT_USER} | can_manage=${CAN_SUDO} | path=$PATH"

detect_linux_package_manager() {
  local tokens=()
  if [[ -r /etc/os-release ]]; then
    # shellcheck disable=SC1091
    . /etc/os-release
    if [[ -n "${ID:-}" ]]; then
      tokens+=("$ID")
    fi
    if [[ -n "${ID_LIKE:-}" ]]; then
      local like
      for like in $ID_LIKE; do
        tokens+=("$like")
      done
    fi
  fi
  local token
  for token in "${tokens[@]}"; do
    case "$token" in
      debian|ubuntu)
        if command -v apt-get >/dev/null 2>&1; then
          printf '%s' apt-get
          return 0
        fi
        ;;
      rhel|centos|fedora|almalinux|rocky|ol)
        if command -v dnf >/dev/null 2>&1; then
          printf '%s' dnf
          return 0
        fi
        ;;
    esac
  done
  if command -v apt-get >/dev/null 2>&1; then
    printf '%s' apt-get
    return 0
  fi
  if command -v dnf >/dev/null 2>&1; then
    printf '%s' dnf
    return 0
  fi
  return 1
}

with_sudo() {
  if (( EUID == 0 )); then
    "$@"
  elif command -v sudo >/dev/null 2>&1; then
    sudo "$@"
  else
    return 1
  fi
}

remove_path() {
  local path="$1"
  local label="$2"
  [[ -z "$path" || "$path" == "/" ]] && return 0
  if rm -rf "$path" 2>/dev/null; then
    log_info "Removed $label ($path)"
    return 0
  fi
  if with_sudo rm -rf "$path" 2>/dev/null; then
    log_info "Removed $label ($path) with sudo"
    return 0
  fi
  log_warn "Unable to remove $label ($path)"
  return 1
}

maybe_home() {
  local user="$1"
  local home=""
  if command -v getent >/dev/null 2>&1; then
    home="$(getent passwd "$user" | cut -d: -f6 2>/dev/null || true)"
  fi
  [[ -z "$home" ]] && home="/home/$user"
  printf '%s\n' "$home"
}

uninstall_api_deregister() {
  local base="${CODEX_SYNC_BASE_URL%/}"
  local key="$CODEX_SYNC_API_KEY"
  local cafile="$CODEX_SYNC_CA_FILE"
  if [[ -z "$base" || -z "$key" ]]; then
    log_warn "Skipping API deregistration (missing base URL or API key)"
    return
  fi
  local url="${base}/auth?force=1"
  local args=(-fsS -X DELETE -H "X-API-Key: ${key}")
  [[ -n "$cafile" ]] && args+=(--cacert "$cafile")
  if curl "${args[@]}" "$url" >/dev/null 2>&1; then
    log_info "API deregistration succeeded"
  else
    log_warn "API deregistration failed (continuing cleanup)"
  fi
}

cmd_uninstall() {
  log_info "Starting Codex uninstall"
  uninstall_api_deregister

  # Legacy env/config files
  remove_path "/usr/local/etc/codex-sync.env" "sync env (system)"
  remove_path "/etc/codex-sync.env" "sync env (system-legacy)"
  remove_path "$HOME/.codex/sync.env" "sync env (user)"

  # Auth + state per user (current, chris, root)
  local users=("$CURRENT_USER" "chris" "root")
  local seen=()
  local u home
  for u in "${users[@]}"; do
    local skip=0
    for existing in "${seen[@]}"; do
      [[ "$existing" == "$u" ]] && skip=1 && break
    done
    (( skip )) && continue
    seen+=("$u")
    home="$(maybe_home "$u")"
    [[ ! -d "$home" ]] && continue
    remove_path "$home/.codex/auth.json" "auth.json for $u"
    remove_path "$home/.codex" ".codex dir for $u"
  done

  # Binaries and install dirs
  remove_path "/usr/local/bin/cdx" "cdx binary"
  remove_path "$HOME/.local/bin/cdx" "cdx binary (user)"
  remove_path "/usr/local/bin/codex" "codex binary"
  remove_path "$HOME/.local/bin/codex" "codex binary (user)"
  remove_path "/opt/codex" "/opt/codex directory"

  # NPM global package (best effort)
  if command -v npm >/dev/null 2>&1; then
    if npm list -g codex-cli --depth=0 >/dev/null 2>&1; then
      if (( EUID == 0 )); then
        npm uninstall -g codex-cli >/dev/null 2>&1 || log_warn "npm uninstall codex-cli failed"
      else
        with_sudo npm uninstall -g codex-cli >/dev/null 2>&1 || npm uninstall -g codex-cli >/dev/null 2>&1 || log_warn "npm uninstall codex-cli failed"
      fi
      log_info "Removed npm codex-cli (if present)"
    fi
  fi

  log_info "Codex uninstall complete"
  exit 0
}

ensure_commands() {
  local missing=()
  local cmd
  for cmd in "$@"; do
    if ! command -v "$cmd" >/dev/null 2>&1; then
      missing+=("$cmd")
    fi
  done

  if (( ${#missing[@]} == 0 )); then
    return 0
  fi

  if [[ "$(uname -s)" != "Linux" ]]; then
    log_error "Missing required commands: ${missing[*]}. Automatic installation is only supported on Linux."
    exit 1
  fi

  local pm=""
  if ! pm="$(detect_linux_package_manager)"; then
    log_error "Missing required commands: ${missing[*]}. Unable to determine package manager for automatic installation."
    exit 1
  fi

  local use_sudo=()
  if (( EUID != 0 )); then
    if command -v sudo >/dev/null 2>&1; then
      use_sudo=(sudo)
    else
      log_error "Missing required commands: ${missing[*]}. Install them manually or rerun Codex as root to allow automatic installation."
      exit 1
    fi
  fi

  case "$pm" in
    apt-get)
      log_info "Installing prerequisites (${missing[*]}) with apt-get"
      if (( ${#use_sudo[@]} > 0 )); then
        "${use_sudo[@]}" apt-get update -qq
        "${use_sudo[@]}" env DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends "${missing[@]}"
      else
        apt-get update -qq
        DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends "${missing[@]}"
      fi
      ;;
    dnf)
      log_info "Installing prerequisites (${missing[*]}) with dnf"
      if (( ${#use_sudo[@]} > 0 )); then
        "${use_sudo[@]}" dnf install -y "${missing[@]}"
      else
        dnf install -y "${missing[@]}"
      fi
      ;;
    *)
      log_error "Unsupported package manager: ${pm}"
      exit 1
      ;;
  esac

  local still_missing=()
  for cmd in "${missing[@]}"; do
    if ! command -v "$cmd" >/dev/null 2>&1; then
      still_missing+=("$cmd")
    fi
  done

  if (( ${#still_missing[@]} > 0 )); then
    log_error "Failed to install required commands: ${still_missing[*]}"
    exit 1
  fi
}

is_codex_installed_via_npm() {
  if ! command -v npm >/dev/null 2>&1; then
    return 1
  fi
  if npm list -g codex-cli --depth=0 >/dev/null 2>&1; then
    return 0
  fi
  return 1
}

update_codex_via_npm() {
  local target="$1"
  if ! command -v npm >/dev/null 2>&1; then
    return 1
  fi
  if [[ -z "$target" ]]; then
    npm install -g codex-cli >/dev/null
  else
    npm install -g "codex-cli@$target" >/dev/null
  fi
}

real_path() {
  if command -v realpath >/dev/null 2>&1; then
    realpath "$1"
  elif command -v python3 >/dev/null 2>&1; then
    python3 - "$1" <<'PY'
import os, sys
print(os.path.realpath(sys.argv[1]))
PY
  else
    # best effort fallback
    local dir
    dir="$(cd "$(dirname "$1")" 2>/dev/null && pwd)"
    printf '%s/%s\n' "${dir:-.}" "$(basename "$1")"
  fi
}

get_file_mtime() {
  if stat --version >/dev/null 2>&1; then
    stat -c %Y "$1"
  else
    stat -f %m "$1"
  fi
}

resolve_real_codex() {
  local self_real
  self_real="$(real_path "$0")"
  local prefer_paths=(
    /usr/local/bin/codex
    /opt/codex/bin/codex
  )
  local preferred=""
  for preferred in "${prefer_paths[@]}"; do
    if [[ -x "$preferred" ]]; then
      local preferred_real
      preferred_real="$(real_path "$preferred")"
      if [[ "$preferred_real" != "$self_real" ]]; then
        printf '%s' "$preferred_real"
        return 0
      fi
    fi
  done
  local found=""
  IFS=: read -r -a path_entries <<< "${PATH:-}"
  for entry in "${path_entries[@]}"; do
    [[ -z "$entry" ]] && entry="."
    local candidate="$entry/codex"
    [[ ! -x "$candidate" ]] && continue
    local candidate_real
    candidate_real="$(real_path "$candidate")"
    if [[ "$candidate_real" == "$self_real" ]]; then
      continue
    fi
    found="$candidate_real"
    break
  done
  if [[ -z "$found" && -x /usr/local/bin/codex ]]; then
    found="$(real_path /usr/local/bin/codex)"
  fi
  printf '%s' "$found"
}

normalize_version() {
  local v="$1"
  v="${v#codex-cli }"
  v="${v#codex }"
  v="${v#rust-}"
  v="${v#v}"
  printf '%s' "$v"
}

detect_glibc_version() {
  local version=""
  if command -v getconf >/dev/null 2>&1; then
    local gc
    gc="$(getconf GNU_LIBC_VERSION 2>/dev/null || true)"
    if [[ "$gc" =~ ([0-9]+\.[0-9]+) ]]; then
      version="${BASH_REMATCH[1]}"
    fi
  fi
  if [[ -z "$version" ]]; then
    if command -v ldd >/dev/null 2>&1; then
      local first
      first="$(ldd --version 2>&1 | head -n1)"
      if [[ "$first" =~ ([0-9]+\.[0-9]+) ]]; then
        version="${BASH_REMATCH[1]}"
      fi
    fi
  fi
  printf '%s' "$version"
}

version_lt() {
  local a="$1"
  local b="$2"
  [[ "$a" == "$b" ]] && return 1
  if [[ "$(printf '%s\n%s\n' "$a" "$b" | sort -V | head -n1)" == "$a" ]]; then
    return 0
  fi
  return 1
}

probe_latest_version_tag() {
  local url="${1:-https://github.com/openai/codex/releases/latest}"
  if ! command -v curl >/dev/null 2>&1; then
    return 1
  fi
  local effective
  if ! effective="$(curl -fsSLI -o /dev/null -w '%{url_effective}' -L "$url" 2>/dev/null)"; then
    return 1
  fi
  if [[ "$effective" =~ /tag/([^/]+)$ ]]; then
    printf '%s' "${BASH_REMATCH[1]}"
    return 0
  fi
  return 1
}

require_python() {
  if ! command -v python3 >/dev/null 2>&1; then
    log_warn "python3 is required for update checks; skipping update detection."
    return 1
  fi
  return 0
}

parse_sync_env_file() {
  local path="$1"
  local key value
  while IFS='=' read -r key value; do
    value="${value%$'\r'}"
    case "$key" in
      ''|\#*) continue ;;
    esac
    case "$key" in
      CODEX_SYNC_BASE_URL)
        CODEX_SYNC_BASE_URL="${value%/}"
        ;;
      CODEX_SYNC_API_KEY)
        CODEX_SYNC_API_KEY="$value"
        ;;
      CODEX_SYNC_FQDN)
        CODEX_SYNC_FQDN="$value"
        ;;
      CODEX_SYNC_CA_FILE)
        CODEX_SYNC_CA_FILE="$value"
        ;;
    esac
  done <"$path"
}

load_sync_config() {
  if (( SYNC_CONFIG_LOADED )); then
    return 0
  fi
  if [[ "${CODEX_SYNC_BAKED:-0}" -eq 1 ]]; then
    log_debug "config (baked) | base=${CODEX_SYNC_BASE_URL} | api_key=$(mask_key "$CODEX_SYNC_API_KEY") | fqdn=${CODEX_SYNC_FQDN:-none} | ca=${CODEX_SYNC_CA_FILE:-none}"
    SYNC_CONFIG_LOADED=1
    return 0
  fi
  local path=""
  for path in "${CODEX_SYNC_CONFIG_PATHS[@]}"; do
    [[ -z "$path" ]] && continue
    if [[ -f "$path" ]]; then
      parse_sync_env_file "$path"
      log_debug "loaded sync env: $path"
    fi
  done
  if [[ -z "$CODEX_SYNC_BASE_URL" ]]; then
    CODEX_SYNC_BASE_URL="$CODEX_SYNC_BASE_URL_DEFAULT"
  fi
  log_debug "config | base=${CODEX_SYNC_BASE_URL} | api_key=$(mask_key "$CODEX_SYNC_API_KEY") | fqdn=${CODEX_SYNC_FQDN:-none} | ca=${CODEX_SYNC_CA_FILE:-none}"
  SYNC_CONFIG_LOADED=1
}

sync_auth_with_api() {
  local phase="$1"
  load_sync_config
  if [[ -z "$CODEX_SYNC_API_KEY" || -z "$CODEX_SYNC_BASE_URL" ]]; then
    log_error "Sync config missing API key or base URL; download a fresh cdx wrapper from the server."
    AUTH_PULL_STATUS="missing-config"
    AUTH_PULL_URL="$CODEX_SYNC_BASE_URL"
    return 1
  fi
  if ! command -v python3 >/dev/null 2>&1; then
    if (( SYNC_WARNED_NO_PYTHON == 0 )); then
      log_warn "python3 is required for Codex auth sync; skipping API synchronization."
      SYNC_WARNED_NO_PYTHON=1
    fi
    return 1
  fi
  local auth_path="$HOME/.codex/auth.json"
   # Drop a malformed local auth.json so we can hydrate cleanly.
  if [[ -f "$auth_path" ]] && ! validate_auth_json_file "$auth_path"; then
    rm -f "$auth_path"
  fi
  local phase_label
  phase_label="${phase:-sync}"
  # No chatty per-step auth logging; final summary will capture the outcome.
  local api_output=""
  local api_status=0
  if api_output="$(python3 - "$CODEX_SYNC_BASE_URL" "$CODEX_SYNC_API_KEY" "$auth_path" "$CODEX_SYNC_CA_FILE" "$LOCAL_VERSION" "$WRAPPER_VERSION" <<'PY'
import hashlib, json, os, pathlib, ssl, sys, urllib.error, urllib.request

base = (sys.argv[1] or "").rstrip("/")
api_key = sys.argv[2]
path = pathlib.Path(sys.argv[3]).expanduser()
cafile = sys.argv[4] if len(sys.argv) > 4 else ""
client_version = sys.argv[5] if len(sys.argv) > 5 else "unknown"
wrapper_version = sys.argv[6] if len(sys.argv) > 6 else "unknown"

if not base:
    print("Sync API base URL missing", file=sys.stderr)
    sys.exit(1)


def default_auth():
    return {"last_refresh": "2000-01-01T00:00:00Z", "auths": {}}


def load_auth():
    try:
        data = json.loads(path.read_text(encoding="utf-8"))
    except Exception:  # noqa: BLE001
        return default_auth()
    if not isinstance(data, dict) or "last_refresh" not in data:
        return default_auth()
    return data


def canonical_json(obj):
    return json.dumps(obj, ensure_ascii=False, separators=(",", ":"))


def build_context():
    contexts = []
    # Preferred: custom CA if provided
    ctx_primary = ssl.create_default_context()
    if cafile:
        try:
            ctx_primary.load_verify_locations(cafile)
        except Exception:
            ctx_primary = None
    if ctx_primary is not None:
        try:
            ctx_primary.verify_flags &= ~ssl.VERIFY_X509_STRICT
        except AttributeError:
            pass
        contexts.append(ctx_primary)
    # Fallback: system default
    try:
        ctx_default = ssl.create_default_context()
        ctx_default.verify_flags &= ~ssl.VERIFY_X509_STRICT
        contexts.append(ctx_default)
    except Exception:
        pass
    # Last resort: unverified (only if others fail)
    try:
        contexts.append(ssl._create_unverified_context())
    except Exception:
        pass
    return contexts or [None]


def parse_error_body(body: str):
    msg = body
    details = {}
    try:
        parsed = json.loads(body)
        if isinstance(parsed, dict):
            msg = parsed.get("message", body)
            details = parsed.get("details", {}) or {}
    except Exception:
        pass
    return msg, details


def fail_with_http(exc: urllib.error.HTTPError, action: str):
    body = exc.read().decode("utf-8", "ignore")
    msg, details = parse_error_body(body)
    expected_ip = details.get("expected_ip") if isinstance(details, dict) else None
    received_ip = details.get("received_ip") if isinstance(details, dict) else None
    extra = ""
    if expected_ip or received_ip:
        parts = []
        if expected_ip:
            parts.append(f"expected {expected_ip}")
        if received_ip:
            parts.append(f"received {received_ip}")
        extra = " (" + ", ".join(parts) + ")"
    if exc.code == 401:
        if "Invalid API key" in msg:
            sys.exit(10)
        if "API key missing" in msg:
            sys.exit(21)
        sys.exit(22)
    if exc.code == 403:
        if "Host is disabled" in msg:
            sys.exit(11)
        if "not allowed from this IP" in msg or expected_ip or received_ip:
            print(f"{action} denied (IP bound){extra}", file=sys.stderr)
            sys.exit(12)
        sys.exit(23)
    if exc.code == 503 and "disabled" in msg.lower():
        print("api disabled", file=sys.stderr)
        sys.exit(40)
    print(f"{action} failed ({exc.code}): {msg}{extra}", file=sys.stderr)
    sys.exit(2)


def post_json(url: str, payload: dict, action: str):
    body = canonical_json(payload).encode("utf-8")
    headers = {"Content-Type": "application/json", "X-API-Key": api_key}
    req = urllib.request.Request(url, data=body, headers=headers, method="POST")
    contexts = build_context()
    last_err = None
    for ctx in contexts:
        try:
            with urllib.request.urlopen(req, timeout=20, context=ctx) as resp:
                return json.load(resp)
        except urllib.error.HTTPError as exc:
            fail_with_http(exc, action)
        except Exception as exc:  # noqa: BLE001
            last_err = exc
            continue
    print(f"{action} failed: {last_err}", file=sys.stderr)
    sys.exit(3)


current = load_auth()
auth_json = canonical_json(current)
auth_sha = hashlib.sha256(auth_json.encode("utf-8")).hexdigest()

retrieve_payload = {
    "command": "retrieve",
    "last_refresh": current.get("last_refresh") or "2000-01-01T00:00:00Z",
    "digest": auth_sha,
    "client_version": client_version or "unknown",
}
if wrapper_version and wrapper_version != "unknown":
    retrieve_payload["wrapper_version"] = wrapper_version

retrieve_data = post_json(f"{base}/auth", retrieve_payload, "auth retrieve")
payload_data = retrieve_data.get("data") if isinstance(retrieve_data, dict) else {}
status = (payload_data or {}).get("status")
versions_block = payload_data.get("versions") if isinstance(payload_data, dict) else {}
canonical_digest = payload_data.get("canonical_digest") or payload_data.get("digest")
auth_to_write = None
chatgpt_usage = payload_data.get("chatgpt_usage") if isinstance(payload_data, dict) else {}


def record_versions(vblock):
    out = {}
    if isinstance(vblock, dict):
        cv = vblock.get("client_version")
        if isinstance(cv, str) and cv.strip():
            out["client_version"] = cv.strip()
        wv = vblock.get("wrapper_version")
        if isinstance(wv, str) and wv.strip():
            out["wrapper_version"] = wv.strip()
        ws = vblock.get("wrapper_sha256")
        if isinstance(ws, str) and ws.strip():
            out["wrapper_sha256"] = ws.strip()
        wu = vblock.get("wrapper_url")
        if isinstance(wu, str) and wu.strip():
            out["wrapper_url"] = wu.strip()
    return out


def window(value):
    return value if isinstance(value, dict) else {}


versions_out = record_versions(versions_block)
if versions_out.get("client_version"):
    SYNC_REMOTE_CLIENT_VERSION = versions_out.get("client_version")
if versions_out.get("wrapper_version"):
    SYNC_REMOTE_WRAPPER_VERSION = versions_out.get("wrapper_version")
if versions_out.get("wrapper_sha256"):
    SYNC_REMOTE_WRAPPER_SHA256 = versions_out.get("wrapper_sha256")
if versions_out.get("wrapper_url"):
    SYNC_REMOTE_WRAPPER_URL = versions_out.get("wrapper_url")

primary_window = window(chatgpt_usage.get("primary_window"))
secondary_window = window(chatgpt_usage.get("secondary_window"))

if status == "valid":
    auth_to_write = current
elif status == "outdated":
    auth_to_write = payload_data.get("auth") or current
    lr = payload_data.get("canonical_last_refresh") or payload_data.get("last_refresh")
    if isinstance(lr, str):
        auth_to_write["last_refresh"] = lr
elif status in ("missing", "upload_required"):
    pass
else:
    status = "upload_required"

if status in ("missing", "upload_required"):
    store_payload = {
        "command": "store",
        "auth": current,
        "client_version": client_version or "unknown",
    }
    if canonical_digest:
        store_payload["digest"] = canonical_digest
    if wrapper_version and wrapper_version != "unknown":
        store_payload["wrapper_version"] = wrapper_version
    update_data = post_json(f"{base}/auth", store_payload, "auth store")
    payload_data = update_data.get("data") if isinstance(update_data, dict) else {}
    versions_out = record_versions(payload_data.get("versions", {})) or versions_out
    auth_to_write = payload_data.get("auth") or current
    lr = payload_data.get("canonical_last_refresh") or payload_data.get("last_refresh")
    if isinstance(lr, str):
        auth_to_write["last_refresh"] = lr

if not isinstance(auth_to_write, dict):
    auth_to_write = current

path.parent.mkdir(parents=True, exist_ok=True)
path.write_text(json.dumps(auth_to_write, indent=2) + "\n", encoding="utf-8")
try:
    os.chmod(path, 0o600)
except PermissionError:
    pass

# Surface versions and auth outcome to caller via stdout as JSON
print(
    json.dumps(
        {
            "versions": versions_out,
            "auth_status": status or "unknown",
            "auth_action": ("store" if status in ("missing", "upload_required") else status or "unknown"),
            "auth_message": (
                "synced (no change)" if status == "valid" else
                "updated from api" if status == "outdated" else
                "uploaded current auth" if status in ("missing", "upload_required") else
                status
            ),
            "chatgpt_status": chatgpt_usage.get("status"),
            "chatgpt_plan": chatgpt_usage.get("plan_type"),
            "chatgpt_next": chatgpt_usage.get("next_eligible_at"),
            "chatgpt_primary_used": primary_window.get("used_percent"),
            "chatgpt_primary_limit": primary_window.get("limit_seconds"),
            "chatgpt_primary_reset_after": primary_window.get("reset_after_seconds"),
            "chatgpt_primary_reset_at": primary_window.get("reset_at"),
            "chatgpt_secondary_used": secondary_window.get("used_percent"),
            "chatgpt_secondary_limit": secondary_window.get("limit_seconds"),
            "chatgpt_secondary_reset_after": secondary_window.get("reset_after_seconds"),
            "chatgpt_secondary_reset_at": secondary_window.get("reset_at"),
            "api_calls": payload_data.get("api_calls"),
            "token_usage_month": payload_data.get("token_usage_month"),
        },
        separators=(",", ":"),
    )
)
PY
  )"; then
    log_debug "auth api output: ${api_output}"
    local versions_json
    versions_json="$api_output"
    if [[ -n "$versions_json" ]] && command -v python3 >/dev/null 2>&1; then
      local parsed
      parsed="$(VJSON="$versions_json" python3 - <<'PY'
import json, os, sys
data = os.environ.get("VJSON", "")
try:
    parsed = json.loads(data)
except Exception:
    sys.exit(0)
if not isinstance(parsed, dict):
    sys.exit(0)
versions = parsed.get("versions")
if not isinstance(versions, dict):
    sys.exit(0)
cv = versions.get("client_version")
wv = versions.get("wrapper_version")
ws = versions.get("wrapper_sha256")
wu = versions.get("wrapper_url")
if isinstance(cv, str) and cv.strip():
    print(f"cv={cv.strip()}")
if isinstance(wv, str) and wv.strip():
    print(f"wv={wv.strip()}")
if isinstance(ws, str) and ws.strip():
    print(f"ws={ws.strip()}")
if isinstance(wu, str) and wu.strip():
    print(f"wu={wu.strip()}")
asv = parsed.get("auth_status")
if isinstance(asv, str) and asv.strip():
    print(f"as={asv.strip()}")
aact = parsed.get("auth_action")
if isinstance(aact, str) and aact.strip():
    print(f"aa={aact.strip()}")
amsg = parsed.get("auth_message")
if isinstance(amsg, str) and amsg.strip():
    print(f"am={amsg.strip()}")
cgst = parsed.get("chatgpt_status")
if isinstance(cgst, str) and cgst.strip():
    print(f"cgs={cgst.strip()}")
cgpl = parsed.get("chatgpt_plan")
if isinstance(cgpl, str) and cgpl.strip():
    print(f"cgp={cgpl.strip()}")
cgnx = parsed.get("chatgpt_next")
if isinstance(cgnx, str) and cgnx.strip():
    print(f"cgn={cgnx.strip()}")
def _emit_int(key, prefix):
    if isinstance(key, (int, float)):
        print(f"{prefix}={int(key)}")
cp_u = parsed.get("chatgpt_primary_used")
_emit_int(cp_u, "cgu")
cp_l = parsed.get("chatgpt_primary_limit")
_emit_int(cp_l, "cgl")
cp_r = parsed.get("chatgpt_primary_reset_after")
_emit_int(cp_r, "cgr")
cp_a = parsed.get("chatgpt_primary_reset_at")
if isinstance(cp_a, str) and cp_a.strip():
    print(f"cga={cp_a.strip()}")
cs_u = parsed.get("chatgpt_secondary_used")
_emit_int(cs_u, "cgsu")
cs_l = parsed.get("chatgpt_secondary_limit")
_emit_int(cs_l, "cgsl")
cs_r = parsed.get("chatgpt_secondary_reset_after")
_emit_int(cs_r, "cgsr")
cs_a = parsed.get("chatgpt_secondary_reset_at")
if isinstance(cs_a, str) and cs_a.strip():
    print(f"cgsa={cs_a.strip()}")
api_calls = parsed.get("api_calls")
_emit_int(api_calls, "hac")
month_usage = parsed.get("token_usage_month")
if isinstance(month_usage, dict):
    def _emit_month(key, prefix):
        val = month_usage.get(key)
        _emit_int(val, prefix)
    _emit_month("total", "hmtotal")
    _emit_month("input", "hminput")
    _emit_month("output", "hmoutput")
    _emit_month("cached", "hmcached")
    _emit_month("reasoning", "hmreason")
    _emit_month("events", "hmevents")
PY
)" || true
      if [[ -n "$parsed" ]]; then
        local line
        while IFS= read -r line; do
          case "$line" in
            cv=*)
              SYNC_REMOTE_CLIENT_VERSION="${line#cv=}"
              ;;
            wv=*)
              SYNC_REMOTE_WRAPPER_VERSION="${line#wv=}"
              ;;
            ws=*)
              SYNC_REMOTE_WRAPPER_SHA256="${line#ws=}"
              ;;
            wu=*)
              SYNC_REMOTE_WRAPPER_URL="${line#wu=}"
              ;;
            as=*)
              AUTH_STATUS="${line#as=}"
              ;;
            aa=*)
              AUTH_ACTION="${line#aa=}"
              ;;
            am=*)
              AUTH_MESSAGE="${line#am=}"
              ;;
            cgs=*)
              CHATGPT_STATUS="${line#cgs=}"
              ;;
            cgp=*)
              CHATGPT_PLAN="${line#cgp=}"
              ;;
            cgn=*)
              CHATGPT_NEXT="${line#cgn=}"
              ;;
            cgu=*)
              CHATGPT_PRIMARY_USED="${line#cgu=}"
              ;;
            cgl=*)
              CHATGPT_PRIMARY_LIMIT="${line#cgl=}"
              ;;
            cgr=*)
              CHATGPT_PRIMARY_RESET_AFTER="${line#cgr=}"
              ;;
            cga=*)
              CHATGPT_PRIMARY_RESET_AT="${line#cga=}"
              ;;
            cgsu=*)
              CHATGPT_SECONDARY_USED="${line#cgsu=}"
              ;;
            cgsl=*)
              CHATGPT_SECONDARY_LIMIT="${line#cgsl=}"
              ;;
            cgsr=*)
              CHATGPT_SECONDARY_RESET_AFTER="${line#cgsr=}"
              ;;
            cgsa=*)
              CHATGPT_SECONDARY_RESET_AT="${line#cgsa=}"
              ;;
            hac=*)
              HOST_API_CALLS="${line#hac=}"
              ;;
            hmtotal=*)
              HOST_TOKENS_MONTH_TOTAL="${line#hmtotal=}"
              ;;
            hminput=*)
              HOST_TOKENS_MONTH_INPUT="${line#hminput=}"
              ;;
            hmoutput=*)
              HOST_TOKENS_MONTH_OUTPUT="${line#hmoutput=}"
              ;;
            hmcached=*)
              HOST_TOKENS_MONTH_CACHED="${line#hmcached=}"
              ;;
            hmreason=*)
              HOST_TOKENS_MONTH_REASONING="${line#hmreason=}"
              ;;
            hmevents=*)
              HOST_TOKENS_MONTH_EVENTS="${line#hmevents=}"
              ;;
          esac
        done <<<"$parsed"
      fi
    fi
    AUTH_PULL_STATUS="ok"
    AUTH_PULL_URL="$CODEX_SYNC_BASE_URL"
    return 0
  else
    api_status=$?
  fi
  case "$api_status" in
    10)
      log_warn "Auth sync denied: invalid API key; removing local auth.json"
      AUTH_PULL_STATUS="invalid"
      rm -f "$auth_path" 2>/dev/null || true
      return 1
      ;;
    11)
      log_warn "Auth sync denied: host disabled; removing local auth.json"
      rm -f "$auth_path" 2>/dev/null || true
      return 1
      ;;
    12)
      log_warn "Auth sync blocked for this IP (key bound elsewhere); re-register to rotate the key. Keeping local auth.json."
      return 1
      ;;
    21|22)
      log_warn "Auth sync failed: API key missing/invalid"
      return 1
      ;;
    2|3)
      if [[ -n "$phase" ]]; then
        log_warn "Auth API sync (${phase}) unreachable (base=${CODEX_SYNC_BASE_URL}, key=$(mask_key "$CODEX_SYNC_API_KEY"))"
      else
        log_warn "Auth API sync unreachable (base=${CODEX_SYNC_BASE_URL}, key=$(mask_key "$CODEX_SYNC_API_KEY"))"
      fi
      AUTH_PULL_STATUS="offline"
      AUTH_PULL_URL="$CODEX_SYNC_BASE_URL"
      return 1
      ;;
    40)
      log_warn "Auth sync blocked: API disabled by administrator"
      AUTH_PULL_STATUS="disabled"
      AUTH_PULL_URL="$CODEX_SYNC_BASE_URL"
      return 1
      ;;
    *)
      if [[ -n "$phase" ]]; then
        log_warn "Auth API sync (${phase}) failed (base=${CODEX_SYNC_BASE_URL}, key=$(mask_key "$CODEX_SYNC_API_KEY"))"
      else
        log_warn "Auth API sync failed (base=${CODEX_SYNC_BASE_URL}, key=$(mask_key "$CODEX_SYNC_API_KEY"))"
      fi
      AUTH_PULL_STATUS="fail"
      AUTH_PULL_URL="$CODEX_SYNC_BASE_URL"
      return 1
      ;;
  esac
  return 1
}

get_auth_last_refresh() {
  local path="$1"
  if [[ ! -f "$path" ]]; then
    return 0
  fi
  if ! command -v python3 >/dev/null 2>&1; then
    return 0
  fi
 python3 - "$path" <<'PY'
import json, sys, pathlib
path = pathlib.Path(sys.argv[1])
try:
    data = json.loads(path.read_text(encoding="utf-8"))
except Exception:  # noqa: BLE001
    sys.exit(0)
if isinstance(data, dict):
    lr = data.get("last_refresh")
    if isinstance(lr, str):
        print(lr, end="")
PY
}

is_last_refresh_recent() {
  local last_refresh="$1"
  local max_age_seconds="${2:-$MAX_LOCAL_AUTH_AGE_SECONDS}"
  if [[ -z "$last_refresh" ]]; then
    return 1
  fi
  if ! command -v python3 >/dev/null 2>&1; then
    return 1
  fi
  python3 - "$last_refresh" "$max_age_seconds" <<'PY'
import sys, datetime
from datetime import timezone

value = sys.argv[1]
max_age_seconds = int(sys.argv[2])
max_future_skew = 300
try:
    dt = datetime.datetime.fromisoformat(value.replace("Z", "+00:00"))
    if dt.tzinfo is None:
        dt = dt.replace(tzinfo=timezone.utc)
    now = datetime.datetime.now(timezone.utc)
    delta = now - dt
except Exception:  # noqa: BLE001
    sys.exit(1)

if delta.total_seconds() < -max_future_skew:
    sys.exit(1)
if delta.total_seconds() <= max_age_seconds:
    sys.exit(0)
sys.exit(1)
PY
}

validate_auth_json_file() {
  local path="$1"
  if [[ ! -f "$path" ]]; then
    return 1
  fi
  if ! command -v python3 >/dev/null 2>&1; then
    return 1
  fi
  python3 - "$path" <<'PY'
import json, sys, pathlib

path = pathlib.Path(sys.argv[1])
try:
    data = json.loads(path.read_text(encoding="utf-8"))
except Exception:  # noqa: BLE001
    sys.exit(1)

if not isinstance(data, dict):
    sys.exit(1)

last_refresh = data.get("last_refresh")
auths = data.get("auths")

if not isinstance(last_refresh, str) or not last_refresh.strip():
    sys.exit(1)

if not isinstance(auths, dict) or not auths:
    sys.exit(1)

for target, entry in auths.items():
    if not isinstance(target, str) or not target.strip():
        sys.exit(1)
    if not isinstance(entry, dict):
        sys.exit(1)
    token = entry.get("token")
    if not isinstance(token, str) or not token.strip():
        sys.exit(1)

sys.exit(0)
PY
}

push_auth_if_changed() {
  local phase="${1:-push}"
  local auth_path="$HOME/.codex/auth.json"
  local refreshed
  refreshed="$(get_auth_last_refresh "$auth_path")"
  # No local auth present
  if [[ -z "$ORIGINAL_LAST_REFRESH" && -z "$refreshed" ]]; then
    AUTH_PUSH_RESULT="skipped"
    AUTH_PUSH_REASON="no local auth.json"
    return 0
  fi
  if [[ "$refreshed" == "$ORIGINAL_LAST_REFRESH" ]]; then
    AUTH_PUSH_RESULT="not-needed"
    AUTH_PUSH_REASON="auth.json unchanged"
    return 0
  fi
  if sync_auth_with_api "$phase"; then
    SYNC_PUSH_COMPLETED=1
    AUTH_PUSH_RESULT="uploaded"
    AUTH_PUSH_REASON="auth.json changed"
    return 0
  fi
  AUTH_PUSH_RESULT="failed"
  AUTH_PUSH_REASON="api sync error"
  return 1
}

prompt_sync_python() {
  local mode="$1"
  local base="$2"
  local api_key="$3"
  local prompt_dir="$4"
  local cafile="$5"
  local baseline_file="$6"
  python3 - "$mode" "$base" "$api_key" "$prompt_dir" "$cafile" "$baseline_file" <<'PY'
import hashlib, json, pathlib, ssl, sys, urllib.error, urllib.request

mode = sys.argv[1] if len(sys.argv) > 1 else ""
base = (sys.argv[2] or "").rstrip("/")
api_key = sys.argv[3] if len(sys.argv) > 3 else ""
prompt_dir = pathlib.Path(sys.argv[4]).expanduser()
cafile = sys.argv[5] if len(sys.argv) > 5 else ""
baseline_file = pathlib.Path(sys.argv[6]).expanduser() if len(sys.argv) > 6 else prompt_dir.parent / ".prompt-baseline.json"


def contexts():
    ctxs = []
    primary = ssl.create_default_context()
    if cafile:
        try:
            primary.load_verify_locations(cafile)
        except Exception:
            primary = None
    if primary is not None:
        try:
            primary.verify_flags &= ~ssl.VERIFY_X509_STRICT
        except AttributeError:
            pass
        ctxs.append(primary)
    try:
        fallback = ssl.create_default_context()
        fallback.verify_flags &= ~ssl.VERIFY_X509_STRICT
        ctxs.append(fallback)
    except Exception:
        pass
    try:
        ctxs.append(ssl._create_unverified_context())
    except Exception:
        pass
    return ctxs or [None]


def request_json(method: str, url: str, payload=None):
    data = None
    headers = {"X-API-Key": api_key}
    if payload is not None:
        data = json.dumps(payload, ensure_ascii=False, separators=(",", ":")).encode("utf-8")
        headers["Content-Type"] = "application/json"
    req = urllib.request.Request(url, data=data, headers=headers, method=method)
    last_err = None
    for ctx in contexts():
        try:
            with urllib.request.urlopen(req, timeout=20, context=ctx) as resp:
                return json.load(resp)
        except urllib.error.HTTPError as exc:  # noqa: PERF203
            body = exc.read().decode("utf-8", "ignore")
            reason = f"http-{exc.code}"
            if body:
                reason = f"{reason}:{body.strip()[:80]}"
            raise RuntimeError(reason) from exc
        except Exception as exc:  # noqa: BLE001
            last_err = exc
            continue
    raise RuntimeError(f"request failed: {last_err}")


def parse_front_matter(text: str):
    description = None
    argument_hint = None
    lines = text.splitlines()
    if not lines or lines[0].strip() != "---":
        return description, argument_hint
    end_idx = None
    for idx in range(1, len(lines)):
        if lines[idx].strip() == "---":
            end_idx = idx
            break
    if end_idx is None:
        return description, argument_hint
    for idx in range(1, end_idx):
        line = lines[idx].strip()
        if not line or ":" not in line:
            continue
        key, value = line.split(":", 1)
        key = key.strip().lower()
        value = value.strip()
        if key == "description":
            description = value
        elif key == "argument-hint":
            argument_hint = value
    return description, argument_hint


def load_local(include_content: bool = False):
    prompt_dir.mkdir(parents=True, exist_ok=True)
    prompts = {}
    for path in prompt_dir.iterdir():
        if not path.is_file():
            continue
        try:
            content = path.read_text(encoding="utf-8")
        except Exception:  # noqa: BLE001
            continue
        sha = hashlib.sha256(content.encode("utf-8")).hexdigest()
        entry = {"filename": path.name, "sha": sha}
        if include_content:
            entry["content"] = content
        prompts[path.name] = entry
    return prompts


def save_baseline(prompts: dict):
    try:
        baseline_file.parent.mkdir(parents=True, exist_ok=True)
        baseline_file.write_text(json.dumps(prompts, indent=2) + "\n", encoding="utf-8")
    except Exception:  # noqa: BLE001
        pass


if not base:
    print("error reason=missing-base")
    sys.exit(1)
if not api_key:
    print("error reason=missing-api-key")
    sys.exit(1)

prompt_dir.mkdir(parents=True, exist_ok=True)

if mode == "pull":
    try:
        list_resp = request_json("GET", f"{base}/slash-commands")
    except Exception as exc:  # noqa: BLE001
        print(f"error reason={str(exc).replace(' ', '_')}")
        sys.exit(1)

    commands = []
    if isinstance(list_resp, dict):
        data = list_resp.get("data") or {}
        commands = data.get("commands") or []
    downloaded = 0
    errors = 0
    local = load_local()

    for cmd in commands:
        if not isinstance(cmd, dict):
            continue
        fname = cmd.get("filename")
        rsha = cmd.get("sha256")
        if not fname or not rsha:
            continue
        local_sha = (local.get(fname) or {}).get("sha")
        if local_sha and local_sha == rsha:
            continue
        payload = {"filename": fname}
        if local_sha:
            payload["sha256"] = local_sha
        try:
            resp = request_json("POST", f"{base}/slash-commands/retrieve", payload)
        except Exception as exc:  # noqa: BLE001
            errors += 1
            continue
        data = resp.get("data") if isinstance(resp, dict) else {}
        status = (data or {}).get("status")
        prompt = (data or {}).get("prompt")
        if status == "unchanged":
            continue
        if not isinstance(prompt, str):
            errors += 1
            continue
        try:
            (prompt_dir / fname).write_text(prompt, encoding="utf-8")
            downloaded += 1
        except Exception:  # noqa: BLE001
            errors += 1

    baseline = {name: entry["sha"] for name, entry in load_local().items()}
    remote_names = {cmd["filename"] for cmd in commands if isinstance(cmd, dict) and cmd.get("filename")}
    filtered_baseline = {name: sha for name, sha in baseline.items() if name in remote_names}
    save_baseline(filtered_baseline)
    print(f"ok updated={downloaded} errors={errors}")
    sys.exit(0)

if mode == "push":
    if not baseline_file.exists():
        print("skip reason=no-baseline errors=0")
        sys.exit(0)
    try:
        baseline_data = json.loads(baseline_file.read_text(encoding="utf-8"))
    except Exception:  # noqa: BLE001
        baseline_data = {}
    if not isinstance(baseline_data, dict):
        baseline_data = {}

    current = load_local(include_content=True)
    changes = []
    for name, entry in current.items():
        if baseline_data.get(name) != entry.get("sha"):
            changes.append(entry)

    if not changes:
        print("ok pushed=0 errors=0")
        sys.exit(0)

    errors = 0
    pushed = 0
    for entry in changes:
        fname = entry.get("filename")
        content = entry.get("content")
        sha = entry.get("sha")
        if not fname or not content or not sha:
            continue
        desc, arg_hint = parse_front_matter(content)
        payload = {
            "filename": fname,
            "prompt": content,
            "sha256": sha,
        }
        if desc:
            payload["description"] = desc
        if arg_hint:
            payload["argument_hint"] = arg_hint
        try:
            resp = request_json("POST", f"{base}/slash-commands/store", payload)
        except Exception:  # noqa: BLE001
            errors += 1
            continue
        data = resp.get("data") if isinstance(resp, dict) else {}
        status = (data or {}).get("status")
        if status in ("created", "updated", "unchanged"):
            pushed += 1
        else:
            errors += 1

    if errors == 0:
        latest_baseline = {name: entry["sha"] for name, entry in current.items()}
        save_baseline(latest_baseline)

    print(f"ok pushed={pushed} errors={errors}")
    sys.exit(0)

print("skip reason=unknown-mode errors=0")
PY
}

sync_slash_commands_pull() {
  load_sync_config
  if [[ -z "$CODEX_SYNC_API_KEY" || -z "$CODEX_SYNC_BASE_URL" ]]; then
    PROMPT_SYNC_STATUS="missing-config"
    return 1
  fi
  if ! command -v python3 >/dev/null 2>&1; then
    PROMPT_SYNC_STATUS="no-python"
    log_warn "python3 is required for slash command sync; skipping."
    return 1
  fi
  local summary status_code
  set +e
  summary="$(prompt_sync_python pull "$CODEX_SYNC_BASE_URL" "$CODEX_SYNC_API_KEY" "$PROMPT_DIR" "$CODEX_SYNC_CA_FILE" "$PROMPT_BASELINE_FILE")"
  status_code=$?
  set -e
  PROMPT_SYNC_STATUS="error"
  if (( status_code != 0 )); then
    [[ -n "$summary" ]] && log_warn "Slash command sync failed: $summary" || log_warn "Slash command sync failed."
    PROMPT_PULL_ERRORS=1
    return 1
  fi
  local part
  PROMPT_SYNC_STATUS="${summary%% *}"
  for part in $summary; do
    case "$part" in
      updated=*) PROMPT_PULL_UPDATED="${part#updated=}" ;;
      errors=*) PROMPT_PULL_ERRORS="${part#errors=}" ;;
    esac
  done
  return 0
}

push_slash_commands_if_changed() {
  load_sync_config
  if [[ -z "$CODEX_SYNC_API_KEY" || -z "$CODEX_SYNC_BASE_URL" ]]; then
    PROMPT_PUSH_STATUS="missing-config"
    return 0
  fi
  if [[ ! -f "$PROMPT_BASELINE_FILE" ]]; then
    PROMPT_PUSH_STATUS="no-baseline"
    return 0
  fi
  if ! command -v python3 >/dev/null 2>&1; then
    PROMPT_PUSH_STATUS="no-python"
    return 0
  fi
  local summary status_code
  set +e
  summary="$(prompt_sync_python push "$CODEX_SYNC_BASE_URL" "$CODEX_SYNC_API_KEY" "$PROMPT_DIR" "$CODEX_SYNC_CA_FILE" "$PROMPT_BASELINE_FILE")"
  status_code=$?
  set -e
  PROMPT_PUSH_STATUS="error"
  if (( status_code != 0 )); then
    [[ -n "$summary" ]] && log_warn "Slash command push failed: $summary" || log_warn "Slash command push failed."
    PROMPT_PUSH_ERRORS=1
    return 1
  fi
  local part
  PROMPT_PUSH_STATUS="${summary%% *}"
  for part in $summary; do
    case "$part" in
      pushed=*) PROMPT_PUSHED="${part#pushed=}" ;;
      errors=*) PROMPT_PUSH_ERRORS="${part#errors=}" ;;
    esac
  done
  return 0
}

extract_token_usage_payload() {
  local log_path="$1"
  if [[ ! -f "$log_path" ]]; then
    return 0
  fi
  if ! command -v python3 >/dev/null 2>&1; then
    return 0
  fi
  python3 - "$log_path" <<'PY'
import json, pathlib, re, sys

path = pathlib.Path(sys.argv[1])
try:
    content = path.read_text(encoding="utf-8", errors="ignore")
except Exception:  # noqa: BLE001
    sys.exit(0)

ansi_csi = re.compile(r"\x1B\[[0-9;?]*[ -/]*[@-~]")
ansi_osc = re.compile(r"\x1B\][^\a\x1b]*[\a\x1b\\]")
control = re.compile(r"[\x00-\x08\x0b\x0c\x0e-\x1f\x7f]")


def strip_noise(text: str) -> str:
    text = ansi_osc.sub("", text)
    text = ansi_csi.sub("", text)
    text = control.sub("", text)
    return text


cleaned = strip_noise(content)
lines = [ln.strip() for ln in cleaned.splitlines() if "token usage" in ln.lower()]
if not lines:
    sys.exit(0)

pattern = re.compile(
    r"Token usage:\s*total=(?P<total>[\d,]+)\s+input=(?P<input>[\d,]+)(?:\s*\(\+\s*(?P<cached>[\d,]+)\s*cached\))?\s+output=(?P<output>[\d,]+)(?:\s*\(reasoning\s*(?P<reasoning>[\d,]+)\))?",
    re.IGNORECASE,
)
kv_pattern = re.compile(r"\b(total|input|output|cached|reasoning)\s*[:=]\s*([\d,][\d,]*)", re.IGNORECASE)


def clean_int(val: str | None) -> int | None:
    if val is None:
        return None
    try:
        return int(val.replace(",", ""))
    except Exception:
        return None


entries: list[dict[str, object]] = []
for raw in lines:
    entry: dict[str, object] = {}
    safe_line = raw.strip()
    if len(safe_line) > 240:
        safe_line = safe_line[:240] + "…"

    match = pattern.search(raw)
    if match:
        entry["total"] = clean_int(match.group("total"))
        entry["input"] = clean_int(match.group("input"))
        entry["output"] = clean_int(match.group("output"))
        cached_val = clean_int(match.group("cached"))
        if cached_val is not None:
            entry["cached"] = cached_val
        reasoning_val = clean_int(match.group("reasoning"))
        if reasoning_val is not None:
            entry["reasoning"] = reasoning_val
    else:
        for key, value in kv_pattern.findall(raw):
            cleaned_val = clean_int(value)
            if cleaned_val is not None:
                entry[key.lower()] = cleaned_val
        cached_match = re.search(r"\(\+\s*([\d,]+)\s*cached", raw, re.IGNORECASE)
        if cached_match:
            cached_val = clean_int(cached_match.group(1))
            if cached_val is not None:
                entry["cached"] = cached_val

    if safe_line:
        entry["line"] = safe_line

    if entry:
        entries.append(entry)

if not entries:
    sys.exit(0)

print(json.dumps({"usages": entries}, separators=(",", ":")))
PY
}

post_token_usage_payload() {
  local payload_json="$1"
  if [[ -z "$payload_json" ]]; then
    return 0
  fi
  if [[ -z "$CODEX_SYNC_API_KEY" || -z "$CODEX_SYNC_BASE_URL" ]]; then
    log_warn "Usage push skipped: API key or base URL missing"
    return 1
  fi
  if ! command -v python3 >/dev/null 2>&1; then
    log_warn "Usage push skipped: python3 missing"
    return 1
  fi

  local summary=""
  if summary="$(python3 - "$CODEX_SYNC_BASE_URL" "$CODEX_SYNC_API_KEY" "$payload_json" "$CODEX_SYNC_CA_FILE" <<'PY'
import json, ssl, sys, urllib.error, urllib.request

base = (sys.argv[1] or "").rstrip("/")
api_key = sys.argv[2]
payload_raw = sys.argv[3]
cafile = sys.argv[4] if len(sys.argv) > 4 else ""

try:
    payload = json.loads(payload_raw)
except Exception:  # noqa: BLE001
    sys.exit(1)

body = json.dumps(payload, separators=(",", ":")).encode("utf-8")
headers = {"Content-Type": "application/json", "X-API-Key": api_key}
url = f"{base}/usage"
req = urllib.request.Request(url, data=body, headers=headers, method="POST")


def build_contexts():
    contexts = []
    try:
        ctx = ssl.create_default_context()
        if cafile:
            ctx.load_verify_locations(cafile)
        try:
            ctx.verify_flags &= ~ssl.VERIFY_X509_STRICT
        except Exception:
            pass
        contexts.append(ctx)
    except Exception:
        pass
    try:
        contexts.append(ssl._create_unverified_context())
    except Exception:
        pass
    return contexts or [None]


def format_summary(data: dict) -> str:
    def summarize(entry: dict) -> str:
        parts = []
        for key in ("total", "input", "output", "cached", "reasoning"):
            if isinstance(entry.get(key), int):
                parts.append(f"{key}={entry[key]}")
        if not parts and entry.get("line"):
            return entry["line"]
        return " ".join(parts)

    usages = data.get("usages")
    if isinstance(usages, list) and usages:
        latest = usages[-1] if isinstance(usages[-1], dict) else {}
        summary = summarize(latest if isinstance(latest, dict) else {})
        if len(usages) > 1:
            return f"{len(usages)} rows" + (f" | {summary}" if summary else "")
        return summary

    parts = []
    for key in ("total", "input", "output", "cached", "reasoning"):
        if key in data and data[key] is not None:
            parts.append(f"{key}={data[key]}")
    if not parts and data.get("line"):
        return data["line"]
    return " ".join(parts)


last_err = None
for ctx in build_contexts():
    try:
        with urllib.request.urlopen(req, timeout=10, context=ctx) as resp:  # noqa: S310
            resp.read(512)
            print(format_summary(payload))
            sys.exit(0)
    except urllib.error.HTTPError as exc:
        body = ""
        try:
            body = exc.read().decode("utf-8", "replace")
        except Exception:
            body = ""
        body_snip = (body or "").replace("\n", " ").strip()
        if len(body_snip) > 160:
            body_snip = body_snip[:160] + "…"
        last_err = f"HTTP {exc.code}" + (f": {body_snip}" if body_snip else "")
        continue
    except Exception as exc:  # noqa: BLE001
        last_err = str(exc)
        continue

if last_err:
    print(last_err)
sys.exit(1)
PY
  )"; then
    log_info "Usage push | ok | ${summary}"
    return 0
  fi

  local primary_err="$summary"

  # Fallback: retry without the freeform line if present (avoid bad payloads/escape debris)
  if [[ "$payload_json" == *'"line"'* ]]; then
    local fallback_payload=""
    fallback_payload="$(python3 - "$payload_json" <<'PY'
import json, sys
try:
    data = json.loads(sys.argv[1])
except Exception:  # noqa: BLE001
    sys.exit(1)
if "line" in data:
    data.pop("line", None)
usages = data.get("usages")
if isinstance(usages, list):
    cleaned = []
    for entry in usages:
        if isinstance(entry, dict):
            entry.pop("line", None)
            if entry:
                cleaned.append(entry)
    data["usages"] = cleaned
print(json.dumps(data, separators=(",", ":")))
PY
    )" || fallback_payload=""
    if [[ -n "$fallback_payload" && "$fallback_payload" != "$payload_json" ]]; then
      summary=""
      if summary="$(python3 - "$CODEX_SYNC_BASE_URL" "$CODEX_SYNC_API_KEY" "$fallback_payload" "$CODEX_SYNC_CA_FILE" <<'PY'
import json, ssl, sys, urllib.error, urllib.request

base = (sys.argv[1] or "").rstrip("/")
api_key = sys.argv[2]
payload_raw = sys.argv[3]
cafile = sys.argv[4] if len(sys.argv) > 4 else ""

payload = json.loads(payload_raw)
body = json.dumps(payload, separators=(",", ":")).encode("utf-8")
headers = {"Content-Type": "application/json", "X-API-Key": api_key}
url = f"{base}/usage"
req = urllib.request.Request(url, data=body, headers=headers, method="POST")

ctx = ssl.create_default_context()
if cafile:
    try:
        ctx.load_verify_locations(cafile)
    except Exception:
        pass
try:
    with urllib.request.urlopen(req, timeout=10, context=ctx) as resp:  # noqa: S310
        resp.read(512)
        print("fallback")
        sys.exit(0)
except Exception as exc:  # noqa: BLE001
    print(str(exc))
    sys.exit(1)
PY
      )"; then
        log_info "Usage push | ok (fallback) | ${summary}"
        return 0
      else
        [[ -z "$primary_err" ]] && primary_err="$summary"
      fi
    fi
  fi

  if [[ -z "$primary_err" ]]; then
    primary_err="unknown error"
  fi
  log_warn "Usage push | failed | ${primary_err}"
  return 1
}

parse_usage_summary() {
  local payload_json="$1"
  local summary=""
  summary="$(python3 - "$payload_json" <<'PY'
import json, sys
try:
    data = json.loads(sys.argv[1])
except Exception:  # noqa: BLE001
    sys.exit(0)

usages = data.get("usages")
entry = {}
if isinstance(usages, list) and usages:
    last = usages[-1]
    if isinstance(last, dict):
        entry = last
else:
    entry = data if isinstance(data, dict) else {}

parts = []
total = entry.get("total")
inp = entry.get("input")
out = entry.get("output")
cached = entry.get("cached")
reasoning = entry.get("reasoning")
if isinstance(total, int):
    parts.append(f"sent={total}")
if isinstance(inp, int):
    parts.append(f"input={inp}")
if isinstance(out, int):
    parts.append(f"output={out}")
if isinstance(cached, int):
    parts.append(f"cached={cached}")
if isinstance(reasoning, int):
    parts.append(f"reasoning={reasoning}")
if isinstance(usages, list) and len(usages) > 1:
    parts.append(f"rows={len(usages)}")
if parts:
    print(", ".join(parts))
PY
  )" || summary=""
  printf "%s" "$summary"
}

send_token_usage_if_present() {
  local log_path="$1"
  local payload
  payload="$(extract_token_usage_payload "$log_path")" || return 0
  if [[ -z "$payload" ]]; then
    return 0
  fi

  last_usage_payload="$payload"
  post_token_usage_payload "$payload" || true
}

fetch_release_payload() {
  local api_url="$1"
  local wanted_asset="$2"
  python3 - "$api_url" "$wanted_asset" <<'PY'
import json, sys, time, urllib.request
url = sys.argv[1]
wanted = sys.argv[2]
headers = {
    "Accept": "application/vnd.github+json",
    "User-Agent": "codex-wrapper-update-check"
}
try:
    req = urllib.request.Request(url, headers=headers)
    with urllib.request.urlopen(req, timeout=15) as resp:
        data = json.load(resp)
except Exception as exc:  # noqa: BLE001
    print(f"error: {exc}", file=sys.stderr)
    sys.exit(1)
name = data.get("name") or data.get("tag_name") or ""
assets = data.get("assets") or []
asset = None
if wanted:
    for candidate in assets:
        if candidate.get("name") == wanted:
            asset = candidate
            break
if asset is None:
    for candidate in assets:
        if candidate.get("name") == "codex":
            asset = candidate
            break
if asset is None:
    print("error: could not find a matching release asset", file=sys.stderr)
    sys.exit(2)
payload = {
    "timestamp": int(time.time()),
    "version": name,
    "tag": data.get("tag_name") or "",
    "asset_name": asset.get("name", ""),
    "download_url": asset.get("browser_download_url", "")
}
json.dump(payload, sys.stdout, separators=(",", ":"))
PY
}

read_cached_payload() {
  local cache_file="$1"
  python3 - "$cache_file" <<'PY'
import json, sys
with open(sys.argv[1], 'r', encoding='utf-8') as fh:
    data = json.load(fh)
print(data.get('version', ''))
print(data.get('download_url', ''))
print(data.get('asset_name', ''))
print(data.get('timestamp', 0))
print(data.get('tag', ''))
PY
}

perform_update() (
  set -euo pipefail
  local target_path="$1"
  local url="$2"
  local asset_name="$3"
  local new_version="$4"
  local tmpdir
  tmpdir="$(mktemp -d)"
  trap 'rm -rf "$tmpdir"' EXIT
  log_info "Downloading Codex ${new_version}"
  local asset_file="$tmpdir/asset"
  if ! curl -fsSL "$url" -o "$asset_file"; then
    log_error "Download failed from $url"
    exit 1
  fi
  local extracted="$asset_file"
  case "$asset_name" in
    *.tar.gz)
      tar -xzf "$asset_file" -C "$tmpdir"
      # pick the first executable named codex*
      extracted="$(find "$tmpdir" -type f -name 'codex*' ! -name 'asset' | head -n1)"
      ;;
    *.zip)
      if ! command -v unzip >/dev/null 2>&1; then
        log_error "unzip is required to handle $asset_name"
        exit 1
      fi
      unzip -q "$asset_file" -d "$tmpdir"
      extracted="$(find "$tmpdir" -type f -name 'codex*' | head -n1)"
      ;;
  esac
  if [[ -z "$extracted" || ! -f "$extracted" ]]; then
    log_error "Unable to locate Codex binary inside downloaded asset"
    exit 1
  fi
  chmod +x "$extracted"
  local target_dir
  target_dir="$(dirname "$target_path")"
  if [[ ! -d "$target_dir" ]]; then
    log_error "Target directory $target_dir does not exist"
    exit 1
  fi
  if [[ -w "$target_dir" ]]; then
    log_info "Installing Codex into $target_path"
    install -m 755 "$extracted" "$target_path"
  else
    if (( CAN_SUDO )); then
      log_info "Installing Codex into $target_path with sudo -n"
      $SUDO_BIN install -m 755 "$extracted" "$target_path"
    else
      log_warn "Insufficient permissions to install Codex into $target_path (no sudo)."
      exit 1
    fi
  fi
  log_info "Codex updated to ${new_version}"
)

API_RELEASES_URL="https://api.github.com/repos/openai/codex/releases"

SCRIPT_REAL="$(real_path "$0")"
CODEX_REAL_BIN="$(resolve_real_codex)"
if [[ -z "$CODEX_REAL_BIN" ]]; then
  log_error "Unable to find the real Codex binary on PATH"
  exit 1
fi

platform_os="$(uname -s 2>/dev/null || echo unknown)"
platform_arch="$(uname -m 2>/dev/null || echo unknown)"
print_motd

can_manage_codex=0
if (( IS_ROOT )); then
  can_manage_codex=1
elif (( CAN_SUDO )) && [[ "$CURRENT_USER" == "chris" ]]; then
  can_manage_codex=1
fi

if (( can_manage_codex )) && [[ "$(uname -s)" == "Linux" ]]; then
  ensure_commands curl unzip
fi

LOCAL_VERSION_RAW="$("$CODEX_REAL_BIN" -V 2>/dev/null || true)"
LOCAL_VERSION="$(normalize_version "$LOCAL_VERSION_RAW")"
LOCAL_VERSION_UNKNOWN=0
if [[ -z "$LOCAL_VERSION" ]]; then
  LOCAL_VERSION_UNKNOWN=1
  log_warn "Could not determine local Codex version; attempting to refresh Codex before launch."
fi

# Early auth + versions sync (single POST), captures target versions and hydrates auth if needed.
sync_auth_with_api "pull" || true
sync_slash_commands_pull || true
ORIGINAL_LAST_REFRESH="$(get_auth_last_refresh "$HOME/.codex/auth.json")"
LOCAL_AUTH_IS_FRESH=0
if is_last_refresh_recent "$ORIGINAL_LAST_REFRESH" "$MAX_LOCAL_AUTH_AGE_SECONDS"; then
  LOCAL_AUTH_IS_FRESH=1
fi
HAS_LOCAL_AUTH=0
[[ -f "$HOME/.codex/auth.json" ]] && HAS_LOCAL_AUTH=1

os_name="$(uname -s)"
arch_name="$(uname -m)"
asset_name=""
skip_update_check=0
if (( ! can_manage_codex )); then
  skip_update_check=1
fi
case "$os_name" in
  Linux)
    case "$arch_name" in
      x86_64|amd64)
        asset_name="codex-x86_64-unknown-linux-gnu.tar.gz"
        glibc_version="$(detect_glibc_version)"
        if [[ -z "$glibc_version" ]]; then
          asset_name="codex-x86_64-unknown-linux-musl.tar.gz"
          log_info "Unable to detect glibc version; using musl Codex build for compatibility."
        elif version_lt "$glibc_version" "2.39"; then
          asset_name="codex-x86_64-unknown-linux-musl.tar.gz"
          log_info "glibc ${glibc_version} detected; using musl Codex build for compatibility."
        fi
        ;;
      aarch64|arm64)
        asset_name="codex-aarch64-unknown-linux-gnu.tar.gz"
        ;;
      *)
        log_warn "Unsupported Linux architecture (${arch_name}); skipping update check."
        skip_update_check=1
        ;;
    esac
    ;;
  *)
    log_warn "Non-Linux operating system (${os_name}) detected; skipping update check."
    skip_update_check=1
    ;;
esac

remote_version=""
remote_url=""
remote_asset=""
remote_tag=""
remote_source=""
remote_timestamp=0
prefer_npm_update=0

if (( ! skip_update_check )); then
  if [[ "$AUTH_PULL_STATUS" == "ok" && -n "$SYNC_REMOTE_CLIENT_VERSION" ]]; then
    remote_version="$(normalize_version "$SYNC_REMOTE_CLIENT_VERSION")"
    remote_tag="$remote_version"
    remote_timestamp="$(date +%s)"
    remote_source="api"
  elif [[ "$AUTH_PULL_STATUS" == "ok" ]]; then
    # API succeeded but no version provided; assume local is target to avoid noisy warnings.
    remote_version="$LOCAL_VERSION"
    remote_tag="$LOCAL_VERSION"
    remote_source="api"
  fi
fi

need_update=0
norm_remote=""
if (( ! skip_update_check )) && [[ -n "$remote_version" ]]; then
  norm_remote="$(normalize_version "$remote_version")"
  if (( LOCAL_VERSION_UNKNOWN )); then
    need_update=1
  else
    norm_local="$(normalize_version "$LOCAL_VERSION")"
    if [[ "$norm_remote" != "$norm_local" ]]; then
      if [[ "$(printf '%s\n%s\n' "$norm_local" "$norm_remote" | sort -V | tail -n1)" == "$norm_remote" ]]; then
        need_update=1
      fi
    fi
  fi
fi

if (( need_update )) && is_codex_installed_via_npm; then
  prefer_npm_update=1
fi

# If an update is needed but we don't yet have a download URL (e.g., version came from the API), fetch release metadata now.
if (( need_update )) && [[ -z "$remote_url" ]] && require_python; then
  tmp_payload="$(mktemp)"
  fetch_success=0
  candidate_tags=()
  add_tag() { local t="$1"; [[ -z "$t" ]] && return; for existing in "${candidate_tags[@]}"; do [[ "$existing" == "$t" ]] && return; done; candidate_tags+=("$t"); }
  add_tag "$remote_tag"
  add_tag "$remote_version"
  add_tag "v${remote_version}"
  add_tag "rust-${remote_version}"
  add_tag "rust-v${remote_version}"

  for tag_variant in "${candidate_tags[@]}"; do
    if payload_json="$(fetch_release_payload "${API_RELEASES_URL}/tags/${tag_variant}" "$asset_name" 2>/dev/null)"; then
      printf '%s\n' "$payload_json" > "$tmp_payload"
      if mapfile -t fresh_fields < <(read_cached_payload "$tmp_payload"); then
        remote_version="${fresh_fields[0]}"
        remote_url="${fresh_fields[1]}"
        remote_asset="${fresh_fields[2]}"
        remote_timestamp="${fresh_fields[3]}"
        remote_tag="${fresh_fields[4]}"
        fetch_success=1
        break
      fi
    fi
  done
  rm -f "$tmp_payload"
  if (( fetch_success == 0 )); then
    log_warn "Could not fetch release metadata for Codex ${remote_tag}"
  fi
fi

codex_update_attempted=0
codex_updated=0
codex_update_failed=0
codex_status_label=""
codex_status_note=""
codex_target_label=""
codex_installed_label="${LOCAL_VERSION:-unknown}"

if (( skip_update_check )); then
  codex_target_label="${remote_version:-${LOCAL_VERSION:-unknown}}"
  codex_status_label="Check skipped"
  codex_status_note="not permitted to manage Codex (need root)"
elif (( need_update )) && [[ -n "$remote_url" ]]; then
  display_local="${LOCAL_VERSION:-unknown}"
  codex_target_label="$norm_remote"
  codex_update_attempted=1
  if (( prefer_npm_update )) && update_codex_via_npm "$norm_remote"; then
    hash -r
    CODEX_REAL_BIN="$(resolve_real_codex)"
    LOCAL_VERSION_RAW="$("$CODEX_REAL_BIN" -V 2>/dev/null || true)"
    LOCAL_VERSION="$(normalize_version "$LOCAL_VERSION_RAW")"
    LOCAL_VERSION_UNKNOWN=0
    codex_updated=1
    codex_status_label="Updated"
    codex_status_note="npm codex-cli @${norm_remote}"
  elif perform_update "$CODEX_REAL_BIN" "$remote_url" "${remote_asset:-$asset_name}" "$norm_remote"; then
    hash -r
    CODEX_REAL_BIN="$(resolve_real_codex)"
    LOCAL_VERSION_RAW="$("$CODEX_REAL_BIN" -V 2>/dev/null || true)"
    LOCAL_VERSION="$(normalize_version "$LOCAL_VERSION_RAW")"
    LOCAL_VERSION_UNKNOWN=0
    codex_updated=1
    codex_status_label="Updated"
    codex_status_note="from API ${remote_tag:-latest}"
  else
    codex_update_failed=1
    codex_status_label="Update failed"
    codex_status_note="to ${norm_remote}"
    log_warn "Codex update failed (wanted ${norm_remote}, local ${display_local})"
  fi
else
  if [[ -n "$remote_version" ]]; then
    final_label="${remote_tag:-${remote_version}}"
    codex_target_label="$final_label"
    local_norm="$(normalize_version "$LOCAL_VERSION")"
    remote_norm="$(normalize_version "$final_label")"
    if [[ -n "$local_norm" && -n "$remote_norm" && "$local_norm" != "$remote_norm" ]]; then
      codex_status_label="Update available"
    else
      codex_status_label="Current"
    fi
  else
    codex_status_label="API unavailable"
    codex_target_label="n/a"
    codex_update_failed=1
    log_warn "Codex update check unavailable"
  fi
fi

if [[ -z "$codex_status_label" ]]; then
  codex_status_label="Current"
fi
codex_installed_label="${LOCAL_VERSION:-unknown}"

WRAPPER_VERSION_INITIAL="$WRAPPER_VERSION"
wrapper_update_attempted=0
wrapper_updated=0
wrapper_update_failed=0
wrapper_status_label="Current"
wrapper_status_note=""
wrapper_target_label="$WRAPPER_VERSION"

# Wrapper self-update (single latest version only)
wrapper_state="current (${WRAPPER_VERSION})"
target_wrapper=""
target_wrapper_sha=""
target_wrapper_url=""
wrapper_target_label="$WRAPPER_VERSION"

if [[ "$AUTH_PULL_STATUS" == "ok" || "$CODEX_FORCE_WRAPPER_UPDATE" == "1" ]]; then
  target_wrapper="${SYNC_REMOTE_WRAPPER_VERSION:-${WRAPPER_VERSION}}"
  target_wrapper_sha="${SYNC_REMOTE_WRAPPER_SHA256:-}"
  target_wrapper_url="${SYNC_REMOTE_WRAPPER_URL:-}"
  wrapper_target_label="${target_wrapper:-$WRAPPER_VERSION}"

  if [[ -z "$target_wrapper_url" ]] && [[ -n "$CODEX_SYNC_BASE_URL" ]]; then
    target_wrapper_url="${CODEX_SYNC_BASE_URL%/}/wrapper/download"
  fi
  if [[ -n "$target_wrapper_url" && "$target_wrapper_url" != http* ]]; then
    target_wrapper_url="${CODEX_SYNC_BASE_URL%/}${target_wrapper_url}"
  fi

  need_wrapper_update=0
  if [[ -n "$target_wrapper" && "$target_wrapper" != "$WRAPPER_VERSION" ]]; then
    need_wrapper_update=1
  fi
  if (( need_wrapper_update == 0 )) && [[ -n "$target_wrapper_sha" ]]; then
    if current_wrapper_sha="$(sha256sum "$SCRIPT_REAL" 2>/dev/null | awk '{print $1}')" && [[ -n "$current_wrapper_sha" ]]; then
      if [[ "$current_wrapper_sha" != "$target_wrapper_sha" ]]; then
        need_wrapper_update=1
      fi
    fi
  fi
  if (( CODEX_FORCE_WRAPPER_UPDATE )); then
    need_wrapper_update=1
    wrapper_status_note="forced update requested"
  fi

  if (( need_wrapper_update )) && [[ -n "$target_wrapper_url" ]]; then
    wrapper_update_attempted=1
    if [[ -z "$CODEX_SYNC_API_KEY" ]]; then
      log_warn "Wrapper update skipped: API key missing"
      wrapper_update_failed=1
      wrapper_status_label="Update skipped"
      wrapper_status_note="API key missing"
    else
      tmpdir="$(mktemp -d)"
      tmpwrapper="$tmpdir/cdx"
      curl_args=(-fsSL -H "X-API-Key: $CODEX_SYNC_API_KEY")
      if [[ -n "$CODEX_SYNC_CA_FILE" ]]; then
        curl_args+=("--cacert" "$CODEX_SYNC_CA_FILE")
      fi
      if curl "${curl_args[@]}" "$target_wrapper_url" -o "$tmpwrapper"; then
        dl_sha="$(sha256sum "$tmpwrapper" | awk '{print $1}')"
        if [[ -n "$target_wrapper_sha" && "$dl_sha" != "$target_wrapper_sha" ]]; then
          log_warn "Wrapper update skipped: hash mismatch (expected ${target_wrapper_sha}, got ${dl_sha})"
          wrapper_update_failed=1
          wrapper_status_label="Update skipped"
          wrapper_status_note="hash mismatch"
        else
          chmod +x "$tmpwrapper"
          if [[ -w "$(dirname "$SCRIPT_REAL")" ]]; then
            install -m 755 "$tmpwrapper" "$SCRIPT_REAL"
            WRAPPER_VERSION="$target_wrapper"
            wrapper_state="updated (${WRAPPER_VERSION})"
            wrapper_updated=1
            wrapper_status_label="Updated"
            if [[ "$WRAPPER_VERSION_INITIAL" != "$WRAPPER_VERSION" ]]; then
              wrapper_status_note="${wrapper_status_note:-from ${WRAPPER_VERSION_INITIAL}}"
            fi
          elif (( CAN_SUDO )); then
            if $SUDO_BIN install -m 755 "$tmpwrapper" "$SCRIPT_REAL"; then
              WRAPPER_VERSION="$target_wrapper"
              wrapper_state="updated (${WRAPPER_VERSION})"
              wrapper_updated=1
              wrapper_status_label="Updated"
              if [[ "$WRAPPER_VERSION_INITIAL" != "$WRAPPER_VERSION" ]]; then
                wrapper_status_note="${wrapper_status_note:-from ${WRAPPER_VERSION_INITIAL}}"
              fi
            else
              log_warn "Wrapper update failed: sudo install denied"
              wrapper_update_failed=1
              wrapper_status_label="Update failed"
              wrapper_status_note="sudo install denied"
            fi
          else
            log_warn "Wrapper update skipped: insufficient permissions to write $(dirname "$SCRIPT_REAL")"
            wrapper_update_failed=1
            wrapper_status_label="Update skipped"
            wrapper_status_note="no permission"
          fi
        fi
      else
        log_warn "Wrapper update failed: download error"
        wrapper_update_failed=1
        wrapper_status_label="Update failed"
        wrapper_status_note="download error"
      fi
      rm -rf "$tmpdir"
    fi
  elif (( need_wrapper_update )) && [[ -z "$target_wrapper_url" ]]; then
    log_warn "Wrapper update skipped: API did not provide download URL"
    wrapper_update_failed=1
    wrapper_status_label="Update skipped"
    wrapper_status_note="missing download URL"
  fi
fi

if (( CODEX_EXIT_AFTER_UPDATE )); then
  if (( wrapper_updated )); then
    log_info "Wrapper update completed (version ${WRAPPER_VERSION})."
    exit 0
  fi
  if (( wrapper_update_failed )); then
    log_error "Wrapper update failed (${wrapper_status_note:-unknown})."
    exit 1
  fi
  log_warn "Wrapper update not attempted (status ${wrapper_status_label})."
  exit 1
fi

human_join() {
  local items=("$@")
  local count=${#items[@]}
  if (( count == 0 )); then
    printf ''
  elif (( count == 1 )); then
    printf '%s' "${items[0]}"
  elif (( count == 2 )); then
    printf '%s and %s' "${items[0]}" "${items[1]}"
  else
    local last="${items[count-1]}"
    items=("${items[@]:0:count-1}")
    printf '%s, and %s' "$(printf '%s, ' "${items[@]}" | sed 's/, $//')" "$last"
  fi
}

join_with_semicolon() {
  local out=""
  local part
  for part in "$@"; do
    [[ -z "$part" ]] && continue
    if [[ -n "$out" ]]; then
      out+="; "
    fi
    out+="$part"
  done
  printf "%s" "$out"
}

colorize() {
  local text="$1" tone="$2"
  case "$tone" in
    green) printf "%b%s%b" "${GREEN}${BOLD}" "$text" "${RESET}" ;;
    yellow) printf "%b%s%b" "${YELLOW}${BOLD}" "$text" "${RESET}" ;;
    red) printf "%b%s%b" "${RED}${BOLD}" "$text" "${RESET}" ;;
    *) printf "%s" "$text" ;;
  esac
}

ROW_LABEL_WIDTH=12
ROW_VALUE_WIDTH=32
QUOTA_BAR_WIDTH=24

format_status_row() {
  local label="$1" col1="$2" col2="$3" col3="$4"
  printf "%-${ROW_LABEL_WIDTH}s | %-${ROW_VALUE_WIDTH}s | %-${ROW_VALUE_WIDTH}s | %s" "$label" "$col1" "$col2" "$col3"
}

format_simple_row() {
  local label="$1" text="$2"
  printf "%-${ROW_LABEL_WIDTH}s | %s" "$label" "$text"
}

format_quota_row() {
  local label="$1" text="$2" note="$3"
  printf "%-${ROW_LABEL_WIDTH}s | %-${ROW_VALUE_WIDTH}s | %s" "$label" "$text" "$note"
}

format_duration_short() {
  local seconds="$1"
  [[ "$seconds" =~ ^[0-9]+$ ]] || { printf ""; return; }
  local s=$seconds
  local days=$(( s / 86400 ))
  s=$(( s % 86400 ))
  local hours=$(( s / 3600 ))
  s=$(( s % 3600 ))
  local mins=$(( s / 60 ))
  local parts=()
  (( days > 0 )) && parts+=("${days}d")
  (( hours > 0 )) && parts+=("${hours}h")
  (( mins > 0 )) && parts+=("${mins}m")
  if (( ${#parts[@]} == 0 )); then
    parts=("<1m")
  fi
  printf "%s" "${parts[*]}"
}

render_quota_line() {
  local used="$1" reset_after="$2" reset_at="$3"
  local width=${QUOTA_BAR_WIDTH:-24}
  local tone="yellow"
  local text="n/a"
  local note=""

  if [[ "$used" =~ ^[0-9]+$ ]]; then
    local pct=$used
    (( pct < 0 )) && pct=0
    (( pct > 100 )) && pct=100
    local filled=$(( (pct * width + 50) / 100 ))
    (( filled > width )) && filled=$width
    local bar_filled
    local bar_empty
    bar_filled=$(printf '%*s' "$filled" "" | tr ' ' '#')
    bar_empty=$(printf '%*s' $(( width - filled )) "" | tr ' ' '.')
    if [[ "$reset_after" =~ ^[0-9]+$ ]]; then
      local dur
      dur=$(format_duration_short "$reset_after")
      [[ -n "$dur" ]] && note="resets in ${dur}"
    elif [[ -n "$reset_at" ]]; then
      note="resets @ ${reset_at}"
    fi

    if (( pct >= 95 )); then
      tone="red"
    elif (( pct >= 80 )); then
      tone="yellow"
    else
      tone="green"
    fi

    text=$(printf "%3d%% [%s%s]" "$pct" "$bar_filled" "$bar_empty")
  fi

  printf "%s\t%s\t%s" "$tone" "$text" "$note"
}

format_auth_label() {
  local status="$1" action="$2" msg="$3"
  local parts=()
  case "$status" in
    valid) parts+=("status valid (matches server)") ;;
    outdated) parts+=("status outdated (server newer)") ;;
    missing) parts+=("status missing (upload needed)") ;;
    upload_required) parts+=("status upload required (client newer)") ;;
    *)
      [[ -n "$status" ]] && parts+=("status ${status}")
      ;;
  esac
  case "$action" in
    valid) parts+=("no update needed") ;;
    store) parts+=("stored latest auth on server") ;;
    retrieve) parts+=("pulled latest auth from server") ;;
    *)
      [[ -n "$action" ]] && parts+=("action ${action}")
      ;;
  esac
  [[ -n "$msg" ]] && parts+=("$msg")
  printf "%s" "$(join_with_semicolon "${parts[@]}")"
}

codex_target_label="${codex_target_label:-${remote_tag:-${remote_version:-${LOCAL_VERSION:-unknown}}}}"
wrapper_target_label="${wrapper_target_label:-${WRAPPER_VERSION}}"
wrapper_installed_label="${WRAPPER_VERSION:-unknown}"
codex_installed_label="${codex_installed_label:-${LOCAL_VERSION:-unknown}}"

codex_status_display="$codex_status_label"
if [[ -n "$codex_status_note" ]]; then
  codex_status_display="${codex_status_display} (${codex_status_note})"
fi
wrapper_status_display="$wrapper_status_label"
if [[ -n "$wrapper_status_note" ]]; then
  wrapper_status_display="${wrapper_status_display} (${wrapper_status_note})"
fi

codex_installed_display="$codex_installed_label"
if [[ -n "$codex_installed_display" ]]; then
  codex_installed_display+=" installed"
fi
codex_target_display="$codex_target_label"
if [[ -n "$codex_target_display" && "$codex_target_display" != "n/a" && "$codex_target_display" != "unknown" ]]; then
  codex_target_display+=" available"
fi
wrapper_installed_display="$wrapper_installed_label"
if [[ -n "$wrapper_installed_display" ]]; then
  wrapper_installed_display+=" installed"
fi
wrapper_target_display="$wrapper_target_label"
if [[ -n "$wrapper_target_display" && "$wrapper_target_display" != "n/a" && "$wrapper_target_display" != "unknown" ]]; then
  wrapper_target_display+=" available"
fi

api_label="Unavailable"
api_tone="red"
case "$AUTH_PULL_STATUS" in
  ok)
    api_label="Up and working"
    api_tone="green"
    ;;
  offline)
    api_label="Unavailable (offline)"
    api_tone="yellow"
    ;;
  disabled)
    api_label="API disabled"
    api_tone="red"
    ;;
  invalid)
    api_label="Invalid API key"
    api_tone="red"
    ;;
  missing-config)
    api_label="Missing API config"
    api_tone="red"
    ;;
esac

auth_label="n/a"
if [[ -n "$AUTH_STATUS" ]]; then
  auth_label="$(format_auth_label "$AUTH_STATUS" "$AUTH_ACTION" "$AUTH_MESSAGE")"
elif [[ "$AUTH_PULL_STATUS" == "offline" ]]; then
  cached_lr="${ORIGINAL_LAST_REFRESH:-unknown}"
  if (( HAS_LOCAL_AUTH )) && (( LOCAL_AUTH_IS_FRESH )); then
    auth_label="using cached auth (api offline; last_refresh ${cached_lr})"
  elif (( HAS_LOCAL_AUTH )); then
    auth_label="cached auth stale (api offline; last_refresh ${cached_lr})"
  else
    auth_label="auth unavailable (api offline)"
  fi
elif [[ "$AUTH_PULL_STATUS" != "ok" ]]; then
  auth_label="auth sync failed"
fi

auth_tone="yellow"
case "$AUTH_STATUS" in
  valid|"")
    [[ "$AUTH_PULL_STATUS" == "ok" ]] && auth_tone="green"
    ;;
  outdated|missing|upload_required)
    auth_tone="yellow"
    ;;
  *)
    auth_tone="yellow"
    ;;
esac
if [[ "$AUTH_PULL_STATUS" == "offline" ]]; then
  if (( HAS_LOCAL_AUTH )) && (( LOCAL_AUTH_IS_FRESH )); then
    auth_tone="yellow"
  else
    auth_tone="red"
  fi
elif [[ "$AUTH_PULL_STATUS" != "ok" ]]; then
  auth_tone="red"
fi

prompt_label="sync skipped"
prompt_tone="yellow"
if [[ "$PROMPT_SYNC_STATUS" == "ok" ]]; then
  prompt_label="synced"
  if [[ "$PROMPT_PULL_UPDATED" =~ ^[0-9]+$ ]] && (( PROMPT_PULL_UPDATED > 0 )); then
    prompt_label+=" (${PROMPT_PULL_UPDATED} updated)"
  fi
  if [[ "$PROMPT_PULL_ERRORS" =~ ^[0-9]+$ ]] && (( PROMPT_PULL_ERRORS > 0 )); then
    prompt_label+=" (${PROMPT_PULL_ERRORS} fetch errors)"
    prompt_tone="yellow"
  else
    prompt_tone="green"
  fi
elif [[ "$PROMPT_SYNC_STATUS" == "missing-config" ]]; then
  prompt_label="sync config missing"
  prompt_tone="red"
elif [[ "$PROMPT_SYNC_STATUS" == "no-python" ]]; then
  prompt_label="sync requires python3"
  prompt_tone="yellow"
elif [[ "$PROMPT_SYNC_STATUS" == "error" ]]; then
  prompt_label="sync failed"
  prompt_tone="red"
fi

case "$PROMPT_PUSH_STATUS" in
  ok)
    if [[ "$PROMPT_PUSHED" =~ ^[0-9]+$ ]] && (( PROMPT_PUSHED > 0 )); then
      prompt_label+="; pushed ${PROMPT_PUSHED}"
    fi
    if [[ "$PROMPT_PUSH_ERRORS" =~ ^[0-9]+$ ]] && (( PROMPT_PUSH_ERRORS > 0 )); then
      prompt_label+="; push errors ${PROMPT_PUSH_ERRORS}"
      prompt_tone="yellow"
    fi
    ;;
  no-baseline)
    prompt_label+="; push skipped (no baseline)"
    ;;
  no-python)
    prompt_label+="; push skipped (python missing)"
    ;;
  missing-config)
    prompt_label+="; push skipped (config missing)"
    prompt_tone="red"
    ;;
  error)
    prompt_label+="; push failed"
    prompt_tone="red"
    ;;
esac

command_actions=()
if (( codex_update_attempted )); then command_actions+=("codex"); fi
if (( wrapper_update_attempted )); then command_actions+=("wrapper"); fi
if [[ "$AUTH_STATUS" =~ ^(outdated|missing|upload_required)$ || "$AUTH_ACTION" == "store" ]]; then command_actions+=("auth"); fi
command_label="launching codex"
if (( ${#command_actions[@]} )); then
  command_label="updating $(human_join "${command_actions[@]}")"
fi

result_parts=()
if (( codex_updated )); then
  result_parts+=("codex updated")
elif (( codex_update_failed )); then
  result_parts+=("codex update failed")
else
  result_parts+=("codex ${codex_status_label,,}")
fi
if (( wrapper_updated )); then
  result_parts+=("wrapper updated")
elif (( wrapper_update_failed )); then
  result_parts+=("wrapper update failed")
else
  result_parts+=("wrapper ${wrapper_status_label,,}")
fi
if [[ -n "$AUTH_STATUS" ]]; then
  auth_result="auth ${AUTH_STATUS}"
  if [[ -n "$AUTH_ACTION" ]]; then
    auth_result+=", ${AUTH_ACTION}"
  fi
  result_parts+=("$auth_result")
elif [[ "$AUTH_PULL_STATUS" == "offline" ]]; then
  if (( HAS_LOCAL_AUTH )) && (( LOCAL_AUTH_IS_FRESH )); then
    result_parts+=("auth cached (api offline)")
  elif (( HAS_LOCAL_AUTH )); then
    result_parts+=("auth stale (api offline)")
  else
    result_parts+=("auth unavailable (api offline)")
  fi
elif [[ "$AUTH_PULL_STATUS" != "ok" ]]; then
  result_parts+=("auth unavailable")
fi
if [[ "$PROMPT_SYNC_STATUS" == "ok" ]]; then
  prompt_result="prompts synced"
  if [[ "$PROMPT_PULL_UPDATED" =~ ^[0-9]+$ ]] && (( PROMPT_PULL_UPDATED > 0 )); then
    prompt_result+=" (${PROMPT_PULL_UPDATED} updated)"
  fi
  if [[ "$PROMPT_PUSHED" =~ ^[0-9]+$ ]] && (( PROMPT_PUSHED > 0 )); then
    prompt_result+="; pushed ${PROMPT_PUSHED}"
  fi
  if [[ "$PROMPT_PUSH_ERRORS" =~ ^[0-9]+$ ]] && (( PROMPT_PUSH_ERRORS > 0 )); then
    prompt_result+="; push errors ${PROMPT_PUSH_ERRORS}"
  fi
  result_parts+=("$prompt_result")
elif [[ "$PROMPT_SYNC_STATUS" == "missing-config" ]]; then
  result_parts+=("prompts config missing")
elif [[ "$PROMPT_SYNC_STATUS" == "no-python" ]]; then
  result_parts+=("prompts python missing")
elif [[ "$PROMPT_SYNC_STATUS" == "error" ]]; then
  result_parts+=("prompts sync failed")
fi
if [[ "$PROMPT_PUSH_STATUS" == "error" ]]; then
  result_parts+=("prompts push failed")
fi
result_label="$(human_join "${result_parts[@]}")"

  usage_summary=""
  if [[ -n "$last_usage_payload" ]]; then
    usage_summary="$(parse_usage_summary "$last_usage_payload")"
  fi

  codex_tone="green"
  case "${codex_status_label,,}" in
    update\ available|check\ skipped|update\ skipped)
      codex_tone="yellow"
      ;;
  update\ failed|api\ unavailable)
    codex_tone="red"
    ;;
esac
(( codex_update_failed )) && codex_tone="red"

wrapper_tone="green"
case "${wrapper_status_label,,}" in
  update\ available|update\ skipped|check\ skipped)
    wrapper_tone="yellow"
    ;;
  update\ failed)
    wrapper_tone="red"
    ;;
esac
(( wrapper_update_failed )) && wrapper_tone="red"

result_tone="green"
if (( codex_update_failed )) || (( wrapper_update_failed )) || { [[ "$AUTH_PULL_STATUS" != "ok" ]] && [[ "$AUTH_PULL_STATUS" != "offline" ]]; }; then
  result_tone="red"
elif [[ "$AUTH_PULL_STATUS" == "offline" ]]; then
  if (( HAS_LOCAL_AUTH )); then
    result_tone="yellow"
  else
    result_tone="red"
  fi
elif [[ "$AUTH_STATUS" =~ ^(outdated|missing|upload_required)$ ]]; then
  result_tone="yellow"
elif [[ "${codex_status_label,,}" == "update available" ]] || [[ "${wrapper_status_label,,}" == "update available" ]]; then
  result_tone="yellow"
elif [[ "$PROMPT_SYNC_STATUS" == "error" || "$PROMPT_PUSH_STATUS" == "error" ]]; then
  result_tone="red"
elif [[ "$PROMPT_SYNC_STATUS" != "ok" && "$PROMPT_SYNC_STATUS" != "skip" ]]; then
  result_tone="yellow"
elif [[ "$PROMPT_PUSH_ERRORS" =~ ^[0-9]+$ ]] && (( PROMPT_PUSH_ERRORS > 0 )); then
  result_tone="yellow"
fi

command_tone=""
if (( ${#command_actions[@]} )); then
  command_tone="yellow"
fi

  log_info "$(format_status_row "codex" "$codex_installed_display" "$codex_target_display" "$(colorize "$codex_status_display" "$codex_tone")")"
  log_info "$(format_status_row "wrapper" "$wrapper_installed_display" "$wrapper_target_display" "$(colorize "$wrapper_status_display" "$wrapper_tone")")"
  log_info "$(format_simple_row "api" "$(colorize "$api_label" "$api_tone")")"
  log_info "$(format_simple_row "auth" "$(colorize "$auth_label" "$auth_tone")")"
  log_info "$(format_simple_row "prompts" "$(colorize "$prompt_label" "$prompt_tone")")"
  host_usage_parts=()
  if [[ -n "$HOST_API_CALLS" ]]; then
    host_usage_parts+=("api calls ${HOST_API_CALLS}")
  fi
  if [[ -n "$HOST_TOKENS_MONTH_TOTAL" ]]; then
    token_bits=()
    [[ -n "$HOST_TOKENS_MONTH_TOTAL" ]] && token_bits+=("total ${HOST_TOKENS_MONTH_TOTAL}")
    [[ -n "$HOST_TOKENS_MONTH_INPUT" ]] && token_bits+=("in ${HOST_TOKENS_MONTH_INPUT}")
    [[ -n "$HOST_TOKENS_MONTH_OUTPUT" ]] && token_bits+=("out ${HOST_TOKENS_MONTH_OUTPUT}")
    [[ -n "$HOST_TOKENS_MONTH_CACHED" ]] && token_bits+=("cached ${HOST_TOKENS_MONTH_CACHED}")
    [[ -n "$HOST_TOKENS_MONTH_REASONING" ]] && token_bits+=("reason ${HOST_TOKENS_MONTH_REASONING}")
    token_line="$(join_with_semicolon "${token_bits[@]}")"
    host_usage_parts+=("tokens this month: ${token_line}")
  fi
  if (( ${#host_usage_parts[@]} )); then
    host_usage_text="$(join_with_semicolon "${host_usage_parts[@]}")"
    log_info "$(format_simple_row "host usage" "$host_usage_text")"
  fi
  qline=$(render_quota_line "$CHATGPT_PRIMARY_USED" "$CHATGPT_PRIMARY_RESET_AFTER" "$CHATGPT_PRIMARY_RESET_AT")
  if [[ -n "$qline" ]]; then
    qtone="${qline%%$'\t'*}"
  rest="${qline#*$'\t'}"
  qtext="${rest%%$'\t'*}"
  qnote="${rest#*$'\t'}"
  log_info "$(format_quota_row "5h quota" "$(colorize "$qtext" "$qtone")" "$(colorize "$qnote" "$qtone")")"
fi
qline=$(render_quota_line "$CHATGPT_SECONDARY_USED" "$CHATGPT_SECONDARY_RESET_AFTER" "$CHATGPT_SECONDARY_RESET_AT")
if [[ -n "$qline" ]]; then
  qtone2="${qline%%$'\t'*}"
  rest2="${qline#*$'\t'}"
  qtext2="${rest2%%$'\t'*}"
  qnote2="${rest2#*$'\t'}"
  log_info "$(format_quota_row "week quota" "$(colorize "$qtext2" "$qtone2")" "$(colorize "$qnote2" "$qtone2")")"
fi
if [[ -n "$usage_summary" ]]; then
  log_info "$(format_simple_row "tokens" "$usage_summary")"
fi
log_info "$(format_simple_row "result" "$(colorize "$result_label" "$result_tone")")"
log_info "$(format_simple_row "command" "$(colorize "$command_label" "$command_tone")")"

if (( wrapper_updated )); then
  log_warn "Wrapper updated; restart cdx to use the new wrapper."
  exit 0
fi

AUTH_LAUNCH_ALLOWED=0
AUTH_LAUNCH_REASON=""
case "$AUTH_PULL_STATUS" in
  ok)
    AUTH_LAUNCH_ALLOWED=1
    ;;
  offline)
    if (( HAS_LOCAL_AUTH )) && (( LOCAL_AUTH_IS_FRESH )); then
      AUTH_LAUNCH_ALLOWED=1
      AUTH_LAUNCH_REASON="API offline; using cached auth.json"
    elif (( HAS_LOCAL_AUTH )); then
      AUTH_LAUNCH_REASON="API offline; cached auth.json older than 24h"
    else
      AUTH_LAUNCH_REASON="API offline and no cached auth.json"
    fi
    ;;
  invalid)
    AUTH_LAUNCH_REASON="Invalid API key; download a fresh wrapper or rotate the key."
    ;;
  missing-config)
    AUTH_LAUNCH_REASON="Auth configuration missing (base URL or API key)."
    ;;
  disabled)
    AUTH_LAUNCH_REASON="Auth API disabled by administrator."
    ;;
  fail)
    AUTH_LAUNCH_REASON="Auth sync failed; check API connectivity."
    ;;
  *)
    AUTH_LAUNCH_REASON="Auth unavailable; fix sync before retrying."
    ;;
esac

if (( AUTH_LAUNCH_ALLOWED == 0 )); then
  log_error "${AUTH_LAUNCH_REASON:-Auth unavailable; refusing to start Codex. Re-run after fixing API key or provisioning auth.}"
  exit 1
elif [[ "$AUTH_PULL_STATUS" == "offline" ]]; then
  log_warn "${AUTH_LAUNCH_REASON} (last_refresh ${ORIGINAL_LAST_REFRESH:-unknown})."
fi

cleanup() {
  local exit_status=$?
  trap - EXIT
  push_slash_commands_if_changed || true
  if (( CODEX_COMMAND_STARTED )) && (( SYNC_PUSH_COMPLETED == 0 )); then
    push_auth_if_changed "push" || true
  fi
  # Emit final auth push status if determined
  if [[ -n "$AUTH_PUSH_RESULT" ]]; then
    log_info "Auth push | ${AUTH_PUSH_RESULT} | ${AUTH_PUSH_REASON:-n/a}"
  fi
  exit "$exit_status"
}
trap cleanup EXIT

if (( AUTH_LAUNCH_ALLOWED == 0 )); then
  exit 1
fi

run_codex_command() {
  local tmp_output status
  tmp_output="$(mktemp)"
  set +e
  if [[ -t 1 && "$CODEX_NO_PTY" != "1" ]]; then
    local cmd_line=("$CODEX_REAL_BIN" --ask-for-approval never --sandbox danger-full-access "$@")
    if [[ "$CODEX_NO_SCRIPT" != "1" ]] && command -v script >/dev/null 2>&1; then
      # Use script to keep a PTY and capture output to a typescript file while streaming to the real TTY.
      local cmd_str
      cmd_str="$(printf '%q ' "${cmd_line[@]}")"
      script -qef "$tmp_output" -c "$cmd_str"
      status=$?
    elif command -v python3 >/dev/null 2>&1; then
      # Fallback PTY using Python's pty module when script is unavailable.
      status=0
      python3 - "$tmp_output" "${cmd_line[@]}" <<'PY'
import os, sys, pty
log_path = sys.argv[1]
cmd = sys.argv[2:]
with open(log_path, "wb") as log:
    pid, fd = pty.fork()
    if pid == 0:
        os.execvp(cmd[0], cmd)
    try:
        while True:
            try:
                data = os.read(fd, 1024)
            except OSError:
                break
            if not data:
                break
            os.write(sys.stdout.fileno(), data)
            log.write(data)
            log.flush()
    except KeyboardInterrupt:
        pass
    _, status = os.waitpid(pid, 0)
    sys.exit(os.WEXITSTATUS(status))
PY
      status=$?
    else
      # Last-resort: run directly to preserve TTY; no tee (token usage may be skipped).
      "${cmd_line[@]}"
      status=$?
    fi
    if [[ ${status:-1} -ne 0 ]]; then
      # Fallback: run without PTY to avoid terminal quirks (e.g., notebooks).
      "${cmd_line[@]}" 2>&1 | tee "$tmp_output"
      status=${PIPESTATUS[0]}
    fi
  else
    "$CODEX_REAL_BIN" --ask-for-approval never --sandbox danger-full-access "$@" 2>&1 | tee "$tmp_output"
    status=${PIPESTATUS[0]}
  fi
  set -e
  if [[ -f "$tmp_output" ]]; then
    send_token_usage_if_present "$tmp_output"
    rm -f "$tmp_output"
  fi
  return "$status"
}

CODEX_COMMAND_STARTED=1
if run_codex_command "$@"; then
  cmd_status=0
else
  cmd_status=$?
fi
push_auth_if_changed "push" || true
exit "$cmd_status"
